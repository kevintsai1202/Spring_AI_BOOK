# 7.4 ETL(ä¸­) - é€²éšæ–‡ä»¶é¡å‹

> **å°æ‡‰ç« ç¯€**: Day21
> **å°æ‡‰ç¯„ä¾‹**: `chapter7-rag-etl-pipeline`
> **é›£åº¦**: â­â­â­â­â˜†

---

## ğŸ“š æœ¬ç« æ¦‚è¦

çœŸå¯¦ä¸–ç•Œçš„çŸ¥è­˜åº«ä¸åªæœ‰ PDF å’Œ Word,é‚„æœ‰ Excel è©¦ç®—è¡¨ã€PowerPoint ç°¡å ±ã€æƒæåœ–ç‰‡ã€å£“ç¸®æª”æ¡ˆ...ã€‚æœ¬ç« å°‡æ•™ä½ å¦‚ä½•ä½¿ç”¨ Spring AI è™•ç†é€™äº›é€²éšæ–‡ä»¶é¡å‹,å»ºç«‹å®Œæ•´çš„å¤šåª’é«”å…§å®¹æå–èƒ½åŠ›ã€‚

**å­¸ç¿’ç›®æ¨™**:
- ä½¿ç”¨ TikaDocumentReader è™•ç† Office æ–‡ä»¶
- å¯¦ç¾ OCR åœ–åƒæ–‡å­—æå–
- è™•ç†å£“ç¸®æª”æ¡ˆçš„æ‰¹æ¬¡æå–
- è¨­è¨ˆçµ±ä¸€çš„å¤šæ ¼å¼æ–‡æª”è™•ç†æ¶æ§‹

---

## ğŸ¯ ç‚ºä»€éº¼éœ€è¦é€²éšæ–‡ä»¶è™•ç†?

### ä¼æ¥­å ´æ™¯éœ€æ±‚

```mermaid
graph TB
    subgraph Enterprise["ğŸ¢ ä¼æ¥­çŸ¥è­˜ä¾†æº"]
        A1["ğŸ“Š Excel å ±è¡¨<br/>(æ¥­å‹™è³‡æ–™)"]
        A2["ğŸ¯ PowerPoint<br/>(ç”¢å“ç°¡å ±)"]
        A3["ğŸ“¸ æƒææ–‡ä»¶<br/>(ç´™æœ¬åˆç´„)"]
        A4["ğŸ“¦ å£“ç¸®æª”æ¡ˆ<br/>(æ­·å²è³‡æ–™)"]
    end

    subgraph Challenge["âš ï¸ è™•ç†æŒ‘æˆ°"]
        B1["å¤šå·¥ä½œè¡¨çµæ§‹"]
        B2["æŠ•å½±ç‰‡æ’ç‰ˆè¤‡é›œ"]
        B3["åœ–åƒæ–‡å­—è­˜åˆ¥"]
        B4["éè¿´è§£å£“ç¸®"]
    end

    subgraph Solution["âœ… Spring AI è§£æ±ºæ–¹æ¡ˆ"]
        C1["TikaDocumentReader<br/>(Office è¬ç”¨è®€å–å™¨)"]
        C2["è‡ªå®šç¾© OCR Reader"]
        C3["Archive Reader<br/>(éè¿´è™•ç†)"]
    end

    A1 --> B1 --> C1
    A2 --> B2 --> C1
    A3 --> B3 --> C2
    A4 --> B4 --> C3

    style Enterprise fill:#e1f5ff,stroke:#0288d1
    style Challenge fill:#fff4e6,stroke:#f57c00
    style Solution fill:#c8e6c9,stroke:#388e3c
```

**çœŸå¯¦æ¡ˆä¾‹**:
- ğŸ“Š **è²¡å‹™éƒ¨é–€**: å¾ Excel å ±è¡¨æå–æ¥­å‹™æ•¸æ“šå»ºç«‹å•ç­”ç³»çµ±
- ğŸ¯ **éŠ·å”®åœ˜éšŠ**: æ•´åˆæ‰€æœ‰ç”¢å“ç°¡å ±å…§å®¹ä¾› AI æŸ¥è©¢
- ğŸ“„ **æ³•å‹™åˆè¦**: å°‡æƒæçš„åˆç´„æ–‡ä»¶æ•¸ä½åŒ–ä¸¦å‘é‡åŒ–
- ğŸ“¦ **IT éƒ¨é–€**: æ‰¹æ¬¡è™•ç†æ­·å²æ–‡æª”å£“ç¸®åŒ…

---

## ğŸ—ï¸ å¤šæ ¼å¼æ–‡æª”æ¶æ§‹

### Spring AI ETL Pipeline æ“´å±•

```mermaid
graph LR
    A["ğŸ“¥ å¤šæ ¼å¼è¼¸å…¥"] --> B["ğŸ”„ DocumentReader<br/>çµ±ä¸€æ¥å£"]
    B --> C1["ğŸ“„ PDF Reader"]
    B --> C2["ğŸ“Š Tika Reader<br/>(Office)"]
    B --> C3["ğŸ“¸ OCR Reader<br/>(åœ–åƒ)"]
    B --> C4["ğŸ“¦ Archive Reader<br/>(ZIP)"]

    C1 --> D["ğŸ”¢ å‘é‡åŒ–"]
    C2 --> D
    C3 --> D
    C4 --> D

    D --> E["ğŸ’¾ Vector Store"]

    style A fill:#e1f5ff,stroke:#0288d1
    style B fill:#fff4e6,stroke:#f57c00
    style D fill:#e1bee7,stroke:#8e24aa
    style E fill:#c8e6c9,stroke:#388e3c
```

**è¨­è¨ˆåŸå‰‡**:
1. **çµ±ä¸€ä»‹é¢**: æ‰€æœ‰ Reader éƒ½å¯¦ç¾ `DocumentReader` æ¥å£
2. **å·¥å» æ¨¡å¼**: æ ¹æ“šæª”æ¡ˆé¡å‹è‡ªå‹•é¸æ“‡é©ç•¶çš„ Reader
3. **å¯æ“´å±•æ€§**: è¼•é¬†æ·»åŠ æ–°çš„æ–‡ä»¶æ ¼å¼æ”¯æ´

---

## ğŸ“Š Office æ–‡ä»¶è™•ç† (Excel & PowerPoint)

### TikaDocumentReader - Office æ–‡ä»¶è¬ç”¨è®€å–å™¨

**Apache Tika** æ˜¯ Spring AI å®˜æ–¹æ¨è–¦çš„ Office æ–‡ä»¶è™•ç†æ–¹æ¡ˆ,æ”¯æ´ Wordã€Excelã€PowerPoint ç­‰æ ¼å¼ã€‚

#### ä¾è³´é…ç½®

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-tika-document-reader</artifactId>
</dependency>
```

#### åŸºæœ¬ç”¨æ³•

```java
// å°æ‡‰ç¯„ä¾‹: chapter7-rag-etl-pipeline/.../service/MultiFormatDocumentReader.java:76

/**
 * è®€å– Office æ–‡æª” (Word, Excel, PowerPoint)
 */
private List<Document> readOfficeDocument(Resource resource) {
    log.debug("ä½¿ç”¨ Tika è®€å– Office æ–‡æª”: {}", resource.getFilename());

    // 1. å‰µå»º TikaDocumentReader (Spring AI æä¾›)
    TikaDocumentReader tikaReader = new TikaDocumentReader(resource);
    List<Document> documents = tikaReader.read();

    // 2. æ·»åŠ æ–‡æª”é¡å‹å…ƒè³‡æ–™
    String filename = resource.getFilename();
    documents.forEach(doc -> {
        doc.getMetadata().put("document_type", determineDocumentType(filename));
        doc.getMetadata().put("source_file", filename);
        doc.getMetadata().put("extraction_method", "TIKA");
    });

    return documents;
}
```

**Tika çš„å¼·å¤§ä¹‹è™•**:
- âœ… è‡ªå‹•åµæ¸¬æ–‡ä»¶ç·¨ç¢¼å’Œæ ¼å¼
- âœ… æå–è¡¨æ ¼ã€åœ–è¡¨çš„æ–‡å­—å…§å®¹
- âœ… è™•ç†è¤‡é›œçš„æ’ç‰ˆå’ŒåµŒå…¥ç‰©ä»¶
- âœ… æ”¯æ´ 1000+ ç¨®æ–‡ä»¶æ ¼å¼

### Office æ–‡ä»¶æå–ç¤ºä¾‹

| æ–‡ä»¶é¡å‹ | æå–å…§å®¹ | æ³¨æ„äº‹é … |
|---------|---------|---------|
| **Excel (.xlsx)** | æ‰€æœ‰å·¥ä½œè¡¨çš„æ–‡å­—ã€æ•¸å€¼ | å…¬å¼æœƒè¢«è½‰ç‚ºè¨ˆç®—çµæœ |
| **PowerPoint (.pptx)** | æŠ•å½±ç‰‡æ–‡å­—ã€å‚™è¨»ã€åœ–è¡¨èªªæ˜ | ä¸åŒ…å«åœ–ç‰‡å…§å®¹ |
| **Word (.docx)** | æ–‡å­—ã€è¡¨æ ¼ã€è¨»è…³ | ä¿ç•™åŸºæœ¬çµæ§‹ |

**å®Œæ•´ ETL æµç¨‹**:

```java
// å°æ‡‰ç¯„ä¾‹: chapter7-rag-etl-pipeline/.../service/EtlPipelineService.java

/**
 * Office æ–‡ä»¶ ETL æµç¨‹
 */
public void processOfficeDocument(Resource resource) {
    // 1. Extract: ä½¿ç”¨ Tika è®€å–
    TikaDocumentReader reader = new TikaDocumentReader(resource);
    List<Document> documents = reader.read();

    // 2. Transform: æ–‡æœ¬åˆ†å‰²
    TokenTextSplitter splitter = new TokenTextSplitter(800, 200, 5, 1000, true);
    List<Document> chunks = splitter.apply(documents);

    // 3. Load: è¼‰å…¥å‘é‡è³‡æ–™åº«
    vectorStore.write(chunks);

    log.info("æˆåŠŸè™•ç† Office æ–‡ä»¶: {}", resource.getFilename());
}
```

---

## ğŸ“¸ åœ–åƒæ–‡ä»¶ OCR è™•ç†

### ç‚ºä»€éº¼éœ€è¦ OCR?

**å ´æ™¯**: å…¬å¸æœ‰å¤§é‡æƒæçš„ç´™æœ¬æ–‡ä»¶ã€åœ–ç‰‡å½¢å¼çš„ç°¡å ±æˆªåœ–...

```mermaid
graph LR
    A["ğŸ“¸ åœ–åƒæ–‡ä»¶<br/>(PNG/JPG/PDFæƒæ)"] --> B["ğŸ” OCR æ–‡å­—è­˜åˆ¥<br/>(Tesseract)"]
    B --> C["ğŸ“„ ç´”æ–‡å­— Document"]
    C --> D["ğŸ”¢ å‘é‡åŒ–"]
    D --> E["ğŸ’¾ Vector Store"]

    style A fill:#e1f5ff,stroke:#0288d1
    style B fill:#fff4e6,stroke:#f57c00
    style C fill:#c8e6c9,stroke:#388e3c
```

### è‡ªå®šç¾© OCR DocumentReader

Spring AI **æ²’æœ‰å…§å»º** OCR Reader,ä½†æˆ‘å€‘å¯ä»¥è¼•é¬†å¯¦ç¾ä¸€å€‹:

```java
// å°æ‡‰ç¯„ä¾‹: chapter7-rag-etl-pipeline/.../reader/ImageOCRDocumentReader.java (æ¦‚å¿µ)

/**
 * OCR åœ–åƒæ–‡å­—æå–å™¨
 * å¯¦ç¾ Spring AI DocumentReader æ¥å£
 */
@Slf4j
public class ImageOCRDocumentReader implements DocumentReader {

    private final Resource resource;
    private final TesseractOCRService ocrService;

    @Override
    public List<Document> read() {
        log.info("OCR æå–åœ–åƒæ–‡å­—: {}", resource.getFilename());

        try (InputStream inputStream = resource.getInputStream()) {
            // 1. è®€å–åœ–åƒ
            BufferedImage image = ImageIO.read(inputStream);

            // 2. åœ–åƒé è™•ç† (ç°éšã€å¢å¼·å°æ¯”åº¦)
            BufferedImage processedImage = preprocessImage(image);

            // 3. OCR æ–‡å­—è­˜åˆ¥
            String extractedText = ocrService.extractText(processedImage);

            if (extractedText != null && !extractedText.trim().isEmpty()) {
                // 4. å»ºç«‹ Document ä¸¦åŠ å…¥å…ƒè³‡æ–™
                Map<String, Object> metadata = Map.of(
                    "document_type", "IMAGE_OCR",
                    "source_file", resource.getFilename(),
                    "image_width", image.getWidth(),
                    "image_height", image.getHeight(),
                    "extraction_method", "TESSERACT_OCR"
                );

                return List.of(new Document(extractedText.trim(), metadata));
            }

            return List.of();

        } catch (Exception e) {
            log.error("OCR æå–å¤±æ•—: {}", resource.getFilename(), e);
            return List.of();
        }
    }

    /**
     * åœ–åƒé è™•ç†: æé«˜ OCR æº–ç¢ºç‡
     */
    private BufferedImage preprocessImage(BufferedImage originalImage) {
        // è½‰æ›ç‚ºç°éš
        BufferedImage grayImage = new BufferedImage(
            originalImage.getWidth(),
            originalImage.getHeight(),
            BufferedImage.TYPE_BYTE_GRAY
        );

        Graphics2D g2d = grayImage.createGraphics();
        g2d.drawImage(originalImage, 0, 0, null);
        g2d.dispose();

        // å¢å¼·å°æ¯”åº¦ (æé«˜è­˜åˆ¥ç‡)
        RescaleOp rescaleOp = new RescaleOp(1.2f, 15, null);
        return rescaleOp.filter(grayImage, null);
    }
}
```

### Tesseract OCR è¨­å®š

**ä¾è³´**:
```xml
<dependency>
    <groupId>net.sourceforge.tess4j</groupId>
    <artifactId>tess4j</artifactId>
    <version>5.7.0</version>
</dependency>
```

**ç’°å¢ƒè¨­å®š**:
```yaml
# application.yml
app:
  etl:
    ocr:
      # Windows é è¨­å®‰è£è·¯å¾‘
      tessdata-path: C:/Program Files/Tesseract-OCR/tessdata
      # æ”¯æ´ç¹é«”ä¸­æ–‡ + è‹±æ–‡
      language: chi_tra+eng
      # OCR å¼•æ“æ¨¡å¼ (1 = LSTM ç¥ç¶“ç¶²è·¯å¼•æ“,æº–ç¢ºåº¦é«˜)
      engine-mode: 1
```

**å®‰è£ Tesseract**:
- **Windows**: https://github.com/UB-Mannheim/tesseract/wiki
- **Mac**: `brew install tesseract tesseract-lang`
- **Linux**: `apt-get install tesseract-ocr tesseract-ocr-chi-tra`

### OCR æœ€ä½³å¯¦è¸

| æŠ€å·§ | èªªæ˜ | æ•ˆæœ |
|-----|------|------|
| **ç°éšè™•ç†** | é™ä½è‰²å½©å¹²æ“¾ | â¬†ï¸ æº–ç¢ºç‡ +10% |
| **å°æ¯”åº¦å¢å¼·** | çªé¡¯æ–‡å­—é‚Šç·£ | â¬†ï¸ æº–ç¢ºç‡ +15% |
| **è§£æåº¦æå‡** | DPI â‰¥ 300 | â¬†ï¸ æº–ç¢ºç‡ +20% |
| **å»å™ªè™•ç†** | ç§»é™¤èƒŒæ™¯é›œè¨Š | â¬†ï¸ æº–ç¢ºç‡ +12% |

**æç¤º**: OCR æå–çš„æ–‡å­—å“è³ªç›´æ¥å½±éŸ¿ RAG æ•ˆæœ,å»ºè­°å°é‡è¦æ–‡ä»¶é€²è¡Œäººå·¥æ ¡é©—ã€‚

---

## ğŸ“¦ å£“ç¸®æª”æ¡ˆæ‰¹æ¬¡è™•ç†

### å ´æ™¯: æ‰¹æ¬¡åŒ¯å…¥æ­·å²æ–‡æª”

**å•é¡Œ**: å®¢æˆ¶æä¾›äº†ä¸€å€‹åŒ…å« 100+ å€‹ PDF å’Œ Word æ–‡ä»¶çš„ ZIP å£“ç¸®åŒ…,éœ€è¦æ‰¹æ¬¡åŒ¯å…¥çŸ¥è­˜åº«ã€‚

**è§£æ±ºæ–¹æ¡ˆ**: å¯¦ç¾ `ArchiveDocumentReader`,éè¿´è™•ç†å£“ç¸®åŒ…å…§çš„æ‰€æœ‰æ–‡ä»¶ã€‚

### Archive DocumentReader å¯¦ç¾

```java
// å°æ‡‰ç¯„ä¾‹: chapter7-rag-etl-pipeline/.../reader/ArchiveDocumentReader.java:39

/**
 * å£“ç¸®æª”æ¡ˆ DocumentReader
 * å¯¦ç¾ Spring AI DocumentReader æ¥å£
 */
@Slf4j
public class ArchiveDocumentReader implements DocumentReader {

    private final Resource archiveResource;
    private final DocumentReaderFactory readerFactory;  // ç”¨æ–¼é¸æ“‡åˆé©çš„ Reader

    @Override
    public List<Document> read() {
        log.info("é–‹å§‹æå–å£“ç¸®æª”æ¡ˆ: {}", archiveResource.getFilename());

        String fileName = archiveResource.getFilename().toLowerCase();

        if (fileName.endsWith(".zip")) {
            return extractZipFile();
        } else {
            log.warn("ä¸æ”¯æ´çš„å£“ç¸®æ ¼å¼: {}", fileName);
            return List.of();
        }
    }

    /**
     * æå– ZIP æª”æ¡ˆ
     */
    private List<Document> extractZipFile() throws IOException {
        List<Document> documents = new ArrayList<>();

        try (ZipInputStream zipInputStream =
                new ZipInputStream(archiveResource.getInputStream())) {

            ZipEntry entry;
            while ((entry = zipInputStream.getNextEntry()) != null) {

                // è·³éç›®éŒ„
                if (entry.isDirectory()) {
                    zipInputStream.closeEntry();
                    continue;
                }

                // æª¢æŸ¥æª”æ¡ˆé¡å‹æ˜¯å¦æ”¯æ´
                if (!isSupportedFileType(entry.getName())) {
                    log.debug("è·³éä¸æ”¯æ´çš„æª”æ¡ˆ: {}", entry.getName());
                    zipInputStream.closeEntry();
                    continue;
                }

                // æå–å–®ä¸€æ¢ç›®
                List<Document> entryDocuments = extractZipEntry(zipInputStream, entry);
                documents.addAll(entryDocuments);

                zipInputStream.closeEntry();
            }
        }

        log.info("å¾ ZIP æå–äº† {} å€‹æ–‡æª”", documents.size());
        return documents;
    }

    /**
     * æå– ZIP æ¢ç›®
     */
    private List<Document> extractZipEntry(ZipInputStream zipInputStream, ZipEntry entry)
            throws IOException {

        // 1. è®€å–æ¢ç›®å…§å®¹åˆ°è¨˜æ†¶é«”
        ByteArrayOutputStream baos = new ByteArrayOutputStream();
        byte[] buffer = new byte[8192];
        int bytesRead;

        while ((bytesRead = zipInputStream.read(buffer)) != -1) {
            baos.write(buffer, 0, bytesRead);
        }

        byte[] entryData = baos.toByteArray();

        // 2. å»ºç«‹è¨˜æ†¶é«”è³‡æº
        Resource entryResource = new ByteArrayResource(entryData, entry.getName());

        // 3. ä½¿ç”¨å·¥å» æ¨¡å¼é¸æ“‡é©ç•¶çš„ DocumentReader
        DocumentReader reader = readerFactory.createReader(entryResource);
        List<Document> documents = reader.read();

        // 4. æ·»åŠ å£“ç¸®æª”æ¡ˆç›¸é—œçš„å…ƒè³‡æ–™
        documents.forEach(doc -> {
            doc.getMetadata().put("archive_source", archiveResource.getFilename());
            doc.getMetadata().put("archive_entry", entry.getName());
            doc.getMetadata().put("extraction_method", "ZIP_ARCHIVE");
        });

        return documents;
    }

    /**
     * æª¢æŸ¥æª”æ¡ˆé¡å‹æ˜¯å¦æ”¯æ´
     */
    private boolean isSupportedFileType(String fileName) {
        String lower = fileName.toLowerCase();
        return lower.endsWith(".pdf") || lower.endsWith(".docx") ||
               lower.endsWith(".xlsx") || lower.endsWith(".pptx") ||
               lower.endsWith(".txt") || lower.endsWith(".md");
    }
}
```

### DocumentReader å·¥å» æ¨¡å¼

```java
// å°æ‡‰ç¯„ä¾‹: chapter7-rag-etl-pipeline/.../reader/DocumentReaderFactory.java

/**
 * DocumentReader å·¥å»  - æ ¹æ“šæª”æ¡ˆé¡å‹é¸æ“‡ Reader
 */
@Component
@Slf4j
public class DocumentReaderFactory {

    /**
     * æ ¹æ“šè³‡æºé¡å‹å‰µå»ºå°æ‡‰çš„ DocumentReader
     */
    public DocumentReader createReader(Resource resource) {
        String filename = resource.getFilename();
        if (filename == null) {
            throw new IllegalArgumentException("ç„¡æ³•åˆ¤æ–·æ–‡ä»¶é¡å‹");
        }

        String lower = filename.toLowerCase();

        // æ ¹æ“šå‰¯æª”åé¸æ“‡ Reader
        if (lower.endsWith(".pdf")) {
            return new PagePdfDocumentReader(resource);
        } else if (lower.endsWith(".txt") || lower.endsWith(".md")) {
            return new TextReader(resource);
        } else if (lower.endsWith(".json")) {
            return new JsonReader(resource);
        } else if (lower.endsWith(".html") || lower.endsWith(".htm")) {
            return new JsoupDocumentReader(resource);
        } else if (isTikaSupported(lower)) {
            // Word, Excel, PowerPoint ä½¿ç”¨ Tika
            return new TikaDocumentReader(resource);
        } else {
            throw new UnsupportedOperationException("ä¸æ”¯æ´çš„æ–‡ä»¶é¡å‹: " + filename);
        }
    }

    private boolean isTikaSupported(String filename) {
        return filename.endsWith(".doc") || filename.endsWith(".docx") ||
               filename.endsWith(".xls") || filename.endsWith(".xlsx") ||
               filename.endsWith(".ppt") || filename.endsWith(".pptx");
    }
}
```

**å·¥å» æ¨¡å¼å„ªå‹¢**:
- âœ… æ–°å¢æ–‡ä»¶æ ¼å¼æ”¯æ´æ™‚,åªéœ€ä¿®æ”¹å·¥å» é¡
- âœ… çµ±ä¸€çš„éŒ¯èª¤è™•ç†å’Œæ—¥èªŒè¨˜éŒ„
- âœ… ä¾¿æ–¼å–®å…ƒæ¸¬è©¦å’Œ Mock

---

## ğŸ”„ çµ±ä¸€çš„å¤šæ ¼å¼è™•ç†æµç¨‹

### ETL Pipeline æ•´åˆ

```mermaid
graph TB
    subgraph Input["ğŸ“¥ å¤šæ ¼å¼è¼¸å…¥"]
        A1["PDF"]
        A2["Office<br/>(Word/Excel/PPT)"]
        A3["åœ–åƒ<br/>(OCR)"]
        A4["ZIP å£“ç¸®åŒ…"]
    end

    subgraph Extract["ğŸ” Extract (æå–)"]
        B["DocumentReaderFactory<br/>è‡ªå‹•é¸æ“‡ Reader"]
    end

    subgraph Transform["ğŸ”„ Transform (è½‰æ›)"]
        C1["TokenTextSplitter<br/>(æ–‡æœ¬åˆ†å¡Š)"]
        C2["MetadataEnricher<br/>(å…ƒè³‡æ–™å¢å¼·)"]
    end

    subgraph Load["ğŸ’¾ Load (è¼‰å…¥)"]
        D["VectorStore.write()<br/>(æ‰¹æ¬¡å¯«å…¥)"]
    end

    A1 --> B
    A2 --> B
    A3 --> B
    A4 --> B

    B --> C1
    C1 --> C2
    C2 --> D

    style Input fill:#e1f5ff,stroke:#0288d1
    style Extract fill:#fff4e6,stroke:#f57c00
    style Transform fill:#e1bee7,stroke:#8e24aa
    style Load fill:#c8e6c9,stroke:#388e3c
```

### çµ±ä¸€è™•ç†æœå‹™

```java
// å°æ‡‰ç¯„ä¾‹: chapter7-rag-etl-pipeline/.../service/EtlPipelineService.java

/**
 * çµ±ä¸€çš„ ETL Pipeline æœå‹™
 */
@Service
@Slf4j
@RequiredArgsConstructor
public class EtlPipelineService {

    private final DocumentReaderFactory readerFactory;
    private final VectorStore vectorStore;
    private final TokenTextSplitter textSplitter;

    /**
     * è™•ç†ä»»æ„æ ¼å¼æ–‡ä»¶çš„çµ±ä¸€å…¥å£
     */
    public void processDocument(Resource resource) {
        try {
            // 1. Extract: å·¥å» æ¨¡å¼è‡ªå‹•é¸æ“‡ Reader
            DocumentReader reader = readerFactory.createReader(resource);
            List<Document> documents = reader.read();

            // 2. Transform: æ–‡æœ¬åˆ†å¡Š
            List<Document> chunks = textSplitter.apply(documents);

            // 3. Load: è¼‰å…¥å‘é‡è³‡æ–™åº«
            vectorStore.write(chunks);

            log.info("âœ… æˆåŠŸè™•ç†æ–‡ä»¶: {}, ç”¢ç”Ÿ {} å€‹ç‰‡æ®µ",
                resource.getFilename(), chunks.size());

        } catch (Exception e) {
            log.error("âŒ è™•ç†æ–‡ä»¶å¤±æ•—: {}", resource.getFilename(), e);
            throw new EtlPipelineException("ETL è™•ç†å¤±æ•—", e);
        }
    }

    /**
     * æ‰¹æ¬¡è™•ç†å¤šå€‹æ–‡ä»¶ (æ”¯æ´ä¸¦è¡Œ)
     */
    public void processBatchDocuments(List<Resource> resources) {
        resources.parallelStream().forEach(resource -> {
            try {
                processDocument(resource);
            } catch (Exception e) {
                log.error("æ‰¹æ¬¡è™•ç†å¤±æ•—: {}", resource.getFilename(), e);
                // å–®ä¸€æ–‡ä»¶å¤±æ•—ä¸å½±éŸ¿å…¶ä»–æ–‡ä»¶
            }
        });
    }
}
```

**ä¸¦è¡Œè™•ç†å„ªå‹¢**:
- 100 å€‹æ–‡ä»¶ä¸²è¡Œè™•ç†: **ç´„ 10 åˆ†é˜**
- 100 å€‹æ–‡ä»¶ä¸¦è¡Œè™•ç† (8 æ ¸å¿ƒ): **ç´„ 2 åˆ†é˜** (5å€æé€Ÿ)

---

## ğŸ“ æœ¬ç« é‡é»å›é¡§

### æŠ€è¡“è¦é»ç¸½çµ

| æ–‡ä»¶é¡å‹ | Spring AI æ”¯æ´ | å¯¦ç¾æ–¹å¼ | ä¼æ¥­åƒ¹å€¼ |
|---------|--------------|---------|---------|
| **Excel** | âœ… TikaDocumentReader | å®˜æ–¹æ”¯æ´ | ğŸ“Š å•†æ¥­è³‡æ–™æå– |
| **PowerPoint** | âœ… TikaDocumentReader | å®˜æ–¹æ”¯æ´ | ğŸ¯ ç°¡å ±å…§å®¹åˆ†æ |
| **OCR åœ–åƒ** | âŒ éœ€è‡ªå®šç¾© | è‡ªå®šç¾© DocumentReader + Tesseract | ğŸ“¸ åœ–åƒæ–‡å­—è­˜åˆ¥ |
| **ZIP å£“ç¸®** | âŒ éœ€è‡ªå®šç¾© | è‡ªå®šç¾© ArchiveDocumentReader | ğŸ“¦ æ‰¹æ¬¡æª”æ¡ˆè™•ç† |

### æ ¸å¿ƒè¨­è¨ˆæ¨¡å¼

1. **çµ±ä¸€ä»‹é¢**: æ‰€æœ‰ Reader å¯¦ç¾ `DocumentReader` æ¥å£
   ```java
   public interface DocumentReader {
       List<Document> read();
   }
   ```

2. **å·¥å» æ¨¡å¼**: æ ¹æ“šæª”æ¡ˆé¡å‹è‡ªå‹•é¸æ“‡ Reader
   ```java
   DocumentReader reader = readerFactory.createReader(resource);
   ```

3. **å‡½æ•¸å¼çµ„åˆ**: ETL ä¸‰éšæ®µçš„å„ªé›…çµ„åˆ
   ```java
   vectorStore.write(
       textSplitter.apply(
           documentReader.read()
       )
   );
   ```

### æœ€ä½³å¯¦è¸

1. âœ… **å„ªå…ˆä½¿ç”¨å®˜æ–¹ Reader**: TikaDocumentReader æ”¯æ´åº¦é«˜
2. âœ… **å®Œå–„éŒ¯èª¤è™•ç†**: å–®ä¸€æª”æ¡ˆå¤±æ•—ä¸å½±éŸ¿æ•´é«”æ‰¹æ¬¡è™•ç†
3. âœ… **ä¸¦è¡Œè™•ç†**: åˆ©ç”¨ `parallelStream()` æå‡æ•ˆèƒ½
4. âœ… **å…ƒè³‡æ–™è±å¯Œ**: è¨˜éŒ„ä¾†æºæª”æ¡ˆã€æå–æ–¹æ³•ç­‰è³‡è¨Š
5. âœ… **è¨˜æ†¶é«”ç®¡ç†**: è™•ç†å¤§å‹æª”æ¡ˆæ™‚ä½¿ç”¨æµå¼è®€å–

### æ•ˆèƒ½å°æ¯”

| è™•ç†æ–¹å¼ | 100 å€‹æ–‡ä»¶ | CPU ä½¿ç”¨ç‡ | è¨˜æ†¶é«” |
|---------|-----------|-----------|--------|
| ä¸²è¡Œè™•ç† | 10 åˆ†é˜ | 12% | 500 MB |
| ä¸¦è¡Œè™•ç† (8æ ¸) | 2 åˆ†é˜ | 75% | 1.2 GB |

---

## ğŸš€ ä¸‹ä¸€æ­¥

åœ¨ **7.5 ETL(ä¸‹) - è³‡æ–™å„ªåŒ–** ä¸­,æˆ‘å€‘å°‡å­¸ç¿’:
- ğŸ“Š **TokenTextSplitter** æ™ºèƒ½åˆ†å¡Šç­–ç•¥
- ğŸ·ï¸ **MetadataEnricher** å…ƒè³‡æ–™å¢å¼·æŠ€è¡“
- ğŸ§¹ **DocumentTransformer** è³‡æ–™æ¸…ç†èˆ‡é è™•ç†
- âš¡ **å‘é‡å“è³ªæå‡** å’Œæ•ˆèƒ½èª¿å„ª

**æç¤º**: é€²éšæ–‡ä»¶è™•ç†æ˜¯ RAG ç³»çµ±çš„åŸºç¤è¨­æ–½,æ‰“å¥½åŸºç¤æ‰èƒ½å»ºæ§‹å¼·å¤§çš„çŸ¥è­˜åº«!

---

**åƒè€ƒè³‡æ–™**:
- [Spring AI TikaDocumentReader](https://docs.spring.io/spring-ai/reference/api/etl-pipeline.html#_tika_docx_pptx_html)
- [Apache Tika Supported Formats](https://tika.apache.org/3.1.0/formats.html)
- [Tesseract OCR Documentation](https://github.com/tesseract-ocr/tesseract)
- [å°æ‡‰ç¯„ä¾‹å°ˆæ¡ˆ](../../code-examples/chapter7-rag/chapter7-rag-etl-pipeline)
