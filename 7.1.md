# 7.1 RAG 流程詳解

> **本章重點**：深入理解 RAG（Retrieval-Augmented Generation）的完整工作流程，掌握企業級 RAG 系統的設計原理和實現方法。

## 🎯 學習目標

完成本章學習後，您將能夠：

- 🎯 **理解 RAG 核心概念**：掌握檢索增強生成的基本原理和應用場景
- 🎯 **掌握 RAG 完整流程**：了解從文檔處理到答案生成的每個步驟
- 🎯 **設計 RAG 系統架構**：學會設計可擴展的企業級 RAG 解決方案
- 🎯 **實現基礎 RAG 功能**：使用 Spring AI 建立第一個 RAG 應用
- 🎯 **優化 RAG 效能**：掌握 RAG 系統的效能調校和最佳實踐

---

## 7.1.1 什麼是 RAG？

### RAG 的定義與價值

**RAG（Retrieval-Augmented Generation）** 是一種結合了資訊檢索和文本生成的 AI 技術，它能夠讓大型語言模型（LLM）基於外部知識庫來生成更準確、更具時效性的回答。

**核心價值**：
- 📚 **知識擴展**：突破 LLM 訓練資料的時間限制
- 🎯 **準確性提升**：基於可靠的外部資料源生成答案
- 🔄 **即時更新**：知識庫可以即時更新，無需重新訓練模型
- 💰 **成本效益**：避免重新訓練大型模型的高昂成本
- 🔍 **可追溯性**：答案來源可追溯，提高可信度

### RAG vs 傳統 LLM

| 特性 | 傳統 LLM | RAG 系統 |
|------|----------|----------|
| **知識來源** | 訓練資料 | 外部知識庫 + 訓練資料 |
| **知識更新** | 需要重新訓練 | 即時更新知識庫 |
| **準確性** | 依賴訓練資料 | 基於最新、可靠資料 |
| **可追溯性** | 無法追溯 | 可追溯到具體文檔 |
| **專業領域** | 泛化能力強 | 專業知識更準確 |
| **成本** | 訓練成本高 | 維護成本低 |

### RAG 的應用場景

**1. 企業知識管理**
```
場景：員工詢問公司政策、流程、產品資訊
優勢：
- 基於最新的內部文檔
- 確保資訊的準確性和一致性
- 減少人工客服負擔
```

**2. 技術文檔助手**
```
場景：開發者查詢 API 文檔、技術規範
優勢：
- 即時反映文檔更新
- 提供精確的技術資訊
- 支援多版本文檔查詢
```

**3. 客戶服務系統**
```
場景：客戶詢問產品功能、故障排除
優勢：
- 基於產品手冊和 FAQ
- 提供個性化解決方案
- 24/7 不間斷服務
```

**4. 法律和合規諮詢**
```
場景：查詢法規條文、合規要求
優勢：
- 基於最新法規資料
- 確保合規性和準確性
- 降低法律風險
```

---

## 7.1.2 RAG 系統架構概覽

### 完整的 RAG 系統架構

```
┌─────────────────────────────────────────────────────────────┐
│                    RAG System Architecture                  │
├─────────────────────────────────────────────────────────────┤
│  User Interface Layer                                       │
│  ┌─────────────────┐    ┌─────────────────┐               │
│  │   Web UI        │    │   Mobile App    │               │
│  │   Chat Bot      │    │   API Client    │               │
│  └─────────────────┘    └─────────────────┘               │
├─────────────────────────────────────────────────────────────┤
│  Application Layer                                          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │              RAG Orchestration Engine                   │ │
│  │  ┌─────────────────────────────────────────────────┐   │ │
│  │  │  • Query Processing                             │   │ │
│  │  │  • Retrieval Coordination                       │   │ │
│  │  │  • Response Generation                          │   │ │
│  │  │  • Result Ranking & Filtering                   │   │ │
│  │  └─────────────────────────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Retrieval Layer                                           │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Vector Store │ │Search Engine│ │Knowledge    │          │
│  │• Embeddings │ │• Full-text  │ │Graph        │          │
│  │• Similarity │ │• Keywords   │ │• Relations  │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
├─────────────────────────────────────────────────────────────┤
│  Data Processing Layer                                      │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │                ETL Pipeline                             │ │
│  │  ┌─────────────────────────────────────────────────┐   │ │
│  │  │  Extract → Transform → Load                     │   │ │
│  │  │  • Document Parsing                             │   │ │
│  │  │  • Text Chunking                                │   │ │
│  │  │  • Embedding Generation                         │   │ │
│  │  │  • Metadata Enrichment                          │   │ │
│  │  └─────────────────────────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Data Sources Layer                                         │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Documents    │ │Databases    │ │APIs         │          │
│  │• PDF        │ │• SQL        │ │• REST       │          │
│  │• Word       │ │• NoSQL      │ │• GraphQL    │          │
│  │• Web Pages  │ │• Vector DB  │ │• External   │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
```

### 核心組件說明

**1. 資料來源層（Data Sources Layer）**
- 📄 **文檔資料**：PDF、Word、Excel、PowerPoint 等
- 🗄️ **資料庫**：關聯式資料庫、NoSQL、向量資料庫
- 🌐 **API 介面**：REST API、GraphQL、第三方服務
- 📊 **結構化資料**：CSV、JSON、XML 等格式

**2. 資料處理層（Data Processing Layer）**
- 🔄 **ETL 管道**：提取、轉換、載入資料
- ✂️ **文本分塊**：將長文檔切分為適當大小的片段
- 🧮 **向量化**：將文本轉換為數值向量
- 🏷️ **元資料增強**：添加分類、標籤、時間戳等資訊

**3. 檢索層（Retrieval Layer）**
- 🔍 **向量存儲**：基於語義相似性的檢索
- 📝 **全文搜尋**：基於關鍵字的傳統搜尋
- 🕸️ **知識圖譜**：基於實體關係的檢索

**4. 應用層（Application Layer）**
- 🎯 **查詢處理**：理解和預處理用戶查詢
- 🔗 **檢索協調**：協調多個檢索源的結果
- 📝 **回應生成**：基於檢索結果生成最終答案
- 📊 **結果排序**：對檢索結果進行排序和過濾

---

## 7.1.3 RAG 工作流程詳解

### 完整的 RAG 工作流程

```
┌─────────────────────────────────────────────────────────────┐
│                    RAG Workflow Process                     │
├─────────────────────────────────────────────────────────────┤
│  Phase 1: Data Preparation (Offline)                       │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  1. Document Collection                                 │ │
│  │     ↓                                                   │ │
│  │  2. Document Parsing & Cleaning                         │ │
│  │     ↓                                                   │ │
│  │  3. Text Chunking & Segmentation                        │ │
│  │     ↓                                                   │ │
│  │  4. Embedding Generation                                │ │
│  │     ↓                                                   │ │
│  │  5. Vector Storage & Indexing                           │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Phase 2: Query Processing (Online)                        │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  1. User Query Input                                    │ │
│  │     ↓                                                   │ │
│  │  2. Query Understanding & Enhancement                   │ │
│  │     ↓                                                   │ │
│  │  3. Query Embedding Generation                          │ │
│  │     ↓                                                   │ │
│  │  4. Similarity Search & Retrieval                       │ │
│  │     ↓                                                   │ │
│  │  5. Context Assembly & Ranking                          │ │
│  │     ↓                                                   │ │
│  │  6. LLM Generation with Context                         │ │
│  │     ↓                                                   │ │
│  │  7. Response Post-processing                            │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

### 階段一：資料準備（離線處理）

**步驟 1：文檔收集**
```java
/**
 * 文檔收集服務
 */
@Service
public class DocumentCollectionService {
    
    public List<Document> collectDocuments(List<String> sources) {
        List<Document> documents = new ArrayList<>();
        
        for (String source : sources) {
            if (source.endsWith(".pdf")) {
                documents.addAll(loadPdfDocuments(source));
            } else if (source.startsWith("http")) {
                documents.addAll(loadWebDocuments(source));
            } else if (source.contains("database")) {
                documents.addAll(loadDatabaseDocuments(source));
            }
        }
        
        return documents;
    }
}
```

**步驟 2：文檔解析與清理**
```java
/**
 * 文檔處理服務
 */
@Service
public class DocumentProcessingService {
    
    public Document processDocument(Document rawDocument) {
        // 1. 提取純文本
        String cleanText = extractText(rawDocument);
        
        // 2. 清理和標準化
        cleanText = cleanAndNormalize(cleanText);
        
        // 3. 提取元資料
        Map<String, Object> metadata = extractMetadata(rawDocument);
        
        return new Document(cleanText, metadata);
    }
    
    private String cleanAndNormalize(String text) {
        return text
            .replaceAll("\\s+", " ")  // 標準化空白字符
            .replaceAll("[^\\p{L}\\p{N}\\p{P}\\p{Z}]", "")  // 移除特殊字符
            .trim();
    }
}
```

**步驟 3：文本分塊**
```java
/**
 * 文本分塊服務
 */
@Service
public class TextChunkingService {
    
    private static final int DEFAULT_CHUNK_SIZE = 1000;
    private static final int DEFAULT_OVERLAP = 200;
    
    public List<Document> chunkDocument(Document document) {
        String text = document.getContent();
        List<Document> chunks = new ArrayList<>();
        
        int start = 0;
        int chunkIndex = 0;
        
        while (start < text.length()) {
            int end = Math.min(start + DEFAULT_CHUNK_SIZE, text.length());
            
            // 尋找適當的分割點（句號、段落等）
            if (end < text.length()) {
                end = findBestSplitPoint(text, start, end);
            }
            
            String chunkText = text.substring(start, end);
            
            // 建立分塊文檔
            Map<String, Object> chunkMetadata = new HashMap<>(document.getMetadata());
            chunkMetadata.put("chunk_index", chunkIndex);
            chunkMetadata.put("chunk_start", start);
            chunkMetadata.put("chunk_end", end);
            
            chunks.add(new Document(chunkText, chunkMetadata));
            
            start = end - DEFAULT_OVERLAP;  // 重疊處理
            chunkIndex++;
        }
        
        return chunks;
    }
}
```

**步驟 4：向量化處理**
```java
/**
 * 向量化服務
 */
@Service
public class EmbeddingService {
    
    private final EmbeddingModel embeddingModel;
    
    public List<Document> generateEmbeddings(List<Document> documents) {
        List<Document> embeddedDocuments = new ArrayList<>();
        
        // 批次處理以提高效率
        List<List<Document>> batches = createBatches(documents, 100);
        
        for (List<Document> batch : batches) {
            List<String> texts = batch.stream()
                .map(Document::getContent)
                .collect(Collectors.toList());
            
            // 生成嵌入向量
            EmbeddingResponse embeddingResponse = embeddingModel.embedForResponse(texts);
            List<List<Double>> embeddings = embeddingResponse.getResults().stream()
                .map(result -> result.getOutput())
                .collect(Collectors.toList());
            
            // 將向量添加到文檔中
            for (int i = 0; i < batch.size(); i++) {
                Document doc = batch.get(i);
                // Spring AI 會自動處理嵌入向量，不需要手動設置
                embeddedDocuments.add(doc);
            }
        }
        
        return embeddedDocuments;
    }
}
```

### 階段二：查詢處理（線上處理）

**步驟 1：查詢理解與增強**
```java
/**
 * 查詢處理服務
 */
@Service
public class QueryProcessingService {
    
    public ProcessedQuery processQuery(String rawQuery) {
        // 1. 查詢清理
        String cleanQuery = cleanQuery(rawQuery);
        
        // 2. 查詢擴展
        List<String> expandedQueries = expandQuery(cleanQuery);
        
        // 3. 意圖識別
        QueryIntent intent = identifyIntent(cleanQuery);
        
        return ProcessedQuery.builder()
            .originalQuery(rawQuery)
            .cleanQuery(cleanQuery)
            .expandedQueries(expandedQueries)
            .intent(intent)
            .build();
    }
    
    private List<String> expandQuery(String query) {
        List<String> expanded = new ArrayList<>();
        expanded.add(query);
        
        // 添加同義詞
        expanded.addAll(findSynonyms(query));
        
        // 添加相關詞彙
        expanded.addAll(findRelatedTerms(query));
        
        return expanded;
    }
}
```

**步驟 2：相似性搜尋**

在 Spring AI 中，相似性搜尋已經由 `QuestionAnswerAdvisor` 和 `VectorStore` 內部自動處理，開發者不需要手動實現檢索邏輯：

```java
/**
 * 基本的向量檢索示例
 */
@Service
public class DocumentRetrievalService {
    
    private final VectorStore vectorStore;
    
    public DocumentRetrievalService(VectorStore vectorStore) {
        this.vectorStore = vectorStore;
    }
    
    /**
     * 手動檢索文檔（當需要自定義檢索邏輯時）
     */
    public List<Document> searchDocuments(String query, int topK, double threshold) {
        return vectorStore.similaritySearch(
            SearchRequest.builder()
                .query(query)
                .topK(topK)
                .similarityThreshold(threshold)
                .build()
        );
    }
}
```

**步驟 3：上下文組裝與生成**

在 Spring AI 中，RAG 的上下文組裝和生成由 `QuestionAnswerAdvisor` 自動處理：

```java
/**
 * RAG 生成服務示例
 */
@Service
public class RAGGenerationService {
    
    private final ChatClient ragChatClient;
    
    public RAGGenerationService(ChatClient ragChatClient) {
        this.ragChatClient = ragChatClient;
    }
    
    /**
     * 使用 RAG 生成回應
     */
    public String generateResponse(String query) {
        // Spring AI 的 QuestionAnswerAdvisor 會自動：
        // 1. 檢索相關文檔
        // 2. 組裝上下文
        // 3. 構建提示詞
        // 4. 調用 LLM 生成回應
        return ragChatClient.prompt()
            .user(query)
            .call()
            .content();
    }
    
    /**
     * 帶有動態過濾條件的 RAG 查詢
     */
    public String generateResponseWithFilter(String query, String filterExpression) {
        return ragChatClient.prompt()
            .user(query)
            .advisors(a -> a.param(QuestionAnswerAdvisor.FILTER_EXPRESSION, filterExpression))
            .call()
            .content();
    }
}
```

---

## 7.1.4 Spring AI RAG 實現

### 基礎 RAG 配置

```java
/**
 * RAG 系統配置
 */
@Configuration
@EnableConfigurationProperties(RAGProperties.class)
public class RAGConfig {
    
    @Bean
    public VectorStore vectorStore(EmbeddingModel embeddingModel) {
        return new SimpleVectorStore(embeddingModel);
    }
    
    @Bean
    public QuestionAnswerAdvisor questionAnswerAdvisor(
            VectorStore vectorStore,
            RAGProperties properties) {
        
        return QuestionAnswerAdvisor.builder(vectorStore)
            .searchRequest(SearchRequest.builder()
                .topK(properties.getTopK())
                .similarityThreshold(properties.getSimilarityThreshold())
                .build())
            .build();
    }
    
    @Bean
    public ChatClient ragChatClient(
            ChatModel chatModel,
            QuestionAnswerAdvisor questionAnswerAdvisor) {
        
        return ChatClient.builder(chatModel)
            .defaultAdvisors(questionAnswerAdvisor)
            .build();
    }
}
```

### RAG 服務實現

```java
/**
 * RAG 服務實現
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class RAGService {
    
    private final ChatClient ragChatClient;
    private final VectorStore vectorStore;
    private final DocumentProcessingService documentProcessor;
    
    /**
     * 添加文檔到知識庫
     */
    public void addDocuments(List<Resource> resources) {
        log.info("Adding {} documents to knowledge base", resources.size());
        
        List<Document> documents = new ArrayList<>();
        
        for (Resource resource : resources) {
            try {
                // 使用 Spring AI 的 ETL pipeline 處理文檔
                List<Document> processedDocs = processDocumentWithETL(resource);
                documents.addAll(processedDocs);
                
            } catch (Exception e) {
                log.error("Failed to process document: {}", resource.getFilename(), e);
            }
        }
        
        // 存儲到向量資料庫
        vectorStore.add(documents);
        
        log.info("Successfully added {} document chunks to knowledge base", documents.size());
    }
    
    private List<Document> processDocumentWithETL(Resource resource) {
        // Spring AI 的 ETL pipeline 會自動：
        // 1. 解析文檔內容
        // 2. 分塊處理
        // 3. 生成嵌入向量
        // 開發者只需要調用相應的 DocumentReader
        
        // 根據文件類型選擇合適的 DocumentReader
        // 例如：PdfDocumentReader, TextDocumentReader 等
        
        // 這裡簡化處理，實際應用中會根據文件類型使用對應的 Reader
        return List.of(new Document(resource.toString()));
    }
    
    /**
     * RAG 查詢
     */
    public RAGResponse query(String question) {
        log.debug("Processing RAG query: {}", question);
        
        long startTime = System.currentTimeMillis();
        
        try {
            // RAG 查詢使用 ChatClient 內建的 Advisor 機制
            String response = ragChatClient.prompt()
                .user(question)
                .call()
                .content();
            
            long processingTime = System.currentTimeMillis() - startTime;
            
            return RAGResponse.builder()
                .question(question)
                .answer(response)
                .processingTimeMs(processingTime)
                .timestamp(LocalDateTime.now())
                .build();
                
        } catch (Exception e) {
            log.error("RAG query failed: {}", question, e);
            throw new RAGException("Failed to process query", e);
        }
    }
    
    /**
     * 提取文檔來源
     */
    private List<DocumentSource> extractSources(List<Document> documents) {
        return documents.stream()
            .map(doc -> DocumentSource.builder()
                .title(getDocumentTitle(doc))
                .source(getDocumentSource(doc))
                .relevanceScore(getRelevanceScore(doc))
                .build())
            .collect(Collectors.toList());
    }
}
```

### RAG REST API

```java
/**
 * RAG REST API 控制器
 */
@RestController
@RequestMapping("/api/rag")
@RequiredArgsConstructor
@Slf4j
public class RAGController {
    
    private final RAGService ragService;
    
    /**
     * RAG 查詢端點
     */
    @PostMapping("/query")
    public ResponseEntity<RAGResponse> query(@RequestBody RAGQueryRequest request) {
        try {
            RAGResponse response = ragService.query(request.getQuestion());
            return ResponseEntity.ok(response);
        } catch (Exception e) {
            log.error("RAG query failed", e);
            return ResponseEntity.badRequest()
                .body(RAGResponse.builder()
                    .question(request.getQuestion())
                    .error("查詢處理失敗：" + e.getMessage())
                    .timestamp(LocalDateTime.now())
                    .build());
        }
    }
    
    /**
     * 添加文檔端點
     */
    @PostMapping("/documents")
    public ResponseEntity<ApiResponse> addDocuments(
            @RequestParam("files") List<MultipartFile> files) {
        
        try {
            List<Resource> resources = files.stream()
                .map(this::convertToResource)
                .collect(Collectors.toList());
            
            ragService.addDocuments(resources);
            
            return ResponseEntity.ok(ApiResponse.success(
                String.format("成功添加 %d 個文檔到知識庫", files.size())));
                
        } catch (Exception e) {
            log.error("Failed to add documents", e);
            return ResponseEntity.badRequest()
                .body(ApiResponse.error("文檔添加失敗：" + e.getMessage()));
        }
    }
    
    /**
     * 知識庫統計端點
     */
    @GetMapping("/stats")
    public ResponseEntity<KnowledgeBaseStats> getStats() {
        // 實現知識庫統計邏輯
        KnowledgeBaseStats stats = KnowledgeBaseStats.builder()
            .totalDocuments(1000)
            .totalChunks(5000)
            .lastUpdated(LocalDateTime.now())
            .build();
        
        return ResponseEntity.ok(stats);
    }
}
```

---

## 📝 本章重點回顧

1. **RAG 核心概念**：理解了檢索增強生成的基本原理和企業價值
2. **系統架構設計**：掌握了完整的 RAG 系統分層架構
3. **工作流程詳解**：學會了從資料準備到查詢處理的完整流程
4. **Spring AI 實現**：完成了基於 Spring AI 的 RAG 系統實現
5. **API 介面設計**：建立了完整的 RAG 服務 REST API

### 技術要點總結

| 技術點 | 重要性 | 實現難度 | 企業價值 |
|--------|--------|----------|----------|
| **RAG 架構設計** | ⭐⭐⭐ | 中 | 系統基礎 |
| **文檔處理流程** | ⭐⭐⭐ | 中 | 資料品質 |
| **向量檢索** | ⭐⭐⭐ | 高 | 檢索準確性 |
| **上下文組裝** | ⭐⭐ | 中 | 回應品質 |
| **API 設計** | ⭐⭐ | 低 | 系統整合 |

### 最佳實踐建議

1. **文檔品質**：確保輸入文檔的品質和結構化程度
2. **分塊策略**：根據文檔類型選擇合適的分塊大小和重疊度
3. **檢索優化**：調整相似性閾值和檢索數量以平衡準確性和效能
4. **提示詞設計**：設計清晰的提示詞模板以提高生成品質
5. **效能監控**：建立完整的 RAG 系統效能監控機制

### 下一步學習方向

在下一章中，我們將深入學習如何將內容向量化，包括：
- 不同嵌入模型的選擇和比較
- 向量化的最佳實踐
- 向量品質評估和優化
- 多語言向量化處理

---

**參考資料：**
- [Spring AI RAG Documentation](https://docs.spring.io/spring-ai/reference/api/vectordbs.html)
- [Retrieval-Augmented Generation Paper](https://arxiv.org/abs/2005.11401)
- [Vector Database Best Practices](https://www.pinecone.io/learn/vector-database/)
- [RAG System Design Patterns](https://blog.langchain.dev/rag-from-scratch/)