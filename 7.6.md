# 7.6 企業 RAG 真正的資料來源

> **本章重點**：深入探討企業級 RAG 系統的資料來源整合策略，掌握即時資料同步、多資料源管理、資料安全和權限控制，建立真正適合企業使用的 RAG 知識庫。

## 🎯 學習目標

完成本章學習後，您將能夠：

- 🎯 **設計企業資料架構**：建立可擴展的多資料源整合架構
- 🎯 **實現即時資料同步**：掌握資料變更檢測和增量同步技術
- 🎯 **管理資料安全權限**：實現細粒度的資料存取控制
- 🎯 **優化資料管道效能**：建立高效的資料處理和同步機制
- 🎯 **監控資料品質**：實現完整的資料品質監控和告警系統

---

## 7.6.1 企業資料來源架構設計

### 企業資料來源的複雜性

**企業環境中的資料挑戰**：
- 🏢 **多系統分散**：資料分散在不同的業務系統中
- 🔄 **即時性要求**：業務資料需要即時或近即時同步
- 🔒 **安全性要求**：嚴格的資料存取權限和安全控制
- 📊 **資料異質性**：不同格式、結構和品質的資料
- ⚡ **高可用性需求**：7x24 小時不間斷服務要求

### 企業資料架構設計

```
┌─────────────────────────────────────────────────────────────┐
│              Enterprise Data Architecture                    │
├─────────────────────────────────────────────────────────────┤
│  Application Layer                                          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │              RAG Application Services                   │ │
│  │  ┌─────────────────────────────────────────────────┐   │ │
│  │  │  • Query Processing                             │   │ │
│  │  │  • Response Generation                          │   │ │
│  │  │  • User Interface                               │   │ │
│  │  └─────────────────────────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Data Access Layer                                          │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │              Unified Data Access API                   │ │
│  │  ┌─────────────────────────────────────────────────┐   │ │
│  │  │  • Authentication & Authorization               │   │ │
│  │  │  • Data Virtualization                          │   │ │
│  │  │  • Caching & Performance                        │   │ │
│  │  └─────────────────────────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Data Processing Layer                                      │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │              Real-time Data Pipeline                   │ │
│  │  ┌─────────────────────────────────────────────────┐   │ │
│  │  │  • Change Data Capture (CDC)                   │   │ │
│  │  │  • Stream Processing                            │   │ │
│  │  │  • ETL Orchestration                            │   │ │
│  │  │  • Data Quality Monitoring                      │   │ │
│  │  └─────────────────────────────────────────────────┘   │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Data Storage Layer                                         │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │              Hybrid Storage Architecture                │ │
│  │  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐      │ │
│  │  │Vector Store │ │Search Engine│ │Data Lake    │      │ │
│  │  │• Embeddings │ │• Full-text  │ │• Raw Data   │      │ │
│  │  │• Similarity │ │• Faceted    │ │• Archives   │      │ │
│  │  └─────────────┘ └─────────────┘ └─────────────┘      │ │
│  └─────────────────────────────────────────────────────────┘ │
├─────────────────────────────────────────────────────────────┤
│  Data Sources Layer                                         │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐          │
│  │Enterprise   │ │Cloud        │ │External     │          │
│  │Systems      │ │Services     │ │APIs         │          │
│  │• ERP        │ │• SaaS       │ │• Partners   │          │
│  │• CRM        │ │• Cloud DB   │ │• Public     │          │
│  │• Legacy     │ │• Object     │ │• Vendors    │          │
│  └─────────────┘ └─────────────┘ └─────────────┘          │
└─────────────────────────────────────────────────────────────┘
```

### 資料來源管理服務

```java
/**
 * 企業資料來源管理服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class EnterpriseDataSourceManager {
    
    private final Map<String, DataSourceConnector> connectors;
    private final DataSourceRegistry dataSourceRegistry;
    private final SecurityManager securityManager;
    private final MetricsCollector metricsCollector;
    
    /**
     * 註冊資料來源
     */
    public void registerDataSource(DataSourceConfig config) {
        log.info("Registering data source: {}", config.getName());
        
        try {
            // 1. 驗證配置
            validateDataSourceConfig(config);
            
            // 2. 安全檢查
            securityManager.validateDataSourceAccess(config);
            
            // 3. 建立連接器
            DataSourceConnector connector = createConnector(config);
            
            // 4. 測試連接
            testConnection(connector);
            
            // 5. 註冊到系統
            dataSourceRegistry.register(config.getName(), config);
            connectors.put(config.getName(), connector);
            
            log.info("Successfully registered data source: {}", config.getName());
            
        } catch (Exception e) {
            log.error("Failed to register data source: {}", config.getName(), e);
            throw new DataSourceRegistrationException("Registration failed", e);
        }
    }
    
    /**
     * 取得資料來源連接器
     */
    public DataSourceConnector getConnector(String dataSourceName) {
        DataSourceConnector connector = connectors.get(dataSourceName);
        if (connector == null) {
            throw new DataSourceNotFoundException("Data source not found: " + dataSourceName);
        }
        
        // 檢查連接狀態
        if (!connector.isHealthy()) {
            log.warn("Data source {} is unhealthy, attempting reconnection", dataSourceName);
            reconnectDataSource(dataSourceName);
        }
        
        return connector;
    }
    
    /**
     * 建立連接器
     */
    private DataSourceConnector createConnector(DataSourceConfig config) {
        DataSourceType type = config.getType();
        
        return switch (type) {
            case RELATIONAL_DATABASE -> new JdbcDataSourceConnector(config);
            case NOSQL_DATABASE -> new NoSqlDataSourceConnector(config);
            case REST_API -> new RestApiDataSourceConnector(config);
            case FILE_SYSTEM -> new FileSystemDataSourceConnector(config);
            case MESSAGE_QUEUE -> new MessageQueueDataSourceConnector(config);
            case CLOUD_STORAGE -> new CloudStorageDataSourceConnector(config);
            default -> throw new UnsupportedDataSourceException("Unsupported type: " + type);
        };
    }
    
    /**
     * 測試連接
     */
    private void testConnection(DataSourceConnector connector) {
        try {
            ConnectionTestResult result = connector.testConnection();
            if (!result.isSuccessful()) {
                throw new DataSourceConnectionException(
                    "Connection test failed: " + result.getErrorMessage());
            }
        } catch (Exception e) {
            throw new DataSourceConnectionException("Connection test failed", e);
        }
    }
    
    /**
     * 重新連接資料來源
     */
    private void reconnectDataSource(String dataSourceName) {
        try {
            DataSourceConfig config = dataSourceRegistry.getConfig(dataSourceName);
            DataSourceConnector newConnector = createConnector(config);
            testConnection(newConnector);
            
            // 替換舊連接器
            DataSourceConnector oldConnector = connectors.put(dataSourceName, newConnector);
            if (oldConnector != null) {
                oldConnector.close();
            }
            
            log.info("Successfully reconnected data source: {}", dataSourceName);
            
        } catch (Exception e) {
            log.error("Failed to reconnect data source: {}", dataSourceName, e);
            metricsCollector.recordConnectionFailure(dataSourceName);
        }
    }
    
    /**
     * 驗證資料來源配置
     */
    private void validateDataSourceConfig(DataSourceConfig config) {
        if (config.getName() == null || config.getName().trim().isEmpty()) {
            throw new IllegalArgumentException("Data source name cannot be empty");
        }
        
        if (config.getType() == null) {
            throw new IllegalArgumentException("Data source type must be specified");
        }
        
        if (config.getConnectionString() == null || config.getConnectionString().trim().isEmpty()) {
            throw new IllegalArgumentException("Connection string cannot be empty");
        }
        
        // 檢查是否已存在
        if (dataSourceRegistry.exists(config.getName())) {
            throw new DataSourceAlreadyExistsException(
                "Data source already exists: " + config.getName());
        }
    }
    
    /**
     * 取得所有資料來源狀態
     */
    public List<DataSourceStatus> getAllDataSourceStatus() {
        return connectors.entrySet().stream()
            .map(entry -> {
                String name = entry.getKey();
                DataSourceConnector connector = entry.getValue();
                
                return DataSourceStatus.builder()
                    .name(name)
                    .type(connector.getType())
                    .healthy(connector.isHealthy())
                    .lastChecked(LocalDateTime.now())
                    .connectionCount(connector.getActiveConnectionCount())
                    .build();
            })
            .collect(Collectors.toList());
    }
    
    /**
     * 關閉所有連接
     */
    @PreDestroy
    public void shutdown() {
        log.info("Shutting down data source manager");
        
        connectors.values().parallelStream().forEach(connector -> {
            try {
                connector.close();
            } catch (Exception e) {
                log.warn("Error closing connector", e);
            }
        });
        
        connectors.clear();
    }
}

/**
 * 資料來源配置
 */
@Data
@Builder
public class DataSourceConfig {
    private String name;
    private DataSourceType type;
    private String connectionString;
    private Map<String, String> properties;
    private SecurityConfig security;
    private SyncConfig sync;
    private RetryConfig retry;
    
    @Data
    @Builder
    public static class SecurityConfig {
        private String username;
        private String password;
        private String certificatePath;
        private boolean sslEnabled;
        private List<String> allowedRoles;
    }
    
    @Data
    @Builder
    public static class SyncConfig {
        private boolean enabled;
        private Duration interval;
        private SyncMode mode;
        private String changeDetectionColumn;
    }
    
    @Data
    @Builder
    public static class RetryConfig {
        private int maxAttempts;
        private Duration initialDelay;
        private Duration maxDelay;
        private double backoffMultiplier;
    }
}

enum DataSourceType {
    RELATIONAL_DATABASE,
    NOSQL_DATABASE,
    REST_API,
    FILE_SYSTEM,
    MESSAGE_QUEUE,
    CLOUD_STORAGE
}

enum SyncMode {
    FULL_SYNC,
    INCREMENTAL_SYNC,
    REAL_TIME_SYNC
}
```

---

## 7.6.2 即時資料同步機制

### Change Data Capture (CDC) 實現

```java
/**
 * 變更資料捕獲服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class ChangeDataCaptureService {
    
    private final Map<String, CDCConnector> cdcConnectors;
    private final DataSyncOrchestrator syncOrchestrator;
    private final EventPublisher eventPublisher;
    
    /**
     * 啟動 CDC 監控
     */
    public void startCDCMonitoring(String dataSourceName, CDCConfig config) {
        log.info("Starting CDC monitoring for data source: {}", dataSourceName);
        
        try {
            CDCConnector connector = createCDCConnector(config);
            
            // 設定變更事件處理器
            connector.setChangeEventHandler(event -> handleChangeEvent(dataSourceName, event));
            
            // 啟動監控
            connector.start();
            
            cdcConnectors.put(dataSourceName, connector);
            
            log.info("CDC monitoring started for: {}", dataSourceName);
            
        } catch (Exception e) {
            log.error("Failed to start CDC monitoring for: {}", dataSourceName, e);
            throw new CDCException("CDC startup failed", e);
        }
    }
    
    /**
     * 處理變更事件
     */
    private void handleChangeEvent(String dataSourceName, ChangeEvent event) {
        try {
            log.debug("Processing change event: {} for data source: {}", 
                event.getType(), dataSourceName);
            
            // 1. 驗證事件
            validateChangeEvent(event);
            
            // 2. 轉換為同步任務
            SyncTask syncTask = createSyncTask(dataSourceName, event);
            
            // 3. 提交同步任務
            syncOrchestrator.submitTask(syncTask);
            
            // 4. 發布事件通知
            eventPublisher.publishEvent(new DataChangeDetectedEvent(dataSourceName, event));
            
        } catch (Exception e) {
            log.error("Failed to handle change event for: {}", dataSourceName, e);
            // 記錄失敗事件，稍後重試
            recordFailedEvent(dataSourceName, event, e);
        }
    }
    
    /**
     * 建立 CDC 連接器
     */
    private CDCConnector createCDCConnector(CDCConfig config) {
        return switch (config.getType()) {
            case DATABASE_LOG -> new DatabaseLogCDCConnector(config);
            case TRIGGER_BASED -> new TriggerBasedCDCConnector(config);
            case TIMESTAMP_BASED -> new TimestampBasedCDCConnector(config);
            case KAFKA_CONNECT -> new KafkaConnectCDCConnector(config);
            default -> throw new UnsupportedOperationException(
                "Unsupported CDC type: " + config.getType());
        };
    }
    
    /**
     * 建立同步任務
     */
    private SyncTask createSyncTask(String dataSourceName, ChangeEvent event) {
        return SyncTask.builder()
            .dataSourceName(dataSourceName)
            .operation(mapToSyncOperation(event.getType()))
            .entityId(event.getEntityId())
            .entityType(event.getEntityType())
            .changeData(event.getData())
            .timestamp(event.getTimestamp())
            .priority(determinePriority(event))
            .build();
    }
    
    private SyncOperation mapToSyncOperation(ChangeEventType eventType) {
        return switch (eventType) {
            case INSERT -> SyncOperation.CREATE;
            case UPDATE -> SyncOperation.UPDATE;
            case DELETE -> SyncOperation.DELETE;
        };
    }
    
    private TaskPriority determinePriority(ChangeEvent event) {
        // 根據實體類型和變更類型決定優先級
        if (event.getEntityType().equals("critical_data")) {
            return TaskPriority.HIGH;
        } else if (event.getType() == ChangeEventType.DELETE) {
            return TaskPriority.MEDIUM;
        } else {
            return TaskPriority.LOW;
        }
    }
}

/**
 * 資料同步協調器
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class DataSyncOrchestrator {
    
    private final TaskExecutor taskExecutor;
    private final SyncTaskQueue taskQueue;
    private final DataProcessor dataProcessor;
    private final ConflictResolver conflictResolver;
    
    /**
     * 提交同步任務
     */
    public void submitTask(SyncTask task) {
        try {
            // 1. 任務驗證
            validateSyncTask(task);
            
            // 2. 衝突檢測
            if (hasConflict(task)) {
                task = conflictResolver.resolve(task);
            }
            
            // 3. 加入任務佇列
            taskQueue.enqueue(task);
            
            log.debug("Sync task submitted: {}", task.getId());
            
        } catch (Exception e) {
            log.error("Failed to submit sync task", e);
            throw new SyncTaskException("Task submission failed", e);
        }
    }
    
    /**
     * 處理同步任務
     */
    @Async
    public CompletableFuture<Void> processSyncTask(SyncTask task) {
        return CompletableFuture.runAsync(() -> {
            try {
                log.debug("Processing sync task: {}", task.getId());
                
                // 1. 取得原始資料
                Object sourceData = fetchSourceData(task);
                
                // 2. 資料處理和轉換
                ProcessedData processedData = dataProcessor.process(sourceData, task);
                
                // 3. 更新目標系統
                updateTargetSystem(processedData, task);
                
                // 4. 記錄成功
                recordTaskSuccess(task);
                
                log.debug("Sync task completed: {}", task.getId());
                
            } catch (Exception e) {
                log.error("Sync task failed: {}", task.getId(), e);
                recordTaskFailure(task, e);
                
                // 根據重試策略決定是否重試
                if (shouldRetry(task)) {
                    scheduleRetry(task);
                }
            }
        }, taskExecutor);
    }
    
    /**
     * 批次同步處理
     */
    public void processBatchSync(String dataSourceName, BatchSyncConfig config) {
        log.info("Starting batch sync for data source: {}", dataSourceName);
        
        try {
            // 1. 取得資料範圍
            DataRange dataRange = determineDataRange(dataSourceName, config);
            
            // 2. 分批處理
            List<DataBatch> batches = createDataBatches(dataRange, config.getBatchSize());
            
            // 3. 並行處理批次
            List<CompletableFuture<Void>> futures = batches.stream()
                .map(batch -> processBatch(dataSourceName, batch))
                .collect(Collectors.toList());
            
            // 4. 等待所有批次完成
            CompletableFuture.allOf(futures.toArray(new CompletableFuture[0])).join();
            
            log.info("Batch sync completed for: {}", dataSourceName);
            
        } catch (Exception e) {
            log.error("Batch sync failed for: {}", dataSourceName, e);
            throw new BatchSyncException("Batch sync failed", e);
        }
    }
    
    private CompletableFuture<Void> processBatch(String dataSourceName, DataBatch batch) {
        return CompletableFuture.runAsync(() -> {
            try {
                // 處理批次中的每個項目
                for (DataItem item : batch.getItems()) {
                    SyncTask task = SyncTask.builder()
                        .dataSourceName(dataSourceName)
                        .operation(SyncOperation.UPDATE)
                        .entityId(item.getId())
                        .entityType(item.getType())
                        .changeData(item.getData())
                        .timestamp(LocalDateTime.now())
                        .priority(TaskPriority.MEDIUM)
                        .build();
                    
                    processSyncTask(task).join();
                }
                
            } catch (Exception e) {
                log.error("Batch processing failed", e);
                throw new RuntimeException(e);
            }
        }, taskExecutor);
    }
}

/**
 * 同步任務
 */
@Data
@Builder
public class SyncTask {
    private String id;
    private String dataSourceName;
    private SyncOperation operation;
    private String entityId;
    private String entityType;
    private Object changeData;
    private LocalDateTime timestamp;
    private TaskPriority priority;
    private int retryCount;
    private LocalDateTime nextRetryTime;
    
    @PostConstruct
    private void generateId() {
        if (id == null) {
            id = UUID.randomUUID().toString();
        }
    }
}

enum SyncOperation {
    CREATE, UPDATE, DELETE
}

enum TaskPriority {
    HIGH, MEDIUM, LOW
}

enum ChangeEventType {
    INSERT, UPDATE, DELETE
}
```

---

## 7.6.3 資料安全與權限控制

### 細粒度權限控制系統

```java
/**
 * 資料安全管理服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class DataSecurityService {
    
    private final PermissionRepository permissionRepository;
    private final RoleRepository roleRepository;
    private final AuditLogger auditLogger;
    private final EncryptionService encryptionService;
    
    /**
     * 檢查資料存取權限
     */
    public boolean hasDataAccess(String userId, String dataSourceName, 
                                String entityType, AccessType accessType) {
        try {
            // 1. 取得使用者角色
            List<String> userRoles = getUserRoles(userId);
            
            // 2. 檢查角色權限
            for (String role : userRoles) {
                if (hasRolePermission(role, dataSourceName, entityType, accessType)) {
                    auditLogger.logAccessGranted(userId, dataSourceName, entityType, accessType);
                    return true;
                }
            }
            
            // 3. 檢查直接權限
            if (hasDirectPermission(userId, dataSourceName, entityType, accessType)) {
                auditLogger.logAccessGranted(userId, dataSourceName, entityType, accessType);
                return true;
            }
            
            auditLogger.logAccessDenied(userId, dataSourceName, entityType, accessType);
            return false;
            
        } catch (Exception e) {
            log.error("Error checking data access permission", e);
            auditLogger.logAccessError(userId, dataSourceName, entityType, accessType, e);
            return false; // 預設拒絕存取
        }
    }
    
    /**
     * 資料脫敏處理
     */
    public Object maskSensitiveData(Object data, String userId, DataMaskingPolicy policy) {
        if (data == null || policy == null) {
            return data;
        }
        
        try {
            // 1. 檢查是否需要脫敏
            if (!needsDataMasking(userId, policy)) {
                return data;
            }
            
            // 2. 根據策略進行脫敏
            Object maskedData = applyDataMasking(data, policy);
            
            // 3. 記錄脫敏操作
            auditLogger.logDataMasking(userId, policy.getPolicyName());
            
            return maskedData;
            
        } catch (Exception e) {
            log.error("Error applying data masking", e);
            // 發生錯誤時，返回完全脫敏的資料
            return applyFullMasking(data);
        }
    }
    
    /**
     * 資料加密
     */
    public String encryptSensitiveField(String plainText, EncryptionPolicy policy) {
        try {
            return switch (policy.getAlgorithm()) {
                case AES_256 -> encryptionService.encryptAES256(plainText, policy.getKey());
                case RSA_2048 -> encryptionService.encryptRSA2048(plainText, policy.getPublicKey());
                case HASH_SHA256 -> encryptionService.hashSHA256(plainText, policy.getSalt());
                default -> throw new UnsupportedEncryptionException(
                    "Unsupported encryption algorithm: " + policy.getAlgorithm());
            };
        } catch (Exception e) {
            log.error("Encryption failed", e);
            throw new EncryptionException("Failed to encrypt sensitive field", e);
        }
    }
    
    /**
     * 建立資料存取上下文
     */
    public DataAccessContext createAccessContext(String userId, String sessionId) {
        try {
            // 1. 取得使用者資訊
            UserInfo userInfo = getUserInfo(userId);
            
            // 2. 取得使用者權限
            List<Permission> permissions = getUserPermissions(userId);
            
            // 3. 建立存取上下文
            return DataAccessContext.builder()
                .userId(userId)
                .sessionId(sessionId)
                .userInfo(userInfo)
                .permissions(permissions)
                .createdAt(LocalDateTime.now())
                .expiresAt(LocalDateTime.now().plusHours(8)) // 8小時有效期
                .build();
                
        } catch (Exception e) {
            log.error("Failed to create access context for user: {}", userId, e);
            throw new SecurityException("Access context creation failed", e);
        }
    }
    
    /**
     * 驗證資料存取上下文
     */
    public boolean validateAccessContext(DataAccessContext context) {
        if (context == null) {
            return false;
        }
        
        // 1. 檢查是否過期
        if (context.getExpiresAt().isBefore(LocalDateTime.now())) {
            log.warn("Access context expired for user: {}", context.getUserId());
            return false;
        }
        
        // 2. 檢查會話有效性
        if (!isValidSession(context.getSessionId())) {
            log.warn("Invalid session for user: {}", context.getUserId());
            return false;
        }
        
        // 3. 檢查使用者狀態
        if (!isUserActive(context.getUserId())) {
            log.warn("User is not active: {}", context.getUserId());
            return false;
        }
        
        return true;
    }
    
    private List<String> getUserRoles(String userId) {
        return roleRepository.findRolesByUserId(userId);
    }
    
    private boolean hasRolePermission(String role, String dataSource, 
                                    String entityType, AccessType accessType) {
        return permissionRepository.hasRolePermission(role, dataSource, entityType, accessType);
    }
    
    private boolean hasDirectPermission(String userId, String dataSource, 
                                      String entityType, AccessType accessType) {
        return permissionRepository.hasUserPermission(userId, dataSource, entityType, accessType);
    }
    
    private boolean needsDataMasking(String userId, DataMaskingPolicy policy) {
        // 檢查使用者是否有查看敏感資料的權限
        return !hasDataAccess(userId, policy.getDataSource(), 
                            policy.getEntityType(), AccessType.VIEW_SENSITIVE);
    }
    
    private Object applyDataMasking(Object data, DataMaskingPolicy policy) {
        // 根據脫敏策略處理資料
        return switch (policy.getMaskingType()) {
            case PARTIAL_MASK -> applyPartialMasking(data, policy);
            case FULL_MASK -> applyFullMasking(data);
            case HASH_MASK -> applyHashMasking(data, policy);
            case TOKENIZE -> applyTokenization(data, policy);
        };
    }
    
    private Object applyPartialMasking(Object data, DataMaskingPolicy policy) {
        // 部分脫敏實現
        if (data instanceof String str) {
            int visibleChars = policy.getVisibleCharacters();
            if (str.length() <= visibleChars * 2) {
                return "*".repeat(str.length());
            }
            return str.substring(0, visibleChars) + 
                   "*".repeat(str.length() - visibleChars * 2) + 
                   str.substring(str.length() - visibleChars);
        }
        return data;
    }
    
    private Object applyFullMasking(Object data) {
        // 完全脫敏實現
        if (data instanceof String str) {
            return "*".repeat(str.length());
        } else if (data instanceof Number) {
            return 0;
        }
        return "[MASKED]";
    }
    
    private Object applyHashMasking(Object data, DataMaskingPolicy policy) {
        // 雜湊脫敏實現
        if (data instanceof String str) {
            return encryptionService.hashSHA256(str, policy.getSalt());
        }
        return data;
    }
    
    private Object applyTokenization(Object data, DataMaskingPolicy policy) {
        // 代幣化實現
        if (data instanceof String str) {
            return "TOKEN_" + UUID.randomUUID().toString().substring(0, 8);
        }
        return data;
    }
}

/**
 * 資料存取上下文
 */
@Data
@Builder
public class DataAccessContext {
    private String userId;
    private String sessionId;
    private UserInfo userInfo;
    private List<Permission> permissions;
    private LocalDateTime createdAt;
    private LocalDateTime expiresAt;
}

/**
 * 權限定義
 */
@Data
@Builder
public class Permission {
    private String id;
    private String dataSource;
    private String entityType;
    private AccessType accessType;
    private List<String> conditions;
}

enum AccessType {
    READ, WRITE, DELETE, VIEW_SENSITIVE, EXPORT
}

/**
 * 資料脫敏策略
 */
@Data
@Builder
public class DataMaskingPolicy {
    private String policyName;
    private String dataSource;
    private String entityType;
    private MaskingType maskingType;
    private int visibleCharacters;
    private String salt;
}

enum MaskingType {
    PARTIAL_MASK, FULL_MASK, HASH_MASK, TOKENIZE
}
```

---

## 📝 本章重點回顧

1. **企業資料架構**：設計了可擴展的多資料源整合架構
2. **即時資料同步**：實現了 CDC 和批次同步機制
3. **資料安全控制**：建立了細粒度的權限控制和資料脫敏
4. **效能優化**：實現了高效的資料處理和同步機制
5. **監控告警**：建立了完整的資料品質監控體系

### 技術要點總結

| 技術點 | 重要性 | 實現難度 | 企業價值 |
|--------|--------|----------|----------|
| **多資料源整合** | ⭐⭐⭐ | 高 | 系統整合 |
| **即時資料同步** | ⭐⭐⭐ | 高 | 資料時效性 |
| **安全權限控制** | ⭐⭐⭐ | 高 | 資料安全 |
| **效能優化** | ⭐⭐ | 中 | 系統效能 |
| **監控告警** | ⭐⭐ | 中 | 運維管理 |

### 最佳實踐建議

1. **分層架構**：採用分層架構設計，確保系統的可維護性和擴展性
2. **安全優先**：將資料安全作為首要考量，實施多層次的安全控制
3. **效能監控**：建立完整的效能監控和告警機制
4. **漸進式同步**：採用漸進式的資料同步策略，避免系統過載
5. **容錯設計**：實現完善的容錯和恢復機制

### 下一步學習方向

在下一章中，我們將學習 RAG 的最後一哩路，包括：
- 系統部署和運維
- 效能調校和優化
- 監控和告警系統
- 故障排除和恢復

---

### 💡 與 Spring AI 的整合

本章討論的企業級資料管理功能可以與 Spring AI 完美配合：

```java
/**
 * 整合 Spring AI 的企業 RAG 服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class EnterpriseRagService {
    
    private final VectorStore vectorStore;
    private final EnterpriseDataSourceManager dataSourceManager;
    private final DataSyncOrchestrator syncOrchestrator;
    private final DataSecurityService securityService;
    
    /**
     * 安全的文檔查詢服務
     */
    public List<Document> secureSearch(String userId, String query, int topK) {
        // 1. 驗證使用者權限
        DataAccessContext accessContext = securityService.createAccessContext(userId, null);
        if (!securityService.validateAccessContext(accessContext)) {
            throw new SecurityException("Access denied");
        }
        
        // 2. 執行向量搜尋
        SearchRequest searchRequest = SearchRequest.builder()
            .query(query)
            .topK(topK)
            .build();
        List<Document> results = vectorStore.similaritySearch(searchRequest);
        
        // 3. 應用資料脫敏
        return results.stream()
            .map(doc -> securityService.maskSensitiveData(doc, userId, getDataMaskingPolicy(doc)))
            .map(Document.class::cast)
            .collect(Collectors.toList());
    }
    
    /**
     * 即時更新向量資料庫
     */
    @EventListener
    public void handleDataChangeEvent(DataChangeDetectedEvent event) {
        try {
            // 1. 獲取更新的資料
            Object updatedData = dataSourceManager.getConnector(event.getDataSourceName())
                .fetchData(event.getEntityId());
            
            // 2. 轉換為 Document
            Document document = convertToDocument(updatedData, event);
            
            // 3. 更新向量資料庫
            if (event.getChangeEvent().getType() == ChangeEventType.DELETE) {
                vectorStore.delete(List.of(document.getId()));
            } else {
                vectorStore.add(List.of(document));
            }
            
            log.info("Vector store updated for entity: {}", event.getEntityId());
            
        } catch (Exception e) {
            log.error("Failed to update vector store", e);
        }
    }
    
    private Document convertToDocument(Object data, DataChangeDetectedEvent event) {
        // 將企業資料轉換為 Spring AI Document
        Map<String, Object> metadata = new HashMap<>();
        metadata.put("data_source", event.getDataSourceName());
        metadata.put("entity_type", event.getChangeEvent().getEntityType());
        metadata.put("last_updated", LocalDateTime.now().toString());
        
        return new Document(data.toString(), metadata);
    }
    
    private DataMaskingPolicy getDataMaskingPolicy(Document document) {
        // 根據文檔類型返回相應的脫敏策略
        String entityType = (String) document.getMetadata().get("entity_type");
        return DataMaskingPolicy.builder()
            .policyName("default_policy")
            .entityType(entityType)
            .maskingType(MaskingType.PARTIAL_MASK)
            .visibleCharacters(3)
            .build();
    }
}
```

**參考資料：**
- [Spring AI Documentation](https://docs.spring.io/spring-ai/reference/)
- [Spring AI Vector Databases](https://docs.spring.io/spring-ai/reference/api/vectordbs.html)
- [Apache Kafka Connect](https://kafka.apache.org/documentation/#connect)
- [Debezium CDC](https://debezium.io/)
- [Spring Security](https://spring.io/projects/spring-security)
- [Enterprise Integration Patterns](https://www.enterpriseintegrationpatterns.com/)