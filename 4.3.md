# 4.3 如何像 ChatGPT 產生流式輸出

> **本章重點**：學習實現 AI 流式輸出功能，讓使用者體驗如同 ChatGPT 般的即時回應效果，大幅提升應用程式的互動性和使用者滿意度。

## 🎯 學習目標

完成本章學習後，您將能夠：

- 🎯 **理解流式輸出原理**：掌握 Server-Sent Events (SSE) 的工作機制
- 🎯 **實現 AI 流式回應**：使用 ChatClient 建立流式 AI 對話功能
- 🎯 **優化使用者體驗**：讓 AI 回應即時顯示，避免長時間等待
- 🎯 **處理流式資料**：掌握 Reactive Streams 和背壓處理
- 🎯 **前端整合技術**：學會使用 EventSource 接收流式資料

---

## 4.3.1 為什麼需要流式輸出？

### 使用者體驗的革命

![流式輸出](https://ithelp.ithome.com.tw/upload/images/20240810/20161290gaE6Faz85x.jpg)

由於 AI 產生內容得靠伺服器運算後產生結果，資料多的話得等不少時間，若能產生資料後馬上分段送出，可大大提升使用者感受。

**傳統同步回應 vs 流式輸出**：

```
傳統方式：
使用者提問 → [等待 10 秒] → 完整回應顯示

流式輸出：
使用者提問 → [0.5秒] 開始顯示 → [持續更新] → 完整回應
```

**流式輸出的優勢**：
- ⚡ **即時反饋**：使用者立即看到 AI 開始回應
- 🎯 **降低焦慮**：避免長時間等待造成的不確定感
- 📱 **更好的互動性**：類似真人對話的體驗
- 🚀 **感知效能提升**：雖然總時間相同，但感覺更快
- 💡 **早期中斷**：使用者可以提前判斷回應品質

### Server-Sent Events (SSE) 技術

要達到這種效果主要靠的是 **Server-Sent Events (SSE)** 伺服器主動推播協定：

**SSE 特點**：
- 📡 **單向通訊**：伺服器向客戶端推送資料
- 🔄 **自動重連**：連線中斷時自動重新連接
- 🌐 **標準協定**：基於 HTTP，廣泛支援
- 💻 **瀏覽器原生支援**：使用 EventSource API

---

## 4.3.2 ChatClient 流式輸出實作

### 基本流式輸出

Spring AI 1.0 GA 的 ChatClient 提供了優雅的流式輸出 API：

```java
package com.example.controller;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.chat.client.ChatClient;
import org.springframework.http.MediaType;
import org.springframework.web.bind.annotation.*;
import reactor.core.publisher.Flux;

@RestController
@RequestMapping("/api/ai")
@RequiredArgsConstructor
@Slf4j
public class StreamingAiController {
    
    private final ChatClient chatClient;

    /**
     * 基本流式 AI 對話
     * @param prompt 使用者輸入的提示詞
     * @return 流式字串回應
     */
    @GetMapping(value = "/chat/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> chatStream(@RequestParam String prompt) {
        log.info("開始流式對話：{}", prompt);
        
        return chatClient.prompt()
                .user(prompt)
                .stream()
                .content();
    }
    
    /**
     * 帶系統提示詞的流式對話
     * @param prompt 使用者輸入
     * @param system 系統提示詞
     * @return 流式回應
     */
    @GetMapping(value = "/chat/stream/system", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> chatStreamWithSystem(
            @RequestParam String prompt,
            @RequestParam(defaultValue = "你是一個友善且專業的 AI 助手") String system) {
        
        return chatClient.prompt()
                .system(system)
                .user(prompt)
                .stream()
                .content()
                .doOnSubscribe(subscription -> 
                    log.info("開始流式對話 - 系統：{}, 使用者：{}", system, prompt))
                .doOnComplete(() -> 
                    log.info("流式對話完成"));
    }
}
```

### 程式碼重點說明

**核心 API**：
- **`stream()`**: 替代 `call()` 來啟用流式輸出
- **`content()`**: 返回 `Flux<String>` 流式字串內容
- **`produces = MediaType.TEXT_EVENT_STREAM_VALUE`**: 指定回應格式為 SSE

**Reactive 操作符**：
- **`doOnSubscribe()`**: 訂閱時執行的動作
- **`doOnComplete()`**: 完成時執行的動作
- **`doOnNext()`**: 每個元素發出時執行的動作

---

## 4.3.3 進階流式輸出控制

### 完整 ChatResponse 流

如果需要更多控制選項，可以使用完整的 ChatResponse 流：

```java
@GetMapping(value = "/chat/stream/response", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<ChatResponse> chatStreamResponse(@RequestParam String prompt) {
    return chatClient.prompt()
            .user(prompt)
            .stream()
            .chatResponse()
            .doOnNext(response -> {
                // 可以存取完整的回應資訊
                log.debug("收到回應片段：{}", response.getResult().getOutput().getContent());
                log.debug("使用的模型：{}", response.getMetadata().getModel());
            });
}
```

### 自定義流式輸出處理

```java
@GetMapping(value = "/chat/stream/custom", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<String> chatStreamCustom(@RequestParam String prompt) {
    return chatClient.prompt()
            .user(prompt)
            .stream()
            .content()
            .map(content -> {
                // 自定義處理每個流式片段
                return "🤖 AI: " + content;
            })
            .filter(content -> {
                // 過濾空內容
                return content != null && !content.trim().isEmpty();
            })
            .doOnNext(content -> {
                // 記錄每個片段
                log.debug("流式內容：{}", content);
            })
            .onErrorResume(error -> {
                log.error("流式輸出錯誤", error);
                return Flux.just("❌ 抱歉，發生錯誤：" + error.getMessage());
            });
}
```

### 結構化流式回應

```java
@Data
public class StreamChunk {
    private String content;
    private String timestamp;
    private String model;
    private boolean isComplete;
    
    public static StreamChunk of(String content, String model) {
        StreamChunk chunk = new StreamChunk();
        chunk.setContent(content);
        chunk.setTimestamp(Instant.now().toString());
        chunk.setModel(model);
        chunk.setComplete(false);
        return chunk;
    }
}

@GetMapping(value = "/chat/stream/structured", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<StreamChunk> chatStreamStructured(@RequestParam String prompt) {
    return chatClient.prompt()
            .user(prompt)
            .stream()
            .chatResponse()
            .map(response -> StreamChunk.of(
                response.getResult().getOutput().getContent(),
                response.getMetadata().getModel()
            ))
            .concatWith(Flux.just(new StreamChunk() {{
                setContent("");
                setComplete(true);
            }}));
}
```

---

## 4.3.4 使用 ChatModel 的流式輸出

### 底層 API 實現

如果直接使用 ChatModel，也可以實現流式輸出：

```java
package com.example.controller;

import lombok.RequiredArgsConstructor;
import org.springframework.ai.chat.model.StreamingChatModel;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.chat.prompt.PromptTemplate;
import org.springframework.http.MediaType;
import org.springframework.web.bind.annotation.*;
import reactor.core.publisher.Flux;

import java.util.Map;

@RestController
@RequestMapping("/api/model")
@RequiredArgsConstructor
public class StreamingModelController {
    
    private final StreamingChatModel streamingChatModel;

    /**
     * 使用 ChatModel 的基本流式輸出
     * @param prompt 使用者輸入
     * @return 流式回應
     */
    @GetMapping(value = "/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> modelStream(@RequestParam String prompt) {
        return streamingChatModel.stream(prompt)
                .map(chatResponse -> 
                    chatResponse.getResult().getOutput().getContent())
                .filter(content -> content != null && !content.isEmpty());
    }
    
    /**
     * 使用 PromptTemplate 的流式輸出
     * @param topic 話題
     * @param style 風格
     * @return 流式回應
     */
    @GetMapping(value = "/stream/template", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> modelStreamWithTemplate(
            @RequestParam String topic,
            @RequestParam(defaultValue = "專業") String style) {
        
        String template = "請以{style}的風格，詳細說明{topic}的相關知識";
        
        PromptTemplate promptTemplate = new PromptTemplate(template);
        Prompt prompt = promptTemplate.create(Map.of(
            "topic", topic,
            "style", style
        ));
        
        return streamingChatModel.stream(prompt)
                .map(chatResponse -> 
                    chatResponse.getResult().getOutput().getContent())
                .filter(content -> content != null && !content.isEmpty());
    }
}
```

---

## 4.3.5 應用程式配置

### 必要依賴

要使用 Spring AI 的流式輸出功能，必須包含 WebFlux 依賴：

```xml
<!-- 必須包含 WebFlux 以支援流式輸出 -->
<dependency>
    <groupId>org.springframework.boot</groupId>
    <artifactId>spring-boot-starter-webflux</artifactId>
</dependency>

<!-- Spring AI OpenAI Starter -->
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-openai-spring-boot-starter</artifactId>
</dependency>
```

> **重要提醒**：流式輸出僅支援 Reactive 架構。即使是命令式應用程式，也必須包含 Reactive 依賴才能使用此功能。

### Spring Boot 配置

確保在 `application.yml` 中正確設定字元編碼和流式選項：

```yaml
server:
  port: 8080
  servlet:
    encoding:
      charset: UTF-8
      enabled: true
      force: true

spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      base-url: https://api.openai.com
      chat:
        options:
          model: gpt-4o-mini
          temperature: 0.7
          max-completion-tokens: 1000
          stream-usage: true  # 在流式回應中包含使用量統計

# 日誌配置
logging:
  level:
    org.springframework.ai: DEBUG
    reactor.netty: INFO
    com.example: DEBUG
```

### 跨域配置（如需要）

```java
@Configuration
public class WebConfig implements WebMvcConfigurer {
    
    @Override
    public void addCorsMappings(CorsRegistry registry) {
        registry.addMapping("/api/**")
                .allowedOrigins("http://localhost:3000", "http://localhost:8081")
                .allowedMethods("GET", "POST", "PUT", "DELETE")
                .allowedHeaders("*")
                .allowCredentials(true);
    }
}
```

---

## 4.3.6 完整的聊天服務實作

### 聊天服務層

```java
package com.example.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.chat.client.ChatClient;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;

import java.time.Duration;

@Service
@RequiredArgsConstructor
@Slf4j
public class ChatService {
    
    private final ChatClient chatClient;
    
    /**
     * 流式聊天服務
     * @param userMessage 使用者訊息
     * @param systemPrompt 系統提示詞
     * @return 流式回應
     */
    public Flux<String> streamChat(String userMessage, String systemPrompt) {
        String defaultSystem = "你是一個友善且專業的 AI 助手，" +
                              "請用繁體中文回答，並提供有用的資訊。";
        
        return chatClient.prompt()
                .system(systemPrompt != null ? systemPrompt : defaultSystem)
                .user(userMessage)
                .stream()
                .content()
                .timeout(Duration.ofSeconds(30))  // 設定超時
                .retry(2)  // 重試機制
                .onErrorResume(error -> {
                    log.error("聊天流式輸出錯誤", error);
                    return Flux.just("❌ 抱歉，發生錯誤，請稍後再試。錯誤訊息：" + error.getMessage());
                })
                .doOnSubscribe(subscription -> 
                    log.info("開始流式聊天 - 使用者：{}", userMessage))
                .doOnComplete(() -> 
                    log.info("流式聊天完成"))
                .doOnError(error -> 
                    log.error("流式聊天發生錯誤：{}", error.getMessage()));
    }
    
    /**
     * 程式碼生成專用流式服務
     * @param description 程式需求描述
     * @param language 程式語言
     * @return 流式程式碼回應
     */
    public Flux<String> streamCodeGeneration(String description, String language) {
        String systemPrompt = String.format(
            "你是一個資深的 %s 開發專家。" +
            "請根據需求描述生成高品質、可執行的程式碼，" +
            "包含適當的註解和最佳實踐。" +
            "請只回傳程式碼，不要額外的說明文字。",
            language
        );
        
        return streamChat(description, systemPrompt);
    }
}
```

### 控制器整合

```java
package com.example.controller;

import com.example.service.ChatService;
import lombok.RequiredArgsConstructor;
import org.springframework.http.MediaType;
import org.springframework.web.bind.annotation.*;
import reactor.core.publisher.Flux;

@RestController
@RequestMapping("/api/chat")
@RequiredArgsConstructor
public class ChatController {
    
    private final ChatService chatService;

    /**
     * 通用流式聊天端點
     * @param prompt 使用者輸入
     * @param system 系統提示詞（可選）
     * @return 流式回應
     */
    @GetMapping(value = "/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> chat(
            @RequestParam String prompt,
            @RequestParam(required = false) String system) {
        return chatService.streamChat(prompt, system);
    }
    
    /**
     * 程式碼生成流式端點
     * @param description 程式需求描述
     * @param language 程式語言
     * @return 流式程式碼
     */
    @GetMapping(value = "/code/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> generateCode(
            @RequestParam String description,
            @RequestParam(defaultValue = "Java") String language) {
        return chatService.streamCodeGeneration(description, language);
    }
    
    /**
     * POST 方式的流式聊天（支援複雜請求）
     * @param request 聊天請求
     * @return 流式回應
     */
    @PostMapping(value = "/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> chatPost(@RequestBody ChatStreamRequest request) {
        return chatService.streamChat(request.getMessage(), request.getSystemPrompt());
    }
}
```

### 請求 DTO

```java
package com.example.dto;

import lombok.Data;

@Data
public class ChatStreamRequest {
    private String message;
    private String systemPrompt;
    private Double temperature;
    private Integer maxTokens;
}
```

---

## 4.3.7 前端整合技術

### JavaScript EventSource 整合

前端可以使用 EventSource 來接收流式資料：

```javascript
/**
 * 流式聊天功能
 * @param {string} prompt - 使用者輸入
 * @param {string} containerId - 顯示容器 ID
 */
function streamChat(prompt, containerId = 'chat-response') {
    const chatContainer = document.getElementById(containerId);
    const encodedPrompt = encodeURIComponent(prompt);
    const eventSource = new EventSource(`/api/chat/stream?prompt=${encodedPrompt}`);
    
    // 清空之前的內容
    chatContainer.innerHTML = '';
    
    // 接收流式資料
    eventSource.onmessage = function(event) {
        const content = event.data;
        if (content && content.trim() !== '') {
            chatContainer.innerHTML += content;
            // 自動滾動到底部
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }
    };
    
    // 錯誤處理
    eventSource.onerror = function(event) {
        console.error('Stream error:', event);
        chatContainer.innerHTML += '<br><span style="color: red;">❌ 連線錯誤，請重新嘗試</span>';
        eventSource.close();
    };
    
    // 連線關閉處理
    eventSource.addEventListener('close', function() {
        console.log('Stream completed');
        eventSource.close();
    });
    
    // 返回 EventSource 實例，以便外部控制
    return eventSource;
}

/**
 * 進階流式聊天（支援取消）
 */
class StreamingChat {
    constructor(containerId) {
        this.container = document.getElementById(containerId);
        this.eventSource = null;
    }
    
    start(prompt, systemPrompt = null) {
        this.stop(); // 停止之前的連線
        
        let url = `/api/chat/stream?prompt=${encodeURIComponent(prompt)}`;
        if (systemPrompt) {
            url += `&system=${encodeURIComponent(systemPrompt)}`;
        }
        
        this.eventSource = new EventSource(url);
        this.container.innerHTML = '';
        
        this.eventSource.onmessage = (event) => {
            this.container.innerHTML += event.data;
            this.container.scrollTop = this.container.scrollHeight;
        };
        
        this.eventSource.onerror = (event) => {
            console.error('Stream error:', event);
            this.container.innerHTML += '<br><span class="error">❌ 發生錯誤</span>';
            this.stop();
        };
    }
    
    stop() {
        if (this.eventSource) {
            this.eventSource.close();
            this.eventSource = null;
        }
    }
}

// 使用範例
const chat = new StreamingChat('chat-response');
chat.start('請介紹 Spring AI 的主要功能');
```

### React 整合範例

```jsx
import React, { useState, useEffect, useRef } from 'react';

function StreamingChat() {
    const [message, setMessage] = useState('');
    const [response, setResponse] = useState('');
    const [isStreaming, setIsStreaming] = useState(false);
    const eventSourceRef = useRef(null);
    
    const startStreaming = () => {
        if (!message.trim()) return;
        
        setResponse('');
        setIsStreaming(true);
        
        const encodedMessage = encodeURIComponent(message);
        eventSourceRef.current = new EventSource(
            `/api/chat/stream?prompt=${encodedMessage}`
        );
        
        eventSourceRef.current.onmessage = (event) => {
            setResponse(prev => prev + event.data);
        };
        
        eventSourceRef.current.onerror = (error) => {
            console.error('Stream error:', error);
            setIsStreaming(false);
            eventSourceRef.current?.close();
        };
        
        eventSourceRef.current.addEventListener('close', () => {
            setIsStreaming(false);
            eventSourceRef.current?.close();
        });
    };
    
    const stopStreaming = () => {
        eventSourceRef.current?.close();
        setIsStreaming(false);
    };
    
    useEffect(() => {
        return () => {
            eventSourceRef.current?.close();
        };
    }, []);
    
    return (
        <div className="streaming-chat">
            <div className="input-section">
                <textarea
                    value={message}
                    onChange={(e) => setMessage(e.target.value)}
                    placeholder="輸入您的問題..."
                    disabled={isStreaming}
                />
                <button 
                    onClick={startStreaming} 
                    disabled={isStreaming || !message.trim()}
                >
                    {isStreaming ? '生成中...' : '發送'}
                </button>
                {isStreaming && (
                    <button onClick={stopStreaming}>停止</button>
                )}
            </div>
            
            <div className="response-section">
                <h3>AI 回應：</h3>
                <div className="response-content">
                    {response || (isStreaming ? '正在思考中...' : '等待您的問題')}
                </div>
            </div>
        </div>
    );
}

export default StreamingChat;
```

---

## 4.3.8 測試與除錯

### 使用 Postman 測試

**基本流式測試**：
```
GET http://localhost:8080/api/chat/stream?prompt=解釋什麼是Spring AI
```

在 Postman 中你會看到：
- Response Type 顯示為 `text/event-stream`
- 內容會分段即時顯示
- 不會等待完整回應才顯示

**帶系統提示詞的測試**：
```
GET http://localhost:8080/api/chat/stream?prompt=寫一個Hello World程式&system=你是一個Java專家
```

### 使用 curl 測試

```bash
# 基本流式測試
curl -N "http://localhost:8080/api/chat/stream?prompt=介紹Spring框架"

# 程式碼生成測試
curl -N "http://localhost:8080/api/chat/code/stream?description=建立一個簡單的REST API&language=Java"

# POST 方式測試
curl -N -X POST "http://localhost:8080/api/chat/stream" \
     -H "Content-Type: application/json" \
     -d '{
       "message": "請解釋什麼是微服務架構",
       "systemPrompt": "你是一個架構師專家"
     }'
```

**重要參數**：
- `-N`: 確保不緩衝輸出，能即時看到流式結果

### 效能測試

```bash
# 使用 Apache Bench 測試併發流式請求
ab -n 10 -c 2 "http://localhost:8080/api/chat/stream?prompt=Hello"

# 使用 wrk 進行壓力測試
wrk -t4 -c10 -d30s "http://localhost:8080/api/chat/stream?prompt=測試"
```

---

## 4.3.9 效能優化與最佳實踐

### 連線池與資源管理

```yaml
# application.yml
spring:
  ai:
    openai:
      chat:
        options:
          max-completion-tokens: 1000  # 限制輸出長度
          stream-usage: true  # 取得流式回應中的使用量統計
```

### 背壓處理

```java
@GetMapping(value = "/chat/stream/backpressure", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<String> chatStreamWithBackpressure(@RequestParam String prompt) {
    return chatClient.prompt()
            .user(prompt)
            .stream()
            .content()
            .onBackpressureBuffer(1000)  // 設定緩衝區大小
            .publishOn(Schedulers.boundedElastic())  // 使用彈性執行緒池
            .delayElements(Duration.ofMillis(10));  // 控制發送頻率
}
```

### 記憶體優化

```java
@Service
public class OptimizedChatService {
    
    private final ChatClient chatClient;
    private final Scheduler scheduler = Schedulers.newBoundedElastic(
        10, 100, "chat-stream", 60, true
    );
    
    public Flux<String> streamChatOptimized(String prompt) {
        return chatClient.prompt()
                .user(prompt)
                .stream()
                .content()
                .subscribeOn(scheduler)  // 使用專用執行緒池
                .doFinally(signalType -> {
                    // 清理資源
                    log.debug("Stream finished with signal: {}", signalType);
                });
    }
}
```

### 錯誤處理與重試

```java
@GetMapping(value = "/chat/stream/resilient", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
public Flux<String> chatStreamResilient(@RequestParam String prompt) {
    return chatClient.prompt()
            .user(prompt)
            .stream()
            .content()
            .timeout(Duration.ofSeconds(30))  // 設定超時
            .retryWhen(Retry.backoff(3, Duration.ofSeconds(1))  // 指數退避重試
                .filter(throwable -> !(throwable instanceof IllegalArgumentException)))
            .onErrorResume(TimeoutException.class, error -> 
                Flux.just("⏰ 請求超時，請稍後再試"))
            .onErrorResume(Exception.class, error -> 
                Flux.just("❌ 服務暫時不可用：" + error.getMessage()));
}
```

---

## 📝 本章重點回顧

1. **流式輸出原理**：理解了 SSE 技術和流式輸出的優勢
2. **ChatClient 流式 API**：掌握了使用 `stream()` 方法實現流式輸出
3. **Reactive Streams**：學會了使用 Flux 處理流式資料
4. **前端整合**：了解如何使用 EventSource 接收流式資料
5. **效能優化**：掌握了背壓處理、錯誤處理等最佳實踐

### 新舊版本對比

| 功能 | 舊版本 (pre-1.0) | 新版本 (1.0 GA) |
|------|------------------|----------------|
| **API 風格** | `chatModel.stream(prompt)` | `chatClient.prompt().user(prompt).stream().content()` |
| **可讀性** | 較低 | 高（Fluent API） |
| **功能豐富度** | 基礎 | 豐富（系統提示詞、選項配置等） |
| **錯誤處理** | 需手動實作 | 內建支援 |
| **效能優化** | 有限 | 完整的 Reactive 支援 |

### 下一步學習方向

在下一章中，我們將深入探討 ChatModel 的內部機制，了解不同 AI 模型的特性和選擇策略，為企業級應用做好準備。

---

**參考資料：**
- [Server-Sent Events Specification](https://html.spec.whatwg.org/multipage/server-sent-events.html)
- [Spring WebFlux Reactive Streams](https://docs.spring.io/spring-framework/docs/current/reference/html/web-reactive.html)
- [Project Reactor Documentation](https://projectreactor.io/docs/core/release/reference/)
- [Spring AI Streaming Documentation](https://docs.spring.io/spring-ai/reference/api/chatclient.html#streaming)