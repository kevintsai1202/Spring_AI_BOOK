# 7.2 å¦‚ä½•å°‡å…§å®¹å‘é‡åŒ–

> **æœ¬ç« é‡é»**ï¼šæ·±å…¥ç†è§£æ–‡æœ¬å‘é‡åŒ–æŠ€è¡“ï¼ŒæŒæ¡ä¸åŒåµŒå…¥æ¨¡å‹çš„é¸æ“‡å’Œä½¿ç”¨ï¼Œå­¸æœƒå„ªåŒ–å‘é‡å“è³ªä»¥æå‡ RAG ç³»çµ±æ•ˆèƒ½ã€‚

## ğŸ¯ å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç« å­¸ç¿’å¾Œï¼Œæ‚¨å°‡èƒ½å¤ ï¼š

- ğŸ¯ **ç†è§£å‘é‡åŒ–åŸç†**ï¼šæŒæ¡æ–‡æœ¬å‘é‡åŒ–çš„åŸºæœ¬æ¦‚å¿µå’Œæ•¸å­¸åŸç†
- ğŸ¯ **é¸æ“‡åˆé©çš„åµŒå…¥æ¨¡å‹**ï¼šäº†è§£ä¸åŒåµŒå…¥æ¨¡å‹çš„ç‰¹é»å’Œé©ç”¨å ´æ™¯
- ğŸ¯ **å¯¦ç¾å‘é‡åŒ–è™•ç†**ï¼šä½¿ç”¨ Spring AI å¯¦ç¾é«˜æ•ˆçš„æ–‡æœ¬å‘é‡åŒ–
- ğŸ¯ **å„ªåŒ–å‘é‡å“è³ª**ï¼šæŒæ¡å‘é‡å“è³ªè©•ä¼°å’Œå„ªåŒ–æŠ€å·§
- ğŸ¯ **è™•ç†å¤šèªè¨€å‘é‡åŒ–**ï¼šå¯¦ç¾è·¨èªè¨€çš„å‘é‡åŒ–è§£æ±ºæ–¹æ¡ˆ

---

## 7.2.1 å‘é‡åŒ–åŸºç¤æ¦‚å¿µ

### ä»€éº¼æ˜¯æ–‡æœ¬å‘é‡åŒ–ï¼Ÿ

**æ–‡æœ¬å‘é‡åŒ–ï¼ˆText Embeddingï¼‰** æ˜¯å°‡æ–‡æœ¬è½‰æ›ç‚ºæ•¸å€¼å‘é‡çš„éç¨‹ï¼Œé€™äº›å‘é‡èƒ½å¤ åœ¨é«˜ç¶­ç©ºé–“ä¸­è¡¨ç¤ºæ–‡æœ¬çš„èªç¾©è³‡è¨Šã€‚

**æ ¸å¿ƒæ¦‚å¿µ**ï¼š
- ğŸ“Š **é«˜ç¶­è¡¨ç¤º**ï¼šå°‡æ–‡æœ¬æ˜ å°„åˆ°é«˜ç¶­å‘é‡ç©ºé–“ï¼ˆé€šå¸¸ 100-4096 ç¶­ï¼‰
- ğŸ¯ **èªç¾©æ•æ‰**ï¼šç›¸ä¼¼æ„æ€çš„æ–‡æœ¬åœ¨å‘é‡ç©ºé–“ä¸­è·é›¢è¼ƒè¿‘
- ğŸ”¢ **æ•¸å€¼è¨ˆç®—**ï¼šæ”¯æ´æ•¸å­¸é‹ç®—ï¼Œå¦‚ç›¸ä¼¼æ€§è¨ˆç®—ã€èšé¡åˆ†æ
- ğŸ”„ **å¯æ¯”è¼ƒæ€§**ï¼šä¸åŒæ–‡æœ¬å¯ä»¥é€šéå‘é‡è·é›¢é€²è¡Œæ¯”è¼ƒ

### å‘é‡åŒ–çš„æ•¸å­¸åŸç†

**å‘é‡ç›¸ä¼¼æ€§è¨ˆç®—**ï¼š

```
1. é¤˜å¼¦ç›¸ä¼¼æ€§ï¼ˆCosine Similarityï¼‰
   similarity = (A Â· B) / (||A|| Ã— ||B||)
   
2. æ­å¹¾é‡Œå¾—è·é›¢ï¼ˆEuclidean Distanceï¼‰
   distance = âˆš(Î£(Ai - Bi)Â²)
   
3. é»ç©ç›¸ä¼¼æ€§ï¼ˆDot Productï¼‰
   similarity = Î£(Ai Ã— Bi)
```

**å‘é‡ç©ºé–“ç¤ºä¾‹**ï¼š
```
æ–‡æœ¬: "Spring Boot æ˜¯ä¸€å€‹ Java æ¡†æ¶"
å‘é‡: [0.2, -0.1, 0.8, 0.3, ..., 0.5]  (1536ç¶­)

æ–‡æœ¬: "Spring Boot is a Java framework"
å‘é‡: [0.18, -0.08, 0.82, 0.28, ..., 0.52]  (1536ç¶­)

ç›¸ä¼¼æ€§: 0.95 (é«˜åº¦ç›¸ä¼¼)
```

### å‘é‡åŒ–çš„ç™¼å±•æ­·ç¨‹

| æŠ€è¡“ | æ™‚æœŸ | ç‰¹é» | ç¶­åº¦ | é©ç”¨å ´æ™¯ |
|------|------|------|------|----------|
| **One-Hot** | 1950s | ç¨€ç–ã€é«˜ç¶­ | è©å½™è¡¨å¤§å° | ç°¡å–®åˆ†é¡ |
| **TF-IDF** | 1970s | çµ±è¨ˆç‰¹å¾µ | è©å½™è¡¨å¤§å° | è³‡è¨Šæª¢ç´¢ |
| **Word2Vec** | 2013 | å¯†é›†å‘é‡ | 100-300 | è©èªç›¸ä¼¼æ€§ |
| **GloVe** | 2014 | å…¨åŸŸçµ±è¨ˆ | 100-300 | è©èªé—œä¿‚ |
| **BERT** | 2018 | ä¸Šä¸‹æ–‡æ„ŸçŸ¥ | 768-1024 | èªç¾©ç†è§£ |
| **OpenAI Embeddings** | 2022 | å¤§è¦æ¨¡é è¨“ç·´ | 1536-3072 | é€šç”¨èªç¾© |

---

## 7.2.2 Spring AI ä¸­çš„åµŒå…¥æ¨¡å‹

### æ”¯æ´çš„åµŒå…¥æ¨¡å‹

Spring AI æ”¯æ´å¤šç¨®åµŒå…¥æ¨¡å‹ï¼Œæ¯ç¨®éƒ½æœ‰å…¶ç‰¹é»å’Œé©ç”¨å ´æ™¯ï¼š

**1. OpenAI Embeddings**
```java
// OpenAI text-embedding-3-small (æœ€æ–°æ¨è–¦)
@Bean
public EmbeddingModel openAIEmbeddingModel() {
    var openAiApi = OpenAiApi.builder()
        .apiKey(System.getenv("OPENAI_API_KEY"))
        .build();
    return new OpenAiEmbeddingModel(
        openAiApi,
        MetadataMode.EMBED,
        OpenAiEmbeddingOptions.builder()
            .withModel("text-embedding-3-small")  // 1536 ç¶­
            .withDimensions(1536)
            .build(),
        RetryUtils.DEFAULT_RETRY_TEMPLATE
    );
}

// OpenAI text-embedding-3-large (é«˜ç²¾åº¦)
@Bean
public EmbeddingModel openAILargeEmbeddingModel() {
    var openAiApi = OpenAiApi.builder()
        .apiKey(System.getenv("OPENAI_API_KEY"))
        .build();
    return new OpenAiEmbeddingModel(
        openAiApi,
        MetadataMode.EMBED,
        OpenAiEmbeddingOptions.builder()
            .withModel("text-embedding-3-large")  // 3072 ç¶­
            .withDimensions(3072)
            .build(),
        RetryUtils.DEFAULT_RETRY_TEMPLATE
    );
}
```

**2. Azure OpenAI Embeddings**
```java
@Bean
public EmbeddingModel azureEmbeddingModel() {
    var azureOpenAiApi = AzureOpenAiApi.builder()
        .apiKey(System.getenv("AZURE_OPENAI_API_KEY"))
        .endpoint(System.getenv("AZURE_OPENAI_ENDPOINT"))
        .build();
    return new AzureOpenAiEmbeddingModel(
        azureOpenAiApi,
        MetadataMode.EMBED,
        AzureOpenAiEmbeddingOptions.builder()
            .withDeploymentName("text-embedding-ada-002")
            .withDimensions(1536)
            .build(),
        RetryUtils.DEFAULT_RETRY_TEMPLATE
    );
}
```

**3. Ollama æœ¬åœ°åµŒå…¥æ¨¡å‹**
```java
@Bean
public EmbeddingModel ollamaEmbeddingModel() {
    var ollamaApi = new OllamaApi();
    return new OllamaEmbeddingModel(
        ollamaApi,
        OllamaOptions.create()
            .withModel("nomic-embed-text")  // æœ¬åœ°æ¨¡å‹
    );
}
```

**4. Transformers åµŒå…¥æ¨¡å‹**
```java
@Bean
public EmbeddingModel transformersEmbeddingModel() {
    return new TransformersEmbeddingModel(
        TransformersEmbeddingOptions.builder()
            .withModelName("sentence-transformers/all-MiniLM-L6-v2")
            .withDimensions(384)
            .build()
    );
}
```

### åµŒå…¥æ¨¡å‹æ¯”è¼ƒ

| æ¨¡å‹ | ç¶­åº¦ | èªè¨€æ”¯æ´ | æ•ˆèƒ½ | æˆæœ¬ | é©ç”¨å ´æ™¯ |
|------|------|----------|------|------|----------|
| **text-embedding-3-small** | 1536 | å¤šèªè¨€ | é«˜ | ä½ | é€šç”¨æ¨è–¦ |
| **text-embedding-3-large** | 3072 | å¤šèªè¨€ | æœ€é«˜ | ä¸­ | é«˜ç²¾åº¦éœ€æ±‚ |
| **text-embedding-ada-002** | 1536 | å¤šèªè¨€ | é«˜ | ä½ | ç©©å®šé¸æ“‡ |
| **nomic-embed-text** | 768 | è‹±æ–‡ç‚ºä¸» | ä¸­ | å…è²» | æœ¬åœ°éƒ¨ç½² |
| **all-MiniLM-L6-v2** | 384 | å¤šèªè¨€ | ä¸­ | å…è²» | è¼•é‡ç´šæ‡‰ç”¨ |

---

## 7.2.3 å‘é‡åŒ–æœå‹™å¯¦ç¾

### åŸºç¤å‘é‡åŒ–æœå‹™

```java
/**
 * æ–‡æœ¬å‘é‡åŒ–æœå‹™
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class TextEmbeddingService {
    
    private final EmbeddingModel embeddingModel;
    private final MeterRegistry meterRegistry;
    
    /**
     * å–®ä¸€æ–‡æœ¬å‘é‡åŒ–
     */
    public float[] embedText(String text) {
        if (text == null || text.trim().isEmpty()) {
            throw new IllegalArgumentException("Text cannot be null or empty");
        }
        
        Timer.Sample sample = Timer.start(meterRegistry);
        
        try {
            // é è™•ç†æ–‡æœ¬
            String processedText = preprocessText(text);
            
            // ç”Ÿæˆå‘é‡
            float[] embedding = embeddingModel.embed(processedText);
            
            // è¨˜éŒ„æŒ‡æ¨™
            sample.stop(Timer.builder("embedding.generation.time")
                .description("Time to generate text embedding")
                .register(meterRegistry));
            
            meterRegistry.counter("embedding.generation.count").increment();
            
            log.debug("Generated embedding for text: {} chars, vector dim: {}", 
                text.length(), embedding.length);
            
            return embedding;
            
        } catch (Exception e) {
            meterRegistry.counter("embedding.generation.errors").increment();
            log.error("Failed to generate embedding for text: {}", text, e);
            throw new EmbeddingException("Failed to generate embedding", e);
        }
    }
    
    /**
     * æ‰¹æ¬¡æ–‡æœ¬å‘é‡åŒ–
     */
    public List<float[]> embedTexts(List<String> texts) {
        if (texts == null || texts.isEmpty()) {
            return Collections.emptyList();
        }
        
        log.info("Generating embeddings for {} texts", texts.size());
        
        Timer.Sample sample = Timer.start(meterRegistry);
        
        try {
            // é è™•ç†æ‰€æœ‰æ–‡æœ¬
            List<String> processedTexts = texts.stream()
                .map(this::preprocessText)
                .collect(Collectors.toList());
            
            // æ‰¹æ¬¡ç”Ÿæˆå‘é‡
            List<float[]> embeddings = embeddingModel.embed(processedTexts);
            
            sample.stop(Timer.builder("embedding.batch.generation.time")
                .description("Time to generate batch embeddings")
                .register(meterRegistry));
            
            meterRegistry.counter("embedding.batch.generation.count")
                .increment(texts.size());
            
            log.info("Successfully generated {} embeddings", embeddings.size());
            
            return embeddings;
            
        } catch (Exception e) {
            meterRegistry.counter("embedding.batch.generation.errors").increment();
            log.error("Failed to generate batch embeddings", e);
            throw new EmbeddingException("Failed to generate batch embeddings", e);
        }
    }
    
    /**
     * æ–‡æœ¬é è™•ç†
     */
    private String preprocessText(String text) {
        if (text == null) {
            return "";
        }
        
        return text
            .trim()
            .replaceAll("\\s+", " ")  // æ¨™æº–åŒ–ç©ºç™½å­—ç¬¦
            .replaceAll("[\\r\\n]+", " ")  // ç§»é™¤æ›è¡Œç¬¦
            .substring(0, Math.min(text.length(), 8000));  // é™åˆ¶é•·åº¦
    }
    
    /**
     * è¨ˆç®—å‘é‡ç›¸ä¼¼æ€§
     */
    public double calculateSimilarity(float[] vector1, float[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vectors must have the same dimension");
        }
        
        // é¤˜å¼¦ç›¸ä¼¼æ€§è¨ˆç®—
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += Math.pow(vector1[i], 2);
            norm2 += Math.pow(vector2[i], 2);
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
```

### é€²éšå‘é‡åŒ–è™•ç†

```java
/**
 * é€²éšå‘é‡åŒ–è™•ç†æœå‹™
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AdvancedEmbeddingService {
    
    private final TextEmbeddingService embeddingService;
    private final RedisTemplate<String, Object> redisTemplate;
    
    private static final String EMBEDDING_CACHE_PREFIX = "embedding:";
    private static final Duration CACHE_TTL = Duration.ofHours(24);
    
    /**
     * å¸¶å¿«å–çš„å‘é‡åŒ–
     */
    public float[] embedTextWithCache(String text) {
        String cacheKey = EMBEDDING_CACHE_PREFIX + DigestUtils.md5Hex(text);
        
        // å˜—è©¦å¾å¿«å–å–å¾—
        float[] cachedEmbedding = (float[]) redisTemplate.opsForValue().get(cacheKey);
        
        if (cachedEmbedding != null) {
            log.debug("Cache hit for text embedding: {}", cacheKey);
            return cachedEmbedding;
        }
        
        // å¿«å–æœªå‘½ä¸­ï¼Œç”Ÿæˆæ–°å‘é‡
        float[] embedding = embeddingService.embedText(text);
        
        // å­˜å…¥å¿«å–
        redisTemplate.opsForValue().set(cacheKey, embedding, CACHE_TTL);
        
        log.debug("Cache miss, generated and cached embedding: {}", cacheKey);
        
        return embedding;
    }
    
    /**
     * åˆ†å±¤å‘é‡åŒ–è™•ç†
     */
    public LayeredEmbedding generateLayeredEmbedding(String text) {
        // 1. å¥å­ç´šå‘é‡åŒ–
        List<String> sentences = splitIntoSentences(text);
        List<float[]> sentenceEmbeddings = embeddingService.embedTexts(sentences);
        
        // 2. æ®µè½ç´šå‘é‡åŒ–
        List<String> paragraphs = splitIntoParagraphs(text);
        List<float[]> paragraphEmbeddings = embeddingService.embedTexts(paragraphs);
        
        // 3. æ–‡æª”ç´šå‘é‡åŒ–
        float[] documentEmbedding = embeddingService.embedText(text);
        
        return LayeredEmbedding.builder()
            .sentences(sentences)
            .sentenceEmbeddings(sentenceEmbeddings)
            .paragraphs(paragraphs)
            .paragraphEmbeddings(paragraphEmbeddings)
            .documentEmbedding(documentEmbedding)
            .build();
    }
    
    /**
     * å¤šæ¨¡å‹å‘é‡åŒ–
     */
    public MultiModelEmbedding generateMultiModelEmbedding(String text) {
        Map<String, float[]> embeddings = new HashMap<>();
        
        // ä½¿ç”¨ä¸åŒæ¨¡å‹ç”Ÿæˆå‘é‡
        try {
            embeddings.put("openai-small", generateWithModel(text, "openai-small"));
            embeddings.put("openai-large", generateWithModel(text, "openai-large"));
            embeddings.put("local-model", generateWithModel(text, "local-model"));
        } catch (Exception e) {
            log.warn("Some embedding models failed", e);
        }
        
        return MultiModelEmbedding.builder()
            .text(text)
            .embeddings(embeddings)
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    /**
     * å‘é‡å“è³ªè©•ä¼°
     */
    public EmbeddingQuality assessEmbeddingQuality(float[] embedding, String originalText) {
        // 1. å‘é‡ç¶­åº¦æª¢æŸ¥
        int dimension = embedding.length;
        boolean validDimension = dimension >= 384 && dimension <= 4096;
        
        // 2. å‘é‡ç¯„æ•¸æª¢æŸ¥
        double norm = calculateVectorNorm(embedding);
        boolean validNorm = norm > 0.1 && norm < 10.0;
        
        // 3. å‘é‡åˆ†ä½ˆæª¢æŸ¥
        double[] stats = calculateVectorStatistics(embedding);
        double mean = stats[0];
        double stdDev = stats[1];
        boolean validDistribution = Math.abs(mean) < 0.5 && stdDev > 0.01;
        
        // 4. æ–‡æœ¬é•·åº¦é©é…æ€§
        boolean validTextLength = originalText.length() >= 10 && originalText.length() <= 8000;
        
        double qualityScore = calculateQualityScore(
            validDimension, validNorm, validDistribution, validTextLength
        );
        
        return EmbeddingQuality.builder()
            .dimension(dimension)
            .norm(norm)
            .mean(mean)
            .standardDeviation(stdDev)
            .qualityScore(qualityScore)
            .isValid(qualityScore > 0.7)
            .build();
    }
    
    private List<String> splitIntoSentences(String text) {
        // ç°¡å–®çš„å¥å­åˆ†å‰²å¯¦ç¾
        return Arrays.stream(text.split("[.!?]+"))
            .map(String::trim)
            .filter(s -> !s.isEmpty())
            .collect(Collectors.toList());
    }
    
    private List<String> splitIntoParagraphs(String text) {
        return Arrays.stream(text.split("\\n\\s*\\n"))
            .map(String::trim)
            .filter(s -> !s.isEmpty())
            .collect(Collectors.toList());
    }
    
    private float[] generateWithModel(String text, String modelType) {
        // æ ¹æ“šæ¨¡å‹é¡å‹é¸æ“‡ä¸åŒçš„åµŒå…¥æ¨¡å‹
        // é€™è£¡ç°¡åŒ–å¯¦ç¾ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­éœ€è¦æ³¨å…¥ä¸åŒçš„æ¨¡å‹
        return embeddingService.embedText(text);
    }
    
    private double calculateVectorNorm(float[] vector) {
        double sum = 0.0;
        for (float value : vector) {
            sum += value * value;
        }
        return Math.sqrt(sum);
    }
    
    private double[] calculateVectorStatistics(float[] vector) {
        // è¨ˆç®—å¹³å‡å€¼
        double sum = 0.0;
        for (float value : vector) {
            sum += value;
        }
        double mean = sum / vector.length;
        
        // è¨ˆç®—æ–¹å·®
        double varianceSum = 0.0;
        for (float value : vector) {
            varianceSum += Math.pow(value - mean, 2);
        }
        double variance = varianceSum / vector.length;
        double stdDev = Math.sqrt(variance);
        
        return new double[]{mean, stdDev};
    }
    
    private double calculateQualityScore(boolean... checks) {
        long passedChecks = Arrays.stream(checks)
            .mapToInt(b -> b ? 1 : 0)
            .sum();
        
        return (double) passedChecks / checks.length;
    }
}
```

---

## 7.2.4 å‘é‡åŒ–é…ç½®èˆ‡å„ªåŒ–

### å‘é‡åŒ–é…ç½®é¡

```java
/**
 * å‘é‡åŒ–é…ç½®
 */
@Configuration
@EnableConfigurationProperties(EmbeddingProperties.class)
public class EmbeddingConfig {
    
    /**
     * ä¸»è¦åµŒå…¥æ¨¡å‹é…ç½®
     */
    @Bean
    @Primary
    public EmbeddingModel primaryEmbeddingModel(EmbeddingProperties properties) {
        EmbeddingProperties.ModelConfig config = properties.getPrimary();
        
        return switch (config.getProvider().toLowerCase()) {
            case "openai" -> createOpenAIEmbeddingModel(config);
            case "azure" -> createAzureEmbeddingModel(config);
            case "ollama" -> createOllamaEmbeddingModel(config);
            case "transformers" -> createTransformersEmbeddingModel(config);
            default -> throw new IllegalArgumentException("Unsupported embedding provider: " + config.getProvider());
        };
    }
    
    /**
     * å‚™ç”¨åµŒå…¥æ¨¡å‹é…ç½®
     */
    @Bean
    @Qualifier("fallback")
    public EmbeddingModel fallbackEmbeddingModel(EmbeddingProperties properties) {
        EmbeddingProperties.ModelConfig config = properties.getFallback();
        
        if (config == null) {
            // é è¨­ä½¿ç”¨æœ¬åœ°æ¨¡å‹ä½œç‚ºå‚™ç”¨
            return new TransformersEmbeddingModel(
                TransformersEmbeddingOptions.builder()
                    .withModelName("sentence-transformers/all-MiniLM-L6-v2")
                    .withDimensions(384)
                    .build()
            );
        }
        
        return createEmbeddingModel(config);
    }
    
    /**
     * å‘é‡åŒ–å¿«å–é…ç½®
     */
    @Bean
    public CacheManager embeddingCacheManager() {
        RedisCacheManager.Builder builder = RedisCacheManager
            .RedisCacheManagerBuilder
            .fromConnectionFactory(redisConnectionFactory())
            .cacheDefaults(cacheConfiguration());
        
        return builder.build();
    }
    
    private RedisCacheConfiguration cacheConfiguration() {
        return RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofHours(24))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new GenericJackson2JsonRedisSerializer()));
    }
    
    private EmbeddingModel createOpenAIEmbeddingModel(EmbeddingProperties.ModelConfig config) {
        OpenAiApi openAiApi = OpenAiApi.builder()
            .apiKey(config.getApiKey())
            .build();
            
        return new OpenAiEmbeddingModel(
            openAiApi,
            MetadataMode.EMBED,
            OpenAiEmbeddingOptions.builder()
                .withModel(config.getModelName())
                .withDimensions(config.getDimensions())
                .build(),
            RetryUtils.DEFAULT_RETRY_TEMPLATE
        );
    }
    
    // å…¶ä»–æ¨¡å‹å‰µå»ºæ–¹æ³•...
}
```

### å‘é‡åŒ–é…ç½®å±¬æ€§

```java
/**
 * å‘é‡åŒ–é…ç½®å±¬æ€§
 */
@ConfigurationProperties(prefix = "app.embedding")
@Data
@Validated
public class EmbeddingProperties {
    
    /**
     * ä¸»è¦åµŒå…¥æ¨¡å‹é…ç½®
     */
    @NotNull
    private ModelConfig primary;
    
    /**
     * å‚™ç”¨åµŒå…¥æ¨¡å‹é…ç½®
     */
    private ModelConfig fallback;
    
    /**
     * å¿«å–é…ç½®
     */
    private CacheConfig cache = new CacheConfig();
    
    /**
     * æ‰¹æ¬¡è™•ç†é…ç½®
     */
    private BatchConfig batch = new BatchConfig();
    
    @Data
    @Validated
    public static class ModelConfig {
        @NotBlank
        private String provider;  // openai, azure, ollama, transformers
        
        @NotBlank
        private String modelName;
        
        @Min(100)
        @Max(4096)
        private int dimensions;
        
        private String apiKey;
        private String endpoint;
        private Duration timeout = Duration.ofSeconds(30);
    }
    
    @Data
    public static class CacheConfig {
        private boolean enabled = true;
        private Duration ttl = Duration.ofHours(24);
        private int maxSize = 10000;
    }
    
    @Data
    public static class BatchConfig {
        private int size = 100;
        private Duration timeout = Duration.ofMinutes(5);
        private int retries = 3;
    }
}
```

### æ‡‰ç”¨é…ç½®æª”æ¡ˆ

```yaml
# application.yml
app:
  embedding:
    primary:
      provider: openai
      model-name: text-embedding-3-small
      dimensions: 1536
      api-key: ${OPENAI_API_KEY}
      timeout: 30s
    
    fallback:
      provider: transformers
      model-name: sentence-transformers/all-MiniLM-L6-v2
      dimensions: 384
      timeout: 60s
    
    cache:
      enabled: true
      ttl: 24h
      max-size: 10000
    
    batch:
      size: 100
      timeout: 5m
      retries: 3

# é–‹ç™¼ç’°å¢ƒé…ç½®
---
spring:
  config:
    activate:
      on-profile: dev

app:
  embedding:
    primary:
      provider: transformers
      model-name: sentence-transformers/all-MiniLM-L6-v2
      dimensions: 384
    cache:
      enabled: false

# ç”Ÿç”¢ç’°å¢ƒé…ç½®
---
spring:
  config:
    activate:
      on-profile: prod

app:
  embedding:
    primary:
      provider: openai
      model-name: text-embedding-3-large
      dimensions: 3072
      api-key: ${OPENAI_API_KEY}
    
    fallback:
      provider: azure
      model-name: text-embedding-ada-002
      dimensions: 1536
      api-key: ${AZURE_OPENAI_API_KEY}
      endpoint: ${AZURE_OPENAI_ENDPOINT}
```

---

## 7.2.5 å‘é‡å“è³ªè©•ä¼°èˆ‡å„ªåŒ–

### å‘é‡å“è³ªè©•ä¼°æœå‹™

```java
/**
 * å‘é‡å“è³ªè©•ä¼°æœå‹™
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class EmbeddingQualityService {
    
    private final TextEmbeddingService embeddingService;
    
    /**
     * ç¶œåˆå“è³ªè©•ä¼°
     */
    public QualityAssessmentResult assessEmbeddingQuality(
            List<String> testTexts, 
            List<String> expectedSimilarTexts) {
        
        log.info("Starting embedding quality assessment with {} test cases", testTexts.size());
        
        List<QualityMetric> metrics = new ArrayList<>();
        
        for (int i = 0; i < testTexts.size(); i++) {
            String testText = testTexts.get(i);
            String expectedSimilar = expectedSimilarTexts.get(i);
            
            QualityMetric metric = assessSinglePair(testText, expectedSimilar);
            metrics.add(metric);
        }
        
        return QualityAssessmentResult.builder()
            .totalTests(testTexts.size())
            .metrics(metrics)
            .averageSimilarity(calculateAverageSimilarity(metrics))
            .qualityScore(calculateOverallQuality(metrics))
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    /**
     * å–®ä¸€æ–‡æœ¬å°è©•ä¼°
     */
    private QualityMetric assessSinglePair(String text1, String text2) {
        try {
            // ç”Ÿæˆå‘é‡
            float[] embedding1 = embeddingService.embedText(text1);
            float[] embedding2 = embeddingService.embedText(text2);
            
            // è¨ˆç®—ç›¸ä¼¼æ€§
            double similarity = embeddingService.calculateSimilarity(embedding1, embedding2);
            
            // è©•ä¼°å‘é‡å“è³ª
            EmbeddingQuality quality1 = assessVectorQuality(embedding1, text1);
            EmbeddingQuality quality2 = assessVectorQuality(embedding2, text2);
            
            return QualityMetric.builder()
                .text1(text1)
                .text2(text2)
                .similarity(similarity)
                .quality1(quality1)
                .quality2(quality2)
                .isValid(similarity > 0.7 && quality1.isValid() && quality2.isValid())
                .build();
                
        } catch (Exception e) {
            log.error("Failed to assess quality for text pair", e);
            return QualityMetric.builder()
                .text1(text1)
                .text2(text2)
                .similarity(0.0)
                .isValid(false)
                .error(e.getMessage())
                .build();
        }
    }
    
    /**
     * å‘é‡å“è³ªè©•ä¼°
     */
    private EmbeddingQuality assessVectorQuality(float[] embedding, String originalText) {
        // 1. ç¶­åº¦æª¢æŸ¥
        int dimension = embedding.length;
        boolean validDimension = dimension >= 384;
        
        // 2. æ•¸å€¼ç¯„åœæª¢æŸ¥
        float min = Float.MAX_VALUE;
        float max = Float.MIN_VALUE;
        for (float value : embedding) {
            min = Math.min(min, value);
            max = Math.max(max, value);
        }
        boolean validRange = min >= -2.0f && max <= 2.0f;
        
        // 3. å‘é‡ç¯„æ•¸æª¢æŸ¥
        double norm = 0.0;
        for (float value : embedding) {
            norm += value * value;
        }
        norm = Math.sqrt(norm);
        boolean validNorm = norm > 0.1 && norm < 10.0;
        
        // 4. é›¶å‘é‡æª¢æŸ¥
        boolean notZeroVector = false;
        for (float value : embedding) {
            if (Math.abs(value) > 1e-6) {
                notZeroVector = true;
                break;
            }
        }
        
        // 5. æ–‡æœ¬é•·åº¦é©é…æ€§
        boolean validTextLength = originalText.length() >= 5;
        
        double qualityScore = calculateQualityScore(
            validDimension, validRange, validNorm, notZeroVector, validTextLength
        );
        
        return EmbeddingQuality.builder()
            .dimension(dimension)
            .norm(norm)
            .minValue(min)
            .maxValue(max)
            .qualityScore(qualityScore)
            .isValid(qualityScore > 0.8)
            .validDimension(validDimension)
            .validRange(validRange)
            .validNorm(validNorm)
            .notZeroVector(notZeroVector)
            .validTextLength(validTextLength)
            .build();
    }
    
    /**
     * èªç¾©ä¸€è‡´æ€§æ¸¬è©¦
     */
    public SemanticConsistencyResult testSemanticConsistency() {
        // æº–å‚™æ¸¬è©¦æ¡ˆä¾‹
        Map<String, List<String>> testCases = prepareSemanticTestCases();
        
        List<ConsistencyTest> results = new ArrayList<>();
        
        for (Map.Entry<String, List<String>> entry : testCases.entrySet()) {
            String category = entry.getKey();
            List<String> texts = entry.getValue();
            
            ConsistencyTest test = testCategoryConsistency(category, texts);
            results.add(test);
        }
        
        return SemanticConsistencyResult.builder()
            .tests(results)
            .overallScore(calculateConsistencyScore(results))
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    private Map<String, List<String>> prepareSemanticTestCases() {
        Map<String, List<String>> testCases = new HashMap<>();
        
        // æŠ€è¡“ç›¸é—œ
        testCases.put("technology", Arrays.asList(
            "Spring Boot æ˜¯ä¸€å€‹ Java æ¡†æ¶",
            "Spring Boot is a Java framework",
            "Spring Boot æ¡†æ¶ç”¨æ–¼ Java é–‹ç™¼",
            "Java Spring Boot æ‡‰ç”¨ç¨‹å¼æ¡†æ¶"
        ));
        
        // å•†æ¥­ç›¸é—œ
        testCases.put("business", Arrays.asList(
            "æé«˜éŠ·å”®æ¥­ç¸¾çš„ç­–ç•¥",
            "å¢åŠ ç‡Ÿæ”¶çš„æ–¹æ³•",
            "éŠ·å”®æˆé•·ç­–ç•¥",
            "æ¥­ç¸¾æå‡è¨ˆåŠƒ"
        ));
        
        return testCases;
    }
    
    private ConsistencyTest testCategoryConsistency(String category, List<String> texts) {
        List<float[]> embeddings = embeddingService.embedTexts(texts);
        
        // è¨ˆç®—æ‰€æœ‰æ–‡æœ¬å°ä¹‹é–“çš„ç›¸ä¼¼æ€§
        List<Double> similarities = new ArrayList<>();
        
        for (int i = 0; i < embeddings.size(); i++) {
            for (int j = i + 1; j < embeddings.size(); j++) {
                double similarity = embeddingService.calculateSimilarity(
                    embeddings.get(i), embeddings.get(j)
                );
                similarities.add(similarity);
            }
        }
        
        double averageSimilarity = similarities.stream()
            .mapToDouble(Double::doubleValue)
            .average()
            .orElse(0.0);
        
        double minSimilarity = similarities.stream()
            .mapToDouble(Double::doubleValue)
            .min()
            .orElse(0.0);
        
        return ConsistencyTest.builder()
            .category(category)
            .texts(texts)
            .similarities(similarities)
            .averageSimilarity(averageSimilarity)
            .minSimilarity(minSimilarity)
            .isConsistent(averageSimilarity > 0.7 && minSimilarity > 0.5)
            .build();
    }
    
    private double calculateAverageSimilarity(List<QualityMetric> metrics) {
        return metrics.stream()
            .mapToDouble(QualityMetric::getSimilarity)
            .average()
            .orElse(0.0);
    }
    
    private double calculateOverallQuality(List<QualityMetric> metrics) {
        long validCount = metrics.stream()
            .mapToLong(m -> m.isValid() ? 1 : 0)
            .sum();
        
        return (double) validCount / metrics.size();
    }
    
    private double calculateQualityScore(boolean... checks) {
        long passedChecks = Arrays.stream(checks)
            .mapToInt(b -> b ? 1 : 0)
            .sum();
        
        return (double) passedChecks / checks.length;
    }
    
    private double calculateConsistencyScore(List<ConsistencyTest> tests) {
        return tests.stream()
            .mapToDouble(ConsistencyTest::getAverageSimilarity)
            .average()
            .orElse(0.0);
    }
}
```

---

## 7.2.6 å¤šèªè¨€å‘é‡åŒ–è™•ç†

### å¤šèªè¨€å‘é‡åŒ–æœå‹™

```java
/**
 * å¤šèªè¨€å‘é‡åŒ–æœå‹™
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class MultilingualEmbeddingService {
    
    private final Map<String, EmbeddingModel> languageSpecificModels;
    private final EmbeddingModel universalModel;
    private final LanguageDetectionService languageDetector;
    
    /**
     * è‡ªå‹•èªè¨€æª¢æ¸¬å‘é‡åŒ–
     */
    public MultilingualEmbedding embedWithLanguageDetection(String text) {
        // 1. æª¢æ¸¬èªè¨€
        LanguageDetectionResult detection = languageDetector.detectLanguage(text);
        
        // 2. é¸æ“‡åˆé©çš„æ¨¡å‹
        EmbeddingModel selectedModel = selectModelForLanguage(detection.getLanguage());
        
        // 3. ç”Ÿæˆå‘é‡
        float[] embedding = selectedModel.embed(text);
        
        return MultilingualEmbedding.builder()
            .text(text)
            .detectedLanguage(detection.getLanguage())
            .confidence(detection.getConfidence())
            .embedding(embedding)
            .modelUsed(selectedModel.getClass().getSimpleName())
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    /**
     * è·¨èªè¨€ç›¸ä¼¼æ€§è¨ˆç®—
     */
    public CrossLanguageSimilarity calculateCrossLanguageSimilarity(
            String text1, String lang1,
            String text2, String lang2) {
        
        // ä½¿ç”¨é€šç”¨å¤šèªè¨€æ¨¡å‹
        float[] embedding1 = universalModel.embed(text1);
        float[] embedding2 = universalModel.embed(text2);
        
        double similarity = calculateCosineSimilarity(embedding1, embedding2);
        
        return CrossLanguageSimilarity.builder()
            .text1(text1)
            .language1(lang1)
            .text2(text2)
            .language2(lang2)
            .similarity(similarity)
            .embedding1(embedding1)
            .embedding2(embedding2)
            .build();
    }
    
    /**
     * å¤šèªè¨€æ–‡æª”è™•ç†
     */
    public List<MultilingualDocument> processMultilingualDocuments(List<String> texts) {
        return texts.parallelStream()
            .map(this::processMultilingualDocument)
            .collect(Collectors.toList());
    }
    
    private MultilingualDocument processMultilingualDocument(String text) {
        // 1. èªè¨€æª¢æ¸¬
        LanguageDetectionResult detection = languageDetector.detectLanguage(text);
        
        // 2. èªè¨€ç‰¹å®šè™•ç†
        String processedText = preprocessTextForLanguage(text, detection.getLanguage());
        
        // 3. å‘é‡åŒ–
        EmbeddingModel model = selectModelForLanguage(detection.getLanguage());
        float[] embedding = model.embed(processedText);
        
        return MultilingualDocument.builder()
            .originalText(text)
            .processedText(processedText)
            .language(detection.getLanguage())
            .confidence(detection.getConfidence())
            .embedding(embedding)
            .build();
    }
    
    private EmbeddingModel selectModelForLanguage(String language) {
        // å„ªå…ˆä½¿ç”¨èªè¨€ç‰¹å®šæ¨¡å‹
        EmbeddingModel specificModel = languageSpecificModels.get(language);
        if (specificModel != null) {
            return specificModel;
        }
        
        // å›é€€åˆ°é€šç”¨æ¨¡å‹
        return universalModel;
    }
    
    private String preprocessTextForLanguage(String text, String language) {
        return switch (language.toLowerCase()) {
            case "zh", "zh-cn", "zh-tw" -> preprocessChineseText(text);
            case "ja" -> preprocessJapaneseText(text);
            case "ko" -> preprocessKoreanText(text);
            case "ar" -> preprocessArabicText(text);
            default -> preprocessDefaultText(text);
        };
    }
    
    private String preprocessChineseText(String text) {
        // ä¸­æ–‡ç‰¹å®šé è™•ç†
        return text
            .replaceAll("[ï¼Œã€‚ï¼ï¼Ÿï¼›ï¼š]", " ")  // æ›¿æ›ä¸­æ–‡æ¨™é»
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessJapaneseText(String text) {
        // æ—¥æ–‡ç‰¹å®šé è™•ç†
        return text
            .replaceAll("[ã€ã€‚ï¼ï¼Ÿ]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessKoreanText(String text) {
        // éŸ“æ–‡ç‰¹å®šé è™•ç†
        return text
            .replaceAll("[ï¼Œã€‚ï¼ï¼Ÿ]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessArabicText(String text) {
        // é˜¿æ‹‰ä¼¯æ–‡ç‰¹å®šé è™•ç†ï¼ˆå¾å³åˆ°å·¦ï¼‰
        return text
            .replaceAll("[ØŒã€‚ï¼ØŸ]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessDefaultText(String text) {
        // é è¨­é è™•ç†ï¼ˆä¸»è¦é‡å°æ‹‰ä¸å­—æ¯èªè¨€ï¼‰
        return text
            .toLowerCase()
            .replaceAll("[,.!?;:]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private double calculateCosineSimilarity(float[] vector1, float[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vectors must have the same dimension");
        }
        
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += Math.pow(vector1[i], 2);
            norm2 += Math.pow(vector2[i], 2);
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
```

---

## ğŸ“ æœ¬ç« é‡é»å›é¡§

1. **å‘é‡åŒ–åŸºç¤æ¦‚å¿µ**ï¼šç†è§£äº†æ–‡æœ¬å‘é‡åŒ–çš„æ•¸å­¸åŸç†å’Œç™¼å±•æ­·ç¨‹
2. **Spring AI åµŒå…¥æ¨¡å‹**ï¼šæŒæ¡äº†å¤šç¨®åµŒå…¥æ¨¡å‹çš„é¸æ“‡å’Œé…ç½®
3. **å‘é‡åŒ–æœå‹™å¯¦ç¾**ï¼šå®Œæˆäº†å®Œæ•´çš„å‘é‡åŒ–è™•ç†æœå‹™
4. **å“è³ªè©•ä¼°èˆ‡å„ªåŒ–**ï¼šå»ºç«‹äº†å‘é‡å“è³ªè©•ä¼°å’Œå„ªåŒ–æ©Ÿåˆ¶
5. **å¤šèªè¨€è™•ç†**ï¼šå¯¦ç¾äº†è·¨èªè¨€çš„å‘é‡åŒ–è§£æ±ºæ–¹æ¡ˆ

### æŠ€è¡“è¦é»ç¸½çµ

| æŠ€è¡“é» | é‡è¦æ€§ | å¯¦ç¾é›£åº¦ | ä¼æ¥­åƒ¹å€¼ |
|--------|--------|----------|----------|
| **åµŒå…¥æ¨¡å‹é¸æ“‡** | â­â­â­ | ä¸­ | åŸºç¤å“è³ª |
| **å‘é‡åŒ–æœå‹™** | â­â­â­ | ä¸­ | æ ¸å¿ƒåŠŸèƒ½ |
| **å“è³ªè©•ä¼°** | â­â­ | é«˜ | ç³»çµ±å¯é æ€§ |
| **å¤šèªè¨€æ”¯æ´** | â­â­ | é«˜ | åœ‹éš›åŒ–éœ€æ±‚ |
| **æ•ˆèƒ½å„ªåŒ–** | â­â­ | ä¸­ | ç³»çµ±æ•ˆèƒ½ |

### æœ€ä½³å¯¦è¸å»ºè­°

1. **æ¨¡å‹é¸æ“‡**ï¼šæ ¹æ“šæ‡‰ç”¨å ´æ™¯é¸æ“‡åˆé©çš„åµŒå…¥æ¨¡å‹ï¼Œå¹³è¡¡ç²¾åº¦å’Œæˆæœ¬
2. **å¿«å–ç­–ç•¥**ï¼šå¯¦æ–½å‘é‡å¿«å–ä»¥æé«˜æ•ˆèƒ½å’Œé™ä½ API èª¿ç”¨æˆæœ¬
3. **å“è³ªç›£æ§**ï¼šå»ºç«‹å‘é‡å“è³ªç›£æ§æ©Ÿåˆ¶ï¼ŒåŠæ™‚ç™¼ç¾å’Œè§£æ±ºå•é¡Œ
4. **æ‰¹æ¬¡è™•ç†**ï¼šä½¿ç”¨æ‰¹æ¬¡è™•ç†æé«˜å‘é‡åŒ–æ•ˆç‡
5. **å¤šèªè¨€æ”¯æ´**ï¼šç‚ºåœ‹éš›åŒ–æ‡‰ç”¨æä¾›å¤šèªè¨€å‘é‡åŒ–æ”¯æ´

### ä¸‹ä¸€æ­¥å­¸ç¿’æ–¹å‘

åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘å€‘å°‡å­¸ç¿’ ETLï¼ˆExtract, Transform, Loadï¼‰çš„ä¸Šç¯‡ - RAG çš„çŸ¥è­˜ä¾†æºï¼ŒåŒ…æ‹¬ï¼š
- å¤šç¨®è³‡æ–™ä¾†æºçš„æ•´åˆ
- æ–‡æª”è§£æå’Œé è™•ç†
- è³‡æ–™æ¸…ç†å’Œæ¨™æº–åŒ–
- ETL ç®¡é“çš„è¨­è¨ˆå’Œå¯¦ç¾

---

**åƒè€ƒè³‡æ–™ï¼š**
- [Spring AI Embedding Models](https://docs.spring.io/spring-ai/reference/api/embeddings.html)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Sentence Transformers](https://www.sbert.net/)
- [Vector Similarity Metrics](https://www.pinecone.io/learn/vector-similarity/)