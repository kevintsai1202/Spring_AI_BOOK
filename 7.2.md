# 7.2 如何將內容向量化

> **本章重點**：深入理解文本向量化技術，掌握不同嵌入模型的選擇和使用，學會優化向量品質以提升 RAG 系統效能。

## 🎯 學習目標

完成本章學習後，您將能夠：

- 🎯 **理解向量化原理**：掌握文本向量化的基本概念和數學原理
- 🎯 **選擇合適的嵌入模型**：了解不同嵌入模型的特點和適用場景
- 🎯 **實現向量化處理**：使用 Spring AI 實現高效的文本向量化
- 🎯 **優化向量品質**：掌握向量品質評估和優化技巧
- 🎯 **處理多語言向量化**：實現跨語言的向量化解決方案

---

## 7.2.1 向量化基礎概念

### 什麼是文本向量化？

**文本向量化（Text Embedding）** 是將文本轉換為數值向量的過程，這些向量能夠在高維空間中表示文本的語義資訊。

**核心概念**：
- 📊 **高維表示**：將文本映射到高維向量空間（通常 100-4096 維）
- 🎯 **語義捕捉**：相似意思的文本在向量空間中距離較近
- 🔢 **數值計算**：支援數學運算，如相似性計算、聚類分析
- 🔄 **可比較性**：不同文本可以通過向量距離進行比較

### 向量化的數學原理

**向量相似性計算**：

```
1. 餘弦相似性（Cosine Similarity）
   similarity = (A · B) / (||A|| × ||B||)
   
2. 歐幾里得距離（Euclidean Distance）
   distance = √(Σ(Ai - Bi)²)
   
3. 點積相似性（Dot Product）
   similarity = Σ(Ai × Bi)
```

**向量空間示例**：
```
文本: "Spring Boot 是一個 Java 框架"
向量: [0.2, -0.1, 0.8, 0.3, ..., 0.5]  (1536維)

文本: "Spring Boot is a Java framework"
向量: [0.18, -0.08, 0.82, 0.28, ..., 0.52]  (1536維)

相似性: 0.95 (高度相似)
```

### 向量化的發展歷程

| 技術 | 時期 | 特點 | 維度 | 適用場景 |
|------|------|------|------|----------|
| **One-Hot** | 1950s | 稀疏、高維 | 詞彙表大小 | 簡單分類 |
| **TF-IDF** | 1970s | 統計特徵 | 詞彙表大小 | 資訊檢索 |
| **Word2Vec** | 2013 | 密集向量 | 100-300 | 詞語相似性 |
| **GloVe** | 2014 | 全域統計 | 100-300 | 詞語關係 |
| **BERT** | 2018 | 上下文感知 | 768-1024 | 語義理解 |
| **OpenAI Embeddings** | 2022 | 大規模預訓練 | 1536-3072 | 通用語義 |

---

## 7.2.2 Spring AI 中的嵌入模型

### 支援的嵌入模型

Spring AI 支援多種嵌入模型，每種都有其特點和適用場景：

**1. OpenAI Embeddings**
```java
// OpenAI text-embedding-3-small (最新推薦)
@Bean
public EmbeddingModel openAIEmbeddingModel() {
    var openAiApi = OpenAiApi.builder()
        .apiKey(System.getenv("OPENAI_API_KEY"))
        .build();
    return new OpenAiEmbeddingModel(
        openAiApi,
        MetadataMode.EMBED,
        OpenAiEmbeddingOptions.builder()
            .withModel("text-embedding-3-small")  // 1536 維
            .withDimensions(1536)
            .build(),
        RetryUtils.DEFAULT_RETRY_TEMPLATE
    );
}

// OpenAI text-embedding-3-large (高精度)
@Bean
public EmbeddingModel openAILargeEmbeddingModel() {
    var openAiApi = OpenAiApi.builder()
        .apiKey(System.getenv("OPENAI_API_KEY"))
        .build();
    return new OpenAiEmbeddingModel(
        openAiApi,
        MetadataMode.EMBED,
        OpenAiEmbeddingOptions.builder()
            .withModel("text-embedding-3-large")  // 3072 維
            .withDimensions(3072)
            .build(),
        RetryUtils.DEFAULT_RETRY_TEMPLATE
    );
}
```

**2. Azure OpenAI Embeddings**
```java
@Bean
public EmbeddingModel azureEmbeddingModel() {
    var azureOpenAiApi = AzureOpenAiApi.builder()
        .apiKey(System.getenv("AZURE_OPENAI_API_KEY"))
        .endpoint(System.getenv("AZURE_OPENAI_ENDPOINT"))
        .build();
    return new AzureOpenAiEmbeddingModel(
        azureOpenAiApi,
        MetadataMode.EMBED,
        AzureOpenAiEmbeddingOptions.builder()
            .withDeploymentName("text-embedding-ada-002")
            .withDimensions(1536)
            .build(),
        RetryUtils.DEFAULT_RETRY_TEMPLATE
    );
}
```

**3. Ollama 本地嵌入模型**
```java
@Bean
public EmbeddingModel ollamaEmbeddingModel() {
    var ollamaApi = new OllamaApi();
    return new OllamaEmbeddingModel(
        ollamaApi,
        OllamaOptions.create()
            .withModel("nomic-embed-text")  // 本地模型
    );
}
```

**4. Transformers 嵌入模型**
```java
@Bean
public EmbeddingModel transformersEmbeddingModel() {
    return new TransformersEmbeddingModel(
        TransformersEmbeddingOptions.builder()
            .withModelName("sentence-transformers/all-MiniLM-L6-v2")
            .withDimensions(384)
            .build()
    );
}
```

### 嵌入模型比較

| 模型 | 維度 | 語言支援 | 效能 | 成本 | 適用場景 |
|------|------|----------|------|------|----------|
| **text-embedding-3-small** | 1536 | 多語言 | 高 | 低 | 通用推薦 |
| **text-embedding-3-large** | 3072 | 多語言 | 最高 | 中 | 高精度需求 |
| **text-embedding-ada-002** | 1536 | 多語言 | 高 | 低 | 穩定選擇 |
| **nomic-embed-text** | 768 | 英文為主 | 中 | 免費 | 本地部署 |
| **all-MiniLM-L6-v2** | 384 | 多語言 | 中 | 免費 | 輕量級應用 |

---

## 7.2.3 向量化服務實現

### 基礎向量化服務

```java
/**
 * 文本向量化服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class TextEmbeddingService {
    
    private final EmbeddingModel embeddingModel;
    private final MeterRegistry meterRegistry;
    
    /**
     * 單一文本向量化
     */
    public float[] embedText(String text) {
        if (text == null || text.trim().isEmpty()) {
            throw new IllegalArgumentException("Text cannot be null or empty");
        }
        
        Timer.Sample sample = Timer.start(meterRegistry);
        
        try {
            // 預處理文本
            String processedText = preprocessText(text);
            
            // 生成向量
            float[] embedding = embeddingModel.embed(processedText);
            
            // 記錄指標
            sample.stop(Timer.builder("embedding.generation.time")
                .description("Time to generate text embedding")
                .register(meterRegistry));
            
            meterRegistry.counter("embedding.generation.count").increment();
            
            log.debug("Generated embedding for text: {} chars, vector dim: {}", 
                text.length(), embedding.length);
            
            return embedding;
            
        } catch (Exception e) {
            meterRegistry.counter("embedding.generation.errors").increment();
            log.error("Failed to generate embedding for text: {}", text, e);
            throw new EmbeddingException("Failed to generate embedding", e);
        }
    }
    
    /**
     * 批次文本向量化
     */
    public List<float[]> embedTexts(List<String> texts) {
        if (texts == null || texts.isEmpty()) {
            return Collections.emptyList();
        }
        
        log.info("Generating embeddings for {} texts", texts.size());
        
        Timer.Sample sample = Timer.start(meterRegistry);
        
        try {
            // 預處理所有文本
            List<String> processedTexts = texts.stream()
                .map(this::preprocessText)
                .collect(Collectors.toList());
            
            // 批次生成向量
            List<float[]> embeddings = embeddingModel.embed(processedTexts);
            
            sample.stop(Timer.builder("embedding.batch.generation.time")
                .description("Time to generate batch embeddings")
                .register(meterRegistry));
            
            meterRegistry.counter("embedding.batch.generation.count")
                .increment(texts.size());
            
            log.info("Successfully generated {} embeddings", embeddings.size());
            
            return embeddings;
            
        } catch (Exception e) {
            meterRegistry.counter("embedding.batch.generation.errors").increment();
            log.error("Failed to generate batch embeddings", e);
            throw new EmbeddingException("Failed to generate batch embeddings", e);
        }
    }
    
    /**
     * 文本預處理
     */
    private String preprocessText(String text) {
        if (text == null) {
            return "";
        }
        
        return text
            .trim()
            .replaceAll("\\s+", " ")  // 標準化空白字符
            .replaceAll("[\\r\\n]+", " ")  // 移除換行符
            .substring(0, Math.min(text.length(), 8000));  // 限制長度
    }
    
    /**
     * 計算向量相似性
     */
    public double calculateSimilarity(float[] vector1, float[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vectors must have the same dimension");
        }
        
        // 餘弦相似性計算
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += Math.pow(vector1[i], 2);
            norm2 += Math.pow(vector2[i], 2);
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
```

### 進階向量化處理

```java
/**
 * 進階向量化處理服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class AdvancedEmbeddingService {
    
    private final TextEmbeddingService embeddingService;
    private final RedisTemplate<String, Object> redisTemplate;
    
    private static final String EMBEDDING_CACHE_PREFIX = "embedding:";
    private static final Duration CACHE_TTL = Duration.ofHours(24);
    
    /**
     * 帶快取的向量化
     */
    public float[] embedTextWithCache(String text) {
        String cacheKey = EMBEDDING_CACHE_PREFIX + DigestUtils.md5Hex(text);
        
        // 嘗試從快取取得
        float[] cachedEmbedding = (float[]) redisTemplate.opsForValue().get(cacheKey);
        
        if (cachedEmbedding != null) {
            log.debug("Cache hit for text embedding: {}", cacheKey);
            return cachedEmbedding;
        }
        
        // 快取未命中，生成新向量
        float[] embedding = embeddingService.embedText(text);
        
        // 存入快取
        redisTemplate.opsForValue().set(cacheKey, embedding, CACHE_TTL);
        
        log.debug("Cache miss, generated and cached embedding: {}", cacheKey);
        
        return embedding;
    }
    
    /**
     * 分層向量化處理
     */
    public LayeredEmbedding generateLayeredEmbedding(String text) {
        // 1. 句子級向量化
        List<String> sentences = splitIntoSentences(text);
        List<float[]> sentenceEmbeddings = embeddingService.embedTexts(sentences);
        
        // 2. 段落級向量化
        List<String> paragraphs = splitIntoParagraphs(text);
        List<float[]> paragraphEmbeddings = embeddingService.embedTexts(paragraphs);
        
        // 3. 文檔級向量化
        float[] documentEmbedding = embeddingService.embedText(text);
        
        return LayeredEmbedding.builder()
            .sentences(sentences)
            .sentenceEmbeddings(sentenceEmbeddings)
            .paragraphs(paragraphs)
            .paragraphEmbeddings(paragraphEmbeddings)
            .documentEmbedding(documentEmbedding)
            .build();
    }
    
    /**
     * 多模型向量化
     */
    public MultiModelEmbedding generateMultiModelEmbedding(String text) {
        Map<String, float[]> embeddings = new HashMap<>();
        
        // 使用不同模型生成向量
        try {
            embeddings.put("openai-small", generateWithModel(text, "openai-small"));
            embeddings.put("openai-large", generateWithModel(text, "openai-large"));
            embeddings.put("local-model", generateWithModel(text, "local-model"));
        } catch (Exception e) {
            log.warn("Some embedding models failed", e);
        }
        
        return MultiModelEmbedding.builder()
            .text(text)
            .embeddings(embeddings)
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    /**
     * 向量品質評估
     */
    public EmbeddingQuality assessEmbeddingQuality(float[] embedding, String originalText) {
        // 1. 向量維度檢查
        int dimension = embedding.length;
        boolean validDimension = dimension >= 384 && dimension <= 4096;
        
        // 2. 向量範數檢查
        double norm = calculateVectorNorm(embedding);
        boolean validNorm = norm > 0.1 && norm < 10.0;
        
        // 3. 向量分佈檢查
        double[] stats = calculateVectorStatistics(embedding);
        double mean = stats[0];
        double stdDev = stats[1];
        boolean validDistribution = Math.abs(mean) < 0.5 && stdDev > 0.01;
        
        // 4. 文本長度適配性
        boolean validTextLength = originalText.length() >= 10 && originalText.length() <= 8000;
        
        double qualityScore = calculateQualityScore(
            validDimension, validNorm, validDistribution, validTextLength
        );
        
        return EmbeddingQuality.builder()
            .dimension(dimension)
            .norm(norm)
            .mean(mean)
            .standardDeviation(stdDev)
            .qualityScore(qualityScore)
            .isValid(qualityScore > 0.7)
            .build();
    }
    
    private List<String> splitIntoSentences(String text) {
        // 簡單的句子分割實現
        return Arrays.stream(text.split("[.!?]+"))
            .map(String::trim)
            .filter(s -> !s.isEmpty())
            .collect(Collectors.toList());
    }
    
    private List<String> splitIntoParagraphs(String text) {
        return Arrays.stream(text.split("\\n\\s*\\n"))
            .map(String::trim)
            .filter(s -> !s.isEmpty())
            .collect(Collectors.toList());
    }
    
    private float[] generateWithModel(String text, String modelType) {
        // 根據模型類型選擇不同的嵌入模型
        // 這裡簡化實現，實際應用中需要注入不同的模型
        return embeddingService.embedText(text);
    }
    
    private double calculateVectorNorm(float[] vector) {
        double sum = 0.0;
        for (float value : vector) {
            sum += value * value;
        }
        return Math.sqrt(sum);
    }
    
    private double[] calculateVectorStatistics(float[] vector) {
        // 計算平均值
        double sum = 0.0;
        for (float value : vector) {
            sum += value;
        }
        double mean = sum / vector.length;
        
        // 計算方差
        double varianceSum = 0.0;
        for (float value : vector) {
            varianceSum += Math.pow(value - mean, 2);
        }
        double variance = varianceSum / vector.length;
        double stdDev = Math.sqrt(variance);
        
        return new double[]{mean, stdDev};
    }
    
    private double calculateQualityScore(boolean... checks) {
        long passedChecks = Arrays.stream(checks)
            .mapToInt(b -> b ? 1 : 0)
            .sum();
        
        return (double) passedChecks / checks.length;
    }
}
```

---

## 7.2.4 向量化配置與優化

### 向量化配置類

```java
/**
 * 向量化配置
 */
@Configuration
@EnableConfigurationProperties(EmbeddingProperties.class)
public class EmbeddingConfig {
    
    /**
     * 主要嵌入模型配置
     */
    @Bean
    @Primary
    public EmbeddingModel primaryEmbeddingModel(EmbeddingProperties properties) {
        EmbeddingProperties.ModelConfig config = properties.getPrimary();
        
        return switch (config.getProvider().toLowerCase()) {
            case "openai" -> createOpenAIEmbeddingModel(config);
            case "azure" -> createAzureEmbeddingModel(config);
            case "ollama" -> createOllamaEmbeddingModel(config);
            case "transformers" -> createTransformersEmbeddingModel(config);
            default -> throw new IllegalArgumentException("Unsupported embedding provider: " + config.getProvider());
        };
    }
    
    /**
     * 備用嵌入模型配置
     */
    @Bean
    @Qualifier("fallback")
    public EmbeddingModel fallbackEmbeddingModel(EmbeddingProperties properties) {
        EmbeddingProperties.ModelConfig config = properties.getFallback();
        
        if (config == null) {
            // 預設使用本地模型作為備用
            return new TransformersEmbeddingModel(
                TransformersEmbeddingOptions.builder()
                    .withModelName("sentence-transformers/all-MiniLM-L6-v2")
                    .withDimensions(384)
                    .build()
            );
        }
        
        return createEmbeddingModel(config);
    }
    
    /**
     * 向量化快取配置
     */
    @Bean
    public CacheManager embeddingCacheManager() {
        RedisCacheManager.Builder builder = RedisCacheManager
            .RedisCacheManagerBuilder
            .fromConnectionFactory(redisConnectionFactory())
            .cacheDefaults(cacheConfiguration());
        
        return builder.build();
    }
    
    private RedisCacheConfiguration cacheConfiguration() {
        return RedisCacheConfiguration.defaultCacheConfig()
            .entryTtl(Duration.ofHours(24))
            .serializeKeysWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new StringRedisSerializer()))
            .serializeValuesWith(RedisSerializationContext.SerializationPair
                .fromSerializer(new GenericJackson2JsonRedisSerializer()));
    }
    
    private EmbeddingModel createOpenAIEmbeddingModel(EmbeddingProperties.ModelConfig config) {
        OpenAiApi openAiApi = OpenAiApi.builder()
            .apiKey(config.getApiKey())
            .build();
            
        return new OpenAiEmbeddingModel(
            openAiApi,
            MetadataMode.EMBED,
            OpenAiEmbeddingOptions.builder()
                .withModel(config.getModelName())
                .withDimensions(config.getDimensions())
                .build(),
            RetryUtils.DEFAULT_RETRY_TEMPLATE
        );
    }
    
    // 其他模型創建方法...
}
```

### 向量化配置屬性

```java
/**
 * 向量化配置屬性
 */
@ConfigurationProperties(prefix = "app.embedding")
@Data
@Validated
public class EmbeddingProperties {
    
    /**
     * 主要嵌入模型配置
     */
    @NotNull
    private ModelConfig primary;
    
    /**
     * 備用嵌入模型配置
     */
    private ModelConfig fallback;
    
    /**
     * 快取配置
     */
    private CacheConfig cache = new CacheConfig();
    
    /**
     * 批次處理配置
     */
    private BatchConfig batch = new BatchConfig();
    
    @Data
    @Validated
    public static class ModelConfig {
        @NotBlank
        private String provider;  // openai, azure, ollama, transformers
        
        @NotBlank
        private String modelName;
        
        @Min(100)
        @Max(4096)
        private int dimensions;
        
        private String apiKey;
        private String endpoint;
        private Duration timeout = Duration.ofSeconds(30);
    }
    
    @Data
    public static class CacheConfig {
        private boolean enabled = true;
        private Duration ttl = Duration.ofHours(24);
        private int maxSize = 10000;
    }
    
    @Data
    public static class BatchConfig {
        private int size = 100;
        private Duration timeout = Duration.ofMinutes(5);
        private int retries = 3;
    }
}
```

### 應用配置檔案

```yaml
# application.yml
app:
  embedding:
    primary:
      provider: openai
      model-name: text-embedding-3-small
      dimensions: 1536
      api-key: ${OPENAI_API_KEY}
      timeout: 30s
    
    fallback:
      provider: transformers
      model-name: sentence-transformers/all-MiniLM-L6-v2
      dimensions: 384
      timeout: 60s
    
    cache:
      enabled: true
      ttl: 24h
      max-size: 10000
    
    batch:
      size: 100
      timeout: 5m
      retries: 3

# 開發環境配置
---
spring:
  config:
    activate:
      on-profile: dev

app:
  embedding:
    primary:
      provider: transformers
      model-name: sentence-transformers/all-MiniLM-L6-v2
      dimensions: 384
    cache:
      enabled: false

# 生產環境配置
---
spring:
  config:
    activate:
      on-profile: prod

app:
  embedding:
    primary:
      provider: openai
      model-name: text-embedding-3-large
      dimensions: 3072
      api-key: ${OPENAI_API_KEY}
    
    fallback:
      provider: azure
      model-name: text-embedding-ada-002
      dimensions: 1536
      api-key: ${AZURE_OPENAI_API_KEY}
      endpoint: ${AZURE_OPENAI_ENDPOINT}
```

---

## 7.2.5 向量品質評估與優化

### 向量品質評估服務

```java
/**
 * 向量品質評估服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class EmbeddingQualityService {
    
    private final TextEmbeddingService embeddingService;
    
    /**
     * 綜合品質評估
     */
    public QualityAssessmentResult assessEmbeddingQuality(
            List<String> testTexts, 
            List<String> expectedSimilarTexts) {
        
        log.info("Starting embedding quality assessment with {} test cases", testTexts.size());
        
        List<QualityMetric> metrics = new ArrayList<>();
        
        for (int i = 0; i < testTexts.size(); i++) {
            String testText = testTexts.get(i);
            String expectedSimilar = expectedSimilarTexts.get(i);
            
            QualityMetric metric = assessSinglePair(testText, expectedSimilar);
            metrics.add(metric);
        }
        
        return QualityAssessmentResult.builder()
            .totalTests(testTexts.size())
            .metrics(metrics)
            .averageSimilarity(calculateAverageSimilarity(metrics))
            .qualityScore(calculateOverallQuality(metrics))
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    /**
     * 單一文本對評估
     */
    private QualityMetric assessSinglePair(String text1, String text2) {
        try {
            // 生成向量
            float[] embedding1 = embeddingService.embedText(text1);
            float[] embedding2 = embeddingService.embedText(text2);
            
            // 計算相似性
            double similarity = embeddingService.calculateSimilarity(embedding1, embedding2);
            
            // 評估向量品質
            EmbeddingQuality quality1 = assessVectorQuality(embedding1, text1);
            EmbeddingQuality quality2 = assessVectorQuality(embedding2, text2);
            
            return QualityMetric.builder()
                .text1(text1)
                .text2(text2)
                .similarity(similarity)
                .quality1(quality1)
                .quality2(quality2)
                .isValid(similarity > 0.7 && quality1.isValid() && quality2.isValid())
                .build();
                
        } catch (Exception e) {
            log.error("Failed to assess quality for text pair", e);
            return QualityMetric.builder()
                .text1(text1)
                .text2(text2)
                .similarity(0.0)
                .isValid(false)
                .error(e.getMessage())
                .build();
        }
    }
    
    /**
     * 向量品質評估
     */
    private EmbeddingQuality assessVectorQuality(float[] embedding, String originalText) {
        // 1. 維度檢查
        int dimension = embedding.length;
        boolean validDimension = dimension >= 384;
        
        // 2. 數值範圍檢查
        float min = Float.MAX_VALUE;
        float max = Float.MIN_VALUE;
        for (float value : embedding) {
            min = Math.min(min, value);
            max = Math.max(max, value);
        }
        boolean validRange = min >= -2.0f && max <= 2.0f;
        
        // 3. 向量範數檢查
        double norm = 0.0;
        for (float value : embedding) {
            norm += value * value;
        }
        norm = Math.sqrt(norm);
        boolean validNorm = norm > 0.1 && norm < 10.0;
        
        // 4. 零向量檢查
        boolean notZeroVector = false;
        for (float value : embedding) {
            if (Math.abs(value) > 1e-6) {
                notZeroVector = true;
                break;
            }
        }
        
        // 5. 文本長度適配性
        boolean validTextLength = originalText.length() >= 5;
        
        double qualityScore = calculateQualityScore(
            validDimension, validRange, validNorm, notZeroVector, validTextLength
        );
        
        return EmbeddingQuality.builder()
            .dimension(dimension)
            .norm(norm)
            .minValue(min)
            .maxValue(max)
            .qualityScore(qualityScore)
            .isValid(qualityScore > 0.8)
            .validDimension(validDimension)
            .validRange(validRange)
            .validNorm(validNorm)
            .notZeroVector(notZeroVector)
            .validTextLength(validTextLength)
            .build();
    }
    
    /**
     * 語義一致性測試
     */
    public SemanticConsistencyResult testSemanticConsistency() {
        // 準備測試案例
        Map<String, List<String>> testCases = prepareSemanticTestCases();
        
        List<ConsistencyTest> results = new ArrayList<>();
        
        for (Map.Entry<String, List<String>> entry : testCases.entrySet()) {
            String category = entry.getKey();
            List<String> texts = entry.getValue();
            
            ConsistencyTest test = testCategoryConsistency(category, texts);
            results.add(test);
        }
        
        return SemanticConsistencyResult.builder()
            .tests(results)
            .overallScore(calculateConsistencyScore(results))
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    private Map<String, List<String>> prepareSemanticTestCases() {
        Map<String, List<String>> testCases = new HashMap<>();
        
        // 技術相關
        testCases.put("technology", Arrays.asList(
            "Spring Boot 是一個 Java 框架",
            "Spring Boot is a Java framework",
            "Spring Boot 框架用於 Java 開發",
            "Java Spring Boot 應用程式框架"
        ));
        
        // 商業相關
        testCases.put("business", Arrays.asList(
            "提高銷售業績的策略",
            "增加營收的方法",
            "銷售成長策略",
            "業績提升計劃"
        ));
        
        return testCases;
    }
    
    private ConsistencyTest testCategoryConsistency(String category, List<String> texts) {
        List<float[]> embeddings = embeddingService.embedTexts(texts);
        
        // 計算所有文本對之間的相似性
        List<Double> similarities = new ArrayList<>();
        
        for (int i = 0; i < embeddings.size(); i++) {
            for (int j = i + 1; j < embeddings.size(); j++) {
                double similarity = embeddingService.calculateSimilarity(
                    embeddings.get(i), embeddings.get(j)
                );
                similarities.add(similarity);
            }
        }
        
        double averageSimilarity = similarities.stream()
            .mapToDouble(Double::doubleValue)
            .average()
            .orElse(0.0);
        
        double minSimilarity = similarities.stream()
            .mapToDouble(Double::doubleValue)
            .min()
            .orElse(0.0);
        
        return ConsistencyTest.builder()
            .category(category)
            .texts(texts)
            .similarities(similarities)
            .averageSimilarity(averageSimilarity)
            .minSimilarity(minSimilarity)
            .isConsistent(averageSimilarity > 0.7 && minSimilarity > 0.5)
            .build();
    }
    
    private double calculateAverageSimilarity(List<QualityMetric> metrics) {
        return metrics.stream()
            .mapToDouble(QualityMetric::getSimilarity)
            .average()
            .orElse(0.0);
    }
    
    private double calculateOverallQuality(List<QualityMetric> metrics) {
        long validCount = metrics.stream()
            .mapToLong(m -> m.isValid() ? 1 : 0)
            .sum();
        
        return (double) validCount / metrics.size();
    }
    
    private double calculateQualityScore(boolean... checks) {
        long passedChecks = Arrays.stream(checks)
            .mapToInt(b -> b ? 1 : 0)
            .sum();
        
        return (double) passedChecks / checks.length;
    }
    
    private double calculateConsistencyScore(List<ConsistencyTest> tests) {
        return tests.stream()
            .mapToDouble(ConsistencyTest::getAverageSimilarity)
            .average()
            .orElse(0.0);
    }
}
```

---

## 7.2.6 多語言向量化處理

### 多語言向量化服務

```java
/**
 * 多語言向量化服務
 */
@Service
@RequiredArgsConstructor
@Slf4j
public class MultilingualEmbeddingService {
    
    private final Map<String, EmbeddingModel> languageSpecificModels;
    private final EmbeddingModel universalModel;
    private final LanguageDetectionService languageDetector;
    
    /**
     * 自動語言檢測向量化
     */
    public MultilingualEmbedding embedWithLanguageDetection(String text) {
        // 1. 檢測語言
        LanguageDetectionResult detection = languageDetector.detectLanguage(text);
        
        // 2. 選擇合適的模型
        EmbeddingModel selectedModel = selectModelForLanguage(detection.getLanguage());
        
        // 3. 生成向量
        float[] embedding = selectedModel.embed(text);
        
        return MultilingualEmbedding.builder()
            .text(text)
            .detectedLanguage(detection.getLanguage())
            .confidence(detection.getConfidence())
            .embedding(embedding)
            .modelUsed(selectedModel.getClass().getSimpleName())
            .timestamp(LocalDateTime.now())
            .build();
    }
    
    /**
     * 跨語言相似性計算
     */
    public CrossLanguageSimilarity calculateCrossLanguageSimilarity(
            String text1, String lang1,
            String text2, String lang2) {
        
        // 使用通用多語言模型
        float[] embedding1 = universalModel.embed(text1);
        float[] embedding2 = universalModel.embed(text2);
        
        double similarity = calculateCosineSimilarity(embedding1, embedding2);
        
        return CrossLanguageSimilarity.builder()
            .text1(text1)
            .language1(lang1)
            .text2(text2)
            .language2(lang2)
            .similarity(similarity)
            .embedding1(embedding1)
            .embedding2(embedding2)
            .build();
    }
    
    /**
     * 多語言文檔處理
     */
    public List<MultilingualDocument> processMultilingualDocuments(List<String> texts) {
        return texts.parallelStream()
            .map(this::processMultilingualDocument)
            .collect(Collectors.toList());
    }
    
    private MultilingualDocument processMultilingualDocument(String text) {
        // 1. 語言檢測
        LanguageDetectionResult detection = languageDetector.detectLanguage(text);
        
        // 2. 語言特定處理
        String processedText = preprocessTextForLanguage(text, detection.getLanguage());
        
        // 3. 向量化
        EmbeddingModel model = selectModelForLanguage(detection.getLanguage());
        float[] embedding = model.embed(processedText);
        
        return MultilingualDocument.builder()
            .originalText(text)
            .processedText(processedText)
            .language(detection.getLanguage())
            .confidence(detection.getConfidence())
            .embedding(embedding)
            .build();
    }
    
    private EmbeddingModel selectModelForLanguage(String language) {
        // 優先使用語言特定模型
        EmbeddingModel specificModel = languageSpecificModels.get(language);
        if (specificModel != null) {
            return specificModel;
        }
        
        // 回退到通用模型
        return universalModel;
    }
    
    private String preprocessTextForLanguage(String text, String language) {
        return switch (language.toLowerCase()) {
            case "zh", "zh-cn", "zh-tw" -> preprocessChineseText(text);
            case "ja" -> preprocessJapaneseText(text);
            case "ko" -> preprocessKoreanText(text);
            case "ar" -> preprocessArabicText(text);
            default -> preprocessDefaultText(text);
        };
    }
    
    private String preprocessChineseText(String text) {
        // 中文特定預處理
        return text
            .replaceAll("[，。！？；：]", " ")  // 替換中文標點
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessJapaneseText(String text) {
        // 日文特定預處理
        return text
            .replaceAll("[、。！？]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessKoreanText(String text) {
        // 韓文特定預處理
        return text
            .replaceAll("[，。！？]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessArabicText(String text) {
        // 阿拉伯文特定預處理（從右到左）
        return text
            .replaceAll("[،。！؟]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private String preprocessDefaultText(String text) {
        // 預設預處理（主要針對拉丁字母語言）
        return text
            .toLowerCase()
            .replaceAll("[,.!?;:]", " ")
            .replaceAll("\\s+", " ")
            .trim();
    }
    
    private double calculateCosineSimilarity(float[] vector1, float[] vector2) {
        if (vector1.length != vector2.length) {
            throw new IllegalArgumentException("Vectors must have the same dimension");
        }
        
        double dotProduct = 0.0;
        double norm1 = 0.0;
        double norm2 = 0.0;
        
        for (int i = 0; i < vector1.length; i++) {
            dotProduct += vector1[i] * vector2[i];
            norm1 += Math.pow(vector1[i], 2);
            norm2 += Math.pow(vector2[i], 2);
        }
        
        return dotProduct / (Math.sqrt(norm1) * Math.sqrt(norm2));
    }
}
```

---

## 📝 本章重點回顧

1. **向量化基礎概念**：理解了文本向量化的數學原理和發展歷程
2. **Spring AI 嵌入模型**：掌握了多種嵌入模型的選擇和配置
3. **向量化服務實現**：完成了完整的向量化處理服務
4. **品質評估與優化**：建立了向量品質評估和優化機制
5. **多語言處理**：實現了跨語言的向量化解決方案

### 技術要點總結

| 技術點 | 重要性 | 實現難度 | 企業價值 |
|--------|--------|----------|----------|
| **嵌入模型選擇** | ⭐⭐⭐ | 中 | 基礎品質 |
| **向量化服務** | ⭐⭐⭐ | 中 | 核心功能 |
| **品質評估** | ⭐⭐ | 高 | 系統可靠性 |
| **多語言支援** | ⭐⭐ | 高 | 國際化需求 |
| **效能優化** | ⭐⭐ | 中 | 系統效能 |

### 最佳實踐建議

1. **模型選擇**：根據應用場景選擇合適的嵌入模型，平衡精度和成本
2. **快取策略**：實施向量快取以提高效能和降低 API 調用成本
3. **品質監控**：建立向量品質監控機制，及時發現和解決問題
4. **批次處理**：使用批次處理提高向量化效率
5. **多語言支援**：為國際化應用提供多語言向量化支援

### 下一步學習方向

在下一章中，我們將學習 ETL（Extract, Transform, Load）的上篇 - RAG 的知識來源，包括：
- 多種資料來源的整合
- 文檔解析和預處理
- 資料清理和標準化
- ETL 管道的設計和實現

---

**參考資料：**
- [Spring AI Embedding Models](https://docs.spring.io/spring-ai/reference/api/embeddings.html)
- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [Sentence Transformers](https://www.sbert.net/)
- [Vector Similarity Metrics](https://www.pinecone.io/learn/vector-similarity/)