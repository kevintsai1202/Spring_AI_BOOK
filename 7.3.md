# 7.3 ETL (上) - RAG 的知識來源

> **本章重點**：深入探討 RAG 系統的各種知識來源，掌握 ETL 流程中的資料提取（Extract）技術，學會整合多元化的企業資料來源。

## 🎯 學習目標

完成本章學習後，您將能夠：

- 🎯 **理解 ETL 基礎概念**：掌握 Extract、Transform、Load 的完整流程
- 🎯 **識別知識來源類型**：了解企業中各種資料來源的特點和挑戰
- 🎯 **實現資料提取器**：開發多種資料來源的提取器
- 🎯 **設計 ETL 架構**：建立可擴展的 ETL 系統架構
- 🎯 **處理資料品質**：掌握資料清理和品質控制技術

---

## 7.3.1 ETL 基礎概念

### 什麼是 ETL？

**ETL（Extract, Transform, Load）** 是資料處理的核心流程，在 RAG 系統中扮演著將原始資料轉換為可搜尋知識的關鍵角色。

**ETL 三階段**：

```
┌─────────────────────────────────────────────────────────────┐
│                    ETL Process Flow                         │
├─────────────────────────────────────────────────────────────┤
│  Extract (提取)                                             │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  • 從各種資料來源提取原始資料                           │ │
│  │  • 處理不同格式和協議                                   │ │
│  │  • 確保資料完整性和一致性                               │ │
│  └─────────────────────────────────────────────────────────┘ │
│                            ↓                                │
│  Transform (轉換)                                           │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  • 清理和標準化資料                                     │ │
│  │  • 文本分塊和預處理                                     │ │
│  │  • 元資料增強和標記                                     │ │
│  │  • 向量化處理                                           │ │
│  └─────────────────────────────────────────────────────────┘ │
│                            ↓                                │
│  Load (載入)                                                │
│  ┌─────────────────────────────────────────────────────────┐ │
│  │  • 存儲到向量資料庫                                     │ │
│  │  • 建立索引和關聯                                       │ │
│  │  • 更新知識庫                                           │ │
│  └─────────────────────────────────────────────────────────┘ │
└─────────────────────────────────────────────────────────────┘
```

### RAG 中的 ETL 特點

**傳統 ETL vs RAG ETL**：

| 特性 | 傳統 ETL | RAG ETL |
|------|----------|----------|
| **資料類型** | 結構化資料 | 非結構化文本 |
| **處理重點** | 資料清理、格式轉換 | 文本理解、語義提取 |
| **輸出格式** | 關聯式表格 | 向量嵌入 |
| **更新頻率** | 批次處理 | 即時/近即時 |
| **品質指標** | 完整性、一致性 | 語義準確性、相關性 |

---

## 7.3.2 企業知識來源分類

### 文檔類資料來源

**1. 辦公文檔**
```
• Microsoft Office 文件
  - Word (.docx, .doc)
  - Excel (.xlsx, .xls)
  - PowerPoint (.pptx, .ppt)
  
• PDF 文檔
  - 文本型 PDF
  - 掃描型 PDF (需 OCR)
  - 受保護 PDF
  
• 純文本文件
  - TXT, RTF
  - Markdown (.md)
  - CSV, TSV
```

**2. 技術文檔**
```
• 程式碼文檔
  - README.md
  - API 文檔
  - 程式碼註解
  
• 設計文檔
  - 系統架構圖
  - 流程圖
  - UML 圖表
```

### 網路資源

**1. 企業網站**
```
• 官方網站內容
• 產品說明頁面
• 常見問題 (FAQ)
• 部落格文章
• 新聞發布
```

**2. 內部系統**
```
• Wiki 系統
• 知識庫平台
• 內部論壇
• 專案管理系統
```

### 資料庫資源

**1. 關聯式資料庫**
```
• 客戶資料
• 產品資訊
• 交易記錄
• 日誌資料
```

**2. NoSQL 資料庫**
```
• MongoDB 文檔
• Elasticsearch 索引
• Redis 快取資料
```

### API 和服務

**1. REST API**
```
• 第三方服務 API
• 內部微服務
• 雲端服務 API
```

**2. 即時資料流**
```
• Kafka 訊息
• WebSocket 資料
• 事件流
```

---

## 7.3.3 資料提取器架構設計

### Spring AI ETL 架構設計

根據 Spring AI 官方文檔，ETL 架構包含三個核心介面：

```java
/**
 * 文檔讀取器 - 提供文檔來源
 */
public interface DocumentReader extends Supplier<List<Document>> {
    default List<Document> read() {
        return get();
    }
}

/**
 * 文檔轉換器 - 處理文檔轉換
 */
public interface DocumentTransformer extends Function<List<Document>, List<Document>> {
    default List<Document> transform(List<Document> documents) {
        return apply(documents);
    }
}

/**
 * 文檔寫入器 - 管理最終儲存
 */
public interface DocumentWriter extends Consumer<List<Document>> {
    default void write(List<Document> documents) {
        accept(documents);
    }
}
```

### Spring AI Document 模型

```java
/**
 * Spring AI 文檔模型
 */
public class Document {
    private String content;
    private Map<String, Object> metadata;
    private String id;
    
    // 建構子
    public Document(String content) {
        this(content, new HashMap<>());
    }
    
    public Document(String content, Map<String, Object> metadata) {
        this.content = content;
        this.metadata = metadata;
        this.id = UUID.randomUUID().toString();
    }
    
    // getter/setter 方法
    public String getContent() { return content; }
    public Map<String, Object> getMetadata() { return metadata; }
    public String getId() { return id; }
}
```

### ETL 管道組合

```java
/**
 * ETL 管道範例
 */
@Component
@Slf4j
public class EtlPipelineService {
    
    private final VectorStore vectorStore;
    
    public EtlPipelineService(VectorStore vectorStore) {
        this.vectorStore = vectorStore;
    }
    
    /**
     * 基本 ETL 流程
     */
    public void processDocuments(Resource resource) {
        // 1. Extract - 使用適當的 DocumentReader
        DocumentReader reader = createReader(resource);
        List<Document> documents = reader.read();
        
        // 2. Transform - 使用 DocumentTransformer
        TokenTextSplitter splitter = new TokenTextSplitter();
        List<Document> transformedDocs = splitter.transform(documents);
        
        // 3. Load - 寫入向量資料庫
        vectorStore.write(transformedDocs);
        
        log.info("Processed {} documents through ETL pipeline", documents.size());
    }
    
    /**
     * 函數式風格的 ETL 流程
     */
    public void processFunctionalStyle(Resource resource) {
        DocumentReader reader = createReader(resource);
        TokenTextSplitter splitter = new TokenTextSplitter();
        
        // 函數式組合
        vectorStore.accept(splitter.apply(reader.get()));
    }
    
    private DocumentReader createReader(Resource resource) {
        String filename = resource.getFilename();
        if (filename != null) {
            if (filename.endsWith(".pdf")) {
                return new PagePdfDocumentReader(resource);
            } else if (filename.endsWith(".txt")) {
                return new TextReader(resource);
            } else if (filename.endsWith(".docx") || filename.endsWith(".doc")) {
                return new TikaDocumentReader(resource);
            }
        }
        throw new IllegalArgumentException("Unsupported file type: " + filename);
    }
}
```

---

## 7.3.4 Spring AI DocumentReader 實現

### PDF 文檔讀取器

#### 依賴配置

首先添加 PDF 文檔讀取器依賴：

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-pdf-document-reader</artifactId>
</dependency>
```

#### PagePdfDocumentReader 實現

```java
/**
 * PDF 頁面文檔讀取器範例
 */
@Component
@Slf4j
public class PdfDocumentService {
    
    
    /**
     * 基本 PDF 文檔讀取
     */
    public List<Document> readPdfDocument(Resource pdfResource) {
        log.info("Reading PDF document: {}", pdfResource.getFilename());
        
        PagePdfDocumentReader pdfReader = new PagePdfDocumentReader(pdfResource,
            PdfDocumentReaderConfig.builder()
                .withPageTopMargin(0)
                .withPageExtractedTextFormatter(ExtractedTextFormatter.builder()
                    .withNumberOfTopTextLinesToDelete(0)
                    .build())
                .withPagesPerDocument(1) // 每頁一個文檔
                .build());
        
        return pdfReader.read();
    }
    
    /**
     * 使用段落分割的 PDF 讀取
     */
    public List<Document> readPdfWithParagraphs(Resource pdfResource) {
        log.info("Reading PDF with paragraph splitting: {}", pdfResource.getFilename());
        
        ParagraphPdfDocumentReader pdfReader = new ParagraphPdfDocumentReader(pdfResource,
            PdfDocumentReaderConfig.builder()
                .withPageTopMargin(0)
                .withPageExtractedTextFormatter(ExtractedTextFormatter.builder()
                    .withNumberOfTopTextLinesToDelete(0)
                    .build())
                .build());
        
        return pdfReader.read();
    }
    
    /**
     * 進階 PDF 配置範例
     */
    public List<Document> readPdfWithAdvancedConfig(Resource pdfResource) {
        PdfDocumentReaderConfig config = PdfDocumentReaderConfig.builder()
            .withPageTopMargin(50)  // 頁面上邊距
            .withPageBottomMargin(50) // 頁面下邊距
            .withPageExtractedTextFormatter(
                ExtractedTextFormatter.builder()
                    .withNumberOfTopTextLinesToDelete(2) // 刪除頂部行數
                    .withNumberOfBottomTextLinesToDelete(1) // 刪除底部行數
                    .build())
            .withPagesPerDocument(3) // 每3頁合併為一個文檔
            .build();
        
        PagePdfDocumentReader pdfReader = new PagePdfDocumentReader(pdfResource, config);
        return pdfReader.read();
    }
    
    /**
     * PDF 文檔處理的完整範例
     */
    public void processMultiplePdfs(List<Resource> pdfResources) {
        for (Resource resource : pdfResources) {
            try {
                List<Document> documents = readPdfDocument(resource);
                
                // 添加自定義元資料
                documents.forEach(doc -> {
                    doc.getMetadata().put("source_file", resource.getFilename());
                    doc.getMetadata().put("processed_at", LocalDateTime.now().toString());
                    doc.getMetadata().put("content_type", "PDF");
                });
                
                log.info("Successfully processed PDF: {} with {} documents", 
                    resource.getFilename(), documents.size());
                
            } catch (Exception e) {
                log.error("Failed to process PDF: {}", resource.getFilename(), e);
            }
        }
    }
    
}

/**
 * PDF 配置類別
 */
@Configuration
public class PdfReaderConfiguration {
    
    /**
     * 默認 PDF 文檔讀取器
     */
    @Bean
    public PagePdfDocumentReader defaultPdfReader(@Value("classpath:sample.pdf") Resource pdfResource) {
        return new PagePdfDocumentReader(pdfResource);
    }
    
    /**
     * 自定義配置的 PDF 文檔讀取器
     */
    @Bean("customPdfReader")
    public PagePdfDocumentReader customPdfReader(@Value("classpath:complex.pdf") Resource pdfResource) {
        PdfDocumentReaderConfig config = PdfDocumentReaderConfig.builder()
            .withPageTopMargin(100)
            .withPageBottomMargin(100)
            .withPageExtractedTextFormatter(
                ExtractedTextFormatter.builder()
                    .withNumberOfTopTextLinesToDelete(3)
                    .withNumberOfBottomTextLinesToDelete(2)
                    .withLeftAlignment(true)
                    .build())
            .withPagesPerDocument(2)
            .build();
        
        return new PagePdfDocumentReader(pdfResource, config);
    }
}
```

### Tika 文檔讀取器

#### 依賴配置

```xml
<dependency>
    <groupId>org.springframework.ai</groupId>
    <artifactId>spring-ai-tika-document-reader</artifactId>
</dependency>
```

#### TikaDocumentReader 實現

```java
/**
 * 使用 Tika 處理多種文檔格式
 */
@Component
@Slf4j
public class TikaDocumentService {
    
    
    /**
     * 使用 TikaDocumentReader 讀取 Word 文檔
     */
    public List<Document> readWordDocument(Resource wordResource) {
        log.info("Reading Word document with Tika: {}", wordResource.getFilename());
        
        TikaDocumentReader tikaReader = new TikaDocumentReader(wordResource);
        List<Document> documents = tikaReader.read();
        
        // 添加自定義元資料
        documents.forEach(doc -> {
            doc.getMetadata().put("document_type", "WORD");
            doc.getMetadata().put("source_file", wordResource.getFilename());
            doc.getMetadata().put("processed_with", "Apache Tika");
        });
        
        return documents;
    }
    
    /**
     * 讀取 PowerPoint 文檔
     */
    public List<Document> readPowerPointDocument(Resource pptResource) {
        log.info("Reading PowerPoint document with Tika: {}", pptResource.getFilename());
        
        TikaDocumentReader tikaReader = new TikaDocumentReader(pptResource);
        List<Document> documents = tikaReader.read();
        
        documents.forEach(doc -> {
            doc.getMetadata().put("document_type", "POWERPOINT");
            doc.getMetadata().put("source_file", pptResource.getFilename());
        });
        
        return documents;
    }
    
    /**
     * 讀取多種格式的文檔
     */
    public List<Document> readDocuments(List<Resource> resources) {
        List<Document> allDocuments = new ArrayList<>();
        
        for (Resource resource : resources) {
            try {
                String filename = resource.getFilename();
                if (filename != null) {
                    List<Document> docs;
                    
                    if (filename.toLowerCase().matches(".*\\.(docx?|pptx?|xlsx?)$")) {
                        // Microsoft Office 文檔
                        docs = readOfficeDocument(resource);
                    } else if (filename.toLowerCase().endsWith(".pdf")) {
                        // PDF 文檔使用專用讀取器
                        continue; // PDF 由 PdfDocumentService 處理
                    } else {
                        // 其他格式嘗試用 Tika
                        docs = readGenericDocument(resource);
                    }
                    
                    allDocuments.addAll(docs);
                    log.info("Processed {} documents from {}", docs.size(), filename);
                }
            } catch (Exception e) {
                log.error("Failed to process document: {}", resource.getFilename(), e);
            }
        }
        
        return allDocuments;
    }
    
    private List<Document> readOfficeDocument(Resource resource) {
        TikaDocumentReader tikaReader = new TikaDocumentReader(resource);
        return tikaReader.read();
    }
    
    private List<Document> readGenericDocument(Resource resource) {
        TikaDocumentReader tikaReader = new TikaDocumentReader(resource);
        return tikaReader.read();
    }
    
}

/**
 * Text 文檔讀取器範例
 */
@Component
@Slf4j
public class TextDocumentService {
    
    /**
     * 讀取純文字檔案
     */
    public List<Document> readTextFile(Resource textResource) {
        log.info("Reading text file: {}", textResource.getFilename());
        
        TextReader textReader = new TextReader(textResource);
        
        // 設置字符編碼
        textReader.setCharset(StandardCharsets.UTF_8);
        
        // 添加自定義元資料
        textReader.getCustomMetadata().put("filename", textResource.getFilename());
        textReader.getCustomMetadata().put("content_type", "TEXT");
        
        return textReader.read();
    }
    
    /**
     * 讀取 Markdown 文件
     */
    public List<Document> readMarkdownFile(Resource markdownResource) {
        log.info("Reading markdown file: {}", markdownResource.getFilename());
        
        MarkdownDocumentReaderConfig config = MarkdownDocumentReaderConfig.builder()
            .withHorizontalRuleCreateDocument(true) // 水平線分割文檔
            .withIncludeCodeBlock(true)  // 包含程式碼區塊
            .withIncludeBlockquote(true) // 包含引用區塊
            .withAdditionalMetadata("filename", markdownResource.getFilename())
            .build();
        
        MarkdownDocumentReader markdownReader = new MarkdownDocumentReader(markdownResource, config);
        return markdownReader.read();
    }
    
    /**
     * 讀取 JSON 文件
     */
    public List<Document> readJsonFile(Resource jsonResource, String... jsonKeysToUse) {
        log.info("Reading JSON file: {}", jsonResource.getFilename());
        
        JsonReader jsonReader = new JsonReader(jsonResource, jsonKeysToUse);
        return jsonReader.read();
    }
    
    /**
     * 使用 JSON Pointer 讀取特定部分
     */
    public List<Document> readJsonWithPointer(Resource jsonResource, String jsonPointer, String... jsonKeysToUse) {
        log.info("Reading JSON file with pointer {}: {}", jsonPointer, jsonResource.getFilename());
        
        JsonReader jsonReader = new JsonReader(jsonResource, jsonKeysToUse);
        return jsonReader.get(jsonPointer);
    }
    
}

/**
 * HTML 文檔讀取器範例
 */
@Component
@Slf4j
public class HtmlDocumentService {
    
    /**
     * 讀取 HTML 文件
     */
    public List<Document> readHtmlFile(Resource htmlResource) {
        log.info("Reading HTML file: {}", htmlResource.getFilename());
        
        JsoupDocumentReaderConfig config = JsoupDocumentReaderConfig.builder()
            .selector("article p, div.content") // CSS 選擇器
            .charset("UTF-8")
            .includeLinkUrls(true) // 包含連結 URL
            .metadataTags(List.of("description", "keywords", "author")) // 提取 meta 標籤
            .additionalMetadata("source", htmlResource.getFilename())
            .build();
        
        JsoupDocumentReader htmlReader = new JsoupDocumentReader(htmlResource, config);
        return htmlReader.read();
    }
    
    /**
     * 讀取網頁 URL
     */
    public List<Document> readWebPage(String url) {
        log.info("Reading web page: {}", url);
        
        try {
            Resource urlResource = new UrlResource(url);
            
            JsoupDocumentReaderConfig config = JsoupDocumentReaderConfig.builder()
                .selector("body") // 提取整個 body 內容
                .allElements(false) // 不使用所有元素
                .groupByElement(false) // 不按元素分組
                .includeLinkUrls(false)
                .metadataTags(List.of("title", "description"))
                .additionalMetadata("url", url)
                .build();
            
            JsoupDocumentReader htmlReader = new JsoupDocumentReader(urlResource, config);
            return htmlReader.read();
            
        } catch (Exception e) {
            log.error("Failed to read web page: {}", url, e);
            return Collections.emptyList();
        }
    }
    
}
```

---

## 7.3.5 文檔轉換器 (DocumentTransformer)

### TokenTextSplitter - 文本分割器

```java
/**
 * 使用 TokenTextSplitter 分割文檔
 */
@Component
@Slf4j
public class DocumentTransformService {
    
    /**
     * 基本文本分割
     */
    public List<Document> splitDocuments(List<Document> documents) {
        TokenTextSplitter splitter = new TokenTextSplitter();
        return splitter.transform(documents);
    }
    
    /**
     * 自定義分割參數
     */
    public List<Document> splitDocumentsCustom(List<Document> documents) {
        // defaultChunkSize: 1000, minChunkSizeChars: 400, 
        // minChunkLengthToEmbed: 10, maxNumChunks: 5000, keepSeparator: true
        TokenTextSplitter splitter = new TokenTextSplitter(1000, 400, 10, 5000, true);
        return splitter.transform(documents);
    }
    
    /**
     * 內容格式轉換器
     */
    public List<Document> formatContent(List<Document> documents) {
        ContentFormatTransformer formatter = new ContentFormatTransformer();
        return formatter.transform(documents);
    }
}

/**
 * 元資料增強服務
 */
@Component
@Slf4j
public class MetadataEnrichmentService {
    
    private final ChatModel chatModel;
    
    public MetadataEnrichmentService(ChatModel chatModel) {
        this.chatModel = chatModel;
    }
    
    /**
     * 關鍵字提取器
     */
    public List<Document> enrichWithKeywords(List<Document> documents, int keywordCount) {
        KeywordMetadataEnricher enricher = new KeywordMetadataEnricher(chatModel, keywordCount);
        return enricher.transform(documents);
    }
    
    /**
     * 摘要產生器
     */
    public List<Document> enrichWithSummary(List<Document> documents) {
        SummaryMetadataEnricher enricher = new SummaryMetadataEnricher(
            chatModel, 
            List.of(SummaryMetadataEnricher.SummaryType.CURRENT,
                   SummaryMetadataEnricher.SummaryType.PREVIOUS,
                   SummaryMetadataEnricher.SummaryType.NEXT)
        );
        return enricher.transform(documents);
    }
    
}

/**
 * 文檔轉換管道範例
 */
@Component
@Slf4j
public class DocumentProcessingPipeline {
    
    private final ChatModel chatModel;
    
    public DocumentProcessingPipeline(ChatModel chatModel) {
        this.chatModel = chatModel;
    }
    
    /**
     * 完整的文檔處理管道
     */
    public List<Document> processDocuments(List<Document> documents) {
        log.info("Starting document processing pipeline with {} documents", documents.size());
        
        // 1. 文本分割
        TokenTextSplitter splitter = new TokenTextSplitter(800, 350, 5, 10000, true);
        List<Document> splitDocs = splitter.transform(documents);
        log.info("Split into {} chunks", splitDocs.size());
        
        // 2. 內容格式化
        ContentFormatTransformer formatter = new ContentFormatTransformer();
        List<Document> formattedDocs = formatter.transform(splitDocs);
        
        // 3. 關鍵字提取
        KeywordMetadataEnricher keywordEnricher = new KeywordMetadataEnricher(chatModel, 5);
        List<Document> keywordEnrichedDocs = keywordEnricher.transform(formattedDocs);
        
        // 4. 摘要產生
        SummaryMetadataEnricher summaryEnricher = new SummaryMetadataEnricher(
            chatModel,
            List.of(SummaryMetadataEnricher.SummaryType.CURRENT)
        );
        List<Document> enrichedDocs = summaryEnricher.transform(keywordEnrichedDocs);
        
        log.info("Completed document processing pipeline with {} enriched documents", enrichedDocs.size());
        return enrichedDocs;
    }
    
}
    
```

---

## 7.3.6 文檔寫入器 (DocumentWriter)

### VectorStore - 向量資料庫寫入器

```java
/**
 * 向量資料庫寫入服務
 */
@Component
@Slf4j
public class VectorStoreService {
    
    private final VectorStore vectorStore;
    private final EmbeddingModel embeddingModel;
    
    public VectorStoreService(VectorStore vectorStore, EmbeddingModel embeddingModel) {
        this.vectorStore = vectorStore;
        this.embeddingModel = embeddingModel;
    }
    
    /**
     * 將文檔寫入向量資料庫
     */
    public void writeDocuments(List<Document> documents) {
        log.info("Writing {} documents to vector store", documents.size());
        
        try {
            // 直接使用 VectorStore.write() 方法
            vectorStore.write(documents);
            log.info("Successfully wrote {} documents to vector store", documents.size());
        } catch (Exception e) {
            log.error("Failed to write documents to vector store", e);
            throw new RuntimeException("Vector store write failed", e);
        }
    }
    
    /**
     * 批次寫入文檔
     */
    public void writeBatchDocuments(List<Document> documents, int batchSize) {
        log.info("Writing {} documents in batches of {}", documents.size(), batchSize);
        
        for (int i = 0; i < documents.size(); i += batchSize) {
            int endIndex = Math.min(i + batchSize, documents.size());
            List<Document> batch = documents.subList(i, endIndex);
            
            try {
                vectorStore.write(batch);
                log.info("Wrote batch {}-{} of {} documents", i + 1, endIndex, documents.size());
            } catch (Exception e) {
                log.error("Failed to write batch {}-{}", i + 1, endIndex, e);
                throw new RuntimeException("Batch write failed", e);
            }
        }
    }
    
    /**
     * 使用搜尋引擎查詢文檔
     */
    public List<Document> searchSimilarDocuments(String query, int k) {
        log.info("Searching for {} similar documents with query: {}", k, query);
        
        try {
            SearchRequest searchRequest = SearchRequest.query(query).withTopK(k);
            return vectorStore.similaritySearch(searchRequest);
        } catch (Exception e) {
            log.error("Failed to search similar documents", e);
            return Collections.emptyList();
        }
    }
    
    /**
     * 使用閾值過濾的搜尋
     */
    public List<Document> searchWithThreshold(String query, int k, double threshold) {
        log.info("Searching with threshold {}: {}", threshold, query);
        
        try {
            SearchRequest searchRequest = SearchRequest.query(query)
                .withTopK(k)
                .withSimilarityThreshold(threshold);
            return vectorStore.similaritySearch(searchRequest);
        } catch (Exception e) {
            log.error("Failed to search with threshold", e);
            return Collections.emptyList();
        }
    }
    
}

/**
 * 文件寫入器範例
 */
@Component
@Slf4j
public class FileWriterService {
    
    /**
     * 將文檔寫入文件
     */
    public void writeDocumentsToFile(List<Document> documents, String filename) {
        log.info("Writing {} documents to file: {}", documents.size(), filename);
        
        FileDocumentWriter writer = new FileDocumentWriter(filename, true, MetadataMode.ALL, false);
        writer.write(documents);
        
        log.info("Successfully wrote documents to file: {}", filename);
    }
    
    /**
     * 附加文檔標記的文件寫入
     */
    public void writeDocumentsWithMarkers(List<Document> documents, String filename) {
        log.info("Writing {} documents with markers to file: {}", documents.size(), filename);
        
        FileDocumentWriter writer = new FileDocumentWriter(
            filename, 
            true,  // withDocumentMarkers
            MetadataMode.ALL, 
            true   // append
        );
        writer.write(documents);
    }
    
}

/**
 * 完整 ETL 管道範例
 */
@Component
@Slf4j
public class CompleteEtlPipeline {
    
    private final VectorStore vectorStore;
    private final ChatModel chatModel;
    
    public CompleteEtlPipeline(VectorStore vectorStore, ChatModel chatModel) {
        this.vectorStore = vectorStore;
        this.chatModel = chatModel;
    }
    
    /**
     * 完整的 ETL 流程
     */
    public void processDocumentsPipeline(List<Resource> resources) {
        log.info("Starting complete ETL pipeline with {} resources", resources.size());
        
        // Extract - 讀取文檔
        List<Document> documents = extractDocuments(resources);
        log.info("Extracted {} documents", documents.size());
        
        // Transform - 轉換文檔
        List<Document> transformedDocs = transformDocuments(documents);
        log.info("Transformed to {} document chunks", transformedDocs.size());
        
        // Load - 將文檔載入向量資料庫
        loadDocuments(transformedDocs);
        log.info("Loaded documents to vector store");
        
        log.info("ETL pipeline completed successfully");
    }
    
    private List<Document> extractDocuments(List<Resource> resources) {
        List<Document> allDocs = new ArrayList<>();
        
        for (Resource resource : resources) {
            DocumentReader reader = createReader(resource);
            List<Document> docs = reader.read();
            allDocs.addAll(docs);
        }
        
        return allDocs;
    }
    
    private DocumentReader createReader(Resource resource) {
        String filename = resource.getFilename();
        if (filename != null) {
            String lowerFilename = filename.toLowerCase();
            if (lowerFilename.endsWith(".pdf")) {
                return new PagePdfDocumentReader(resource);
            } else if (lowerFilename.matches(".*\\.(docx?|pptx?|xlsx?)$")) {
                return new TikaDocumentReader(resource);
            } else if (lowerFilename.endsWith(".txt")) {
                return new TextReader(resource);
            } else if (lowerFilename.endsWith(".md")) {
                return new MarkdownDocumentReader(resource);
            } else if (lowerFilename.endsWith(".json")) {
                return new JsonReader(resource);
            }
        }
        throw new IllegalArgumentException("Unsupported file type: " + filename);
    }
    
    private List<Document> transformDocuments(List<Document> documents) {
        // 1. 文本分割
        TokenTextSplitter splitter = new TokenTextSplitter();
        List<Document> splitDocs = splitter.transform(documents);
        
        // 2. 元資料增強
        KeywordMetadataEnricher enricher = new KeywordMetadataEnricher(chatModel, 5);
        return enricher.transform(splitDocs);
    }
    
    private void loadDocuments(List<Document> documents) {
        vectorStore.write(documents);
    }
}
```

---

## 📝 本章重點回顧

1. **ETL 基礎概念**：理解了 Extract、Transform、Load 的完整流程
2. **知識來源分類**：掌握了企業中各種資料來源的特點
3. **提取器架構**：設計了可擴展的資料提取器系統
4. **文檔提取實現**：完成了 PDF、Word 等文檔的提取器
5. **網頁和資料庫提取**：實現了網頁內容和 SQL 資料庫的提取

### 技術要點總結

| 技術點 | 重要性 | 實現難度 | 企業價值 |
|--------|--------|----------|----------|
| **ETL 架構設計** | ⭐⭐⭐ | 高 | 系統基礎 |
| **文檔提取** | ⭐⭐⭐ | 中 | 核心功能 |
| **網頁提取** | ⭐⭐ | 中 | 資料豐富性 |
| **資料庫整合** | ⭐⭐⭐ | 中 | 企業整合 |
| **品質控制** | ⭐⭐ | 中 | 資料可靠性 |

### 最佳實踐建議

1. **模組化設計**：使用可插拔的提取器架構，便於擴展新的資料來源
2. **錯誤處理**：實現完善的錯誤處理和重試機制
3. **效能優化**：使用批次處理和並行處理提高提取效率
4. **資料品質**：建立資料驗證和清理機制
5. **監控告警**：實施完整的提取過程監控和告警

### 下一步學習方向

在下一章中，我們將學習 ETL 的中篇 - 擷取進階文件類型，包括：
- Excel 和 PowerPoint 文檔處理
- 圖像和多媒體內容提取
- 壓縮檔案和複合文檔處理
- 特殊格式文檔的處理技巧

---

**參考資料：**
- [Apache POI Documentation](https://poi.apache.org/)
- [Apache PDFBox Guide](https://pdfbox.apache.org/)
- [Jsoup HTML Parser](https://jsoup.org/)
- [Spring Data JDBC](https://spring.io/projects/spring-data-jdbc)