# 4.4 æ·±å…¥ç­è§£ ChatModel

> **æœ¬ç« é‡é»**ï¼šæ·±å…¥æ¢è¨ Spring AI çš„æ ¸å¿ƒæ¶æ§‹ï¼Œç†è§£ ChatModel èˆ‡ ChatClient çš„é—œä¿‚ï¼ŒæŒæ¡ä¸åŒ AI æ¨¡å‹çš„ç‰¹æ€§å’Œä¼æ¥­ç´šæ‡‰ç”¨ç­–ç•¥ã€‚

## ğŸ¯ å­¸ç¿’ç›®æ¨™

å®Œæˆæœ¬ç« å­¸ç¿’å¾Œï¼Œæ‚¨å°‡èƒ½å¤ ï¼š

- ğŸ¯ **ç†è§£ Spring AI æ¶æ§‹**ï¼šæŒæ¡ ChatModel å’Œ ChatClient çš„å®Œæ•´æ¶æ§‹é—œä¿‚
- ğŸ¯ **é¸æ“‡åˆé©çš„ AI æ¨¡å‹**ï¼šäº†è§£ä¸åŒæ¨¡å‹çš„ç‰¹æ€§å’Œé©ç”¨å ´æ™¯
- ğŸ¯ **é…ç½®æ¨¡å‹åƒæ•¸**ï¼šå­¸æœƒèª¿æ•´æº«åº¦ã€token é™åˆ¶ç­‰é—œéµåƒæ•¸
- ğŸ¯ **å¯¦ç¾æ¨¡å‹åˆ‡æ›**ï¼šå»ºç«‹å½ˆæ€§çš„å¤šæ¨¡å‹æ”¯æ´æ¶æ§‹
- ğŸ¯ **å„ªåŒ–æ¨¡å‹æ•ˆèƒ½**ï¼šæŒæ¡å¿«å–ã€é€£ç·šæ± ç­‰æ•ˆèƒ½å„ªåŒ–æŠ€è¡“

---

## 4.4.1 Spring AI æ¶æ§‹å…¨è²Œ

### ChatModel vs ChatClient é—œä¿‚åœ–

![ChatModel æ¶æ§‹](https://ithelp.ithome.com.tw/upload/images/20240810/20161290nfq1H0dDoW.jpg)

åˆ°ç›®å‰ç‚ºæ­¢æˆ‘å€‘åšå¾—æ¯”ç›´æ¥ä¸Š ChatGPT ç™¼å•é‚„ä¸å¦‚ï¼ŒChatGPT èµ·ç¢¼é‚„èƒ½è¨˜ä½ä½ æ˜¯èª°ï¼ˆä¸ä¿¡è‡ªå·±å»å•ï¼‰ï¼Œä»Šå¤©æˆ‘å€‘å°±ä¾†æ·±å…¥äº†è§£ Spring AI 1.0 GA ä¸­ ChatClient å’Œ ChatModel çš„å®Œæ•´æ¶æ§‹èˆ‡åŠŸèƒ½ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ChatClient                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚            Fluent API Layer             â”‚    â”‚
â”‚  â”‚  â€¢ prompt()                             â”‚    â”‚
â”‚  â”‚  â€¢ system() / user()                    â”‚    â”‚
â”‚  â”‚  â€¢ call() / stream()                    â”‚    â”‚
â”‚  â”‚  â€¢ content() / chatResponse()           â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                     â”‚                           â”‚
â”‚                     â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚              ChatModel                  â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚        Model Abstraction        â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ call(String)                 â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ call(Prompt)                 â”‚    â”‚    â”‚
â”‚  â”‚  â”‚  â€¢ stream(Prompt)               â”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                     â”‚                           â”‚
â”‚                     â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚           Provider Implementations      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚    â”‚
â”‚  â”‚  â”‚ OpenAI  â”‚ â”‚  Azure  â”‚ â”‚  Groq   â”‚    â”‚    â”‚
â”‚  â”‚  â”‚ ChatModelâ”‚ â”‚ChatModelâ”‚ â”‚ChatModelâ”‚    â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¶æ§‹å±¤ç´šèªªæ˜

**1. ChatClientï¼ˆé«˜ç´š API å±¤ï¼‰**
- æä¾›ç¾ä»£åŒ–çš„ Fluent API ä»‹é¢
- é¡ä¼¼æ–¼ Spring ç”Ÿæ…‹ç³»çµ±ä¸­çš„ RestClientã€WebClient
- å…§å»ºå¸¸ç”¨åŠŸèƒ½ï¼šç³»çµ±æç¤ºè©ã€æµå¼è¼¸å‡ºã€éŒ¯èª¤è™•ç†
- æ¨è–¦ç”¨æ–¼å¤§éƒ¨åˆ†æ‡‰ç”¨å ´æ™¯

**2. ChatModelï¼ˆæŠ½è±¡å±¤ï¼‰**
- å®šç¾©èˆ‡ AI æ¨¡å‹äº’å‹•çš„æ ¸å¿ƒä»‹é¢
- æä¾›çµ±ä¸€çš„ API æŠ½è±¡ï¼Œéš±è—ä¸åŒæä¾›å•†çš„å·®ç•°
- æ”¯æ´åŒæ­¥å’Œç•°æ­¥ï¼ˆæµå¼ï¼‰å‘¼å«
- é©åˆéœ€è¦åº•å±¤æ§åˆ¶çš„å ´æ™¯

**3. Provider Implementationsï¼ˆå¯¦ç¾å±¤ï¼‰**
- å„ AI æœå‹™æä¾›å•†çš„å…·é«”å¯¦ç¾
- è™•ç†ç‰¹å®šæä¾›å•†çš„ API å”å®šå’Œèªè­‰
- è² è²¬è«‹æ±‚è½‰æ›å’Œå›æ‡‰è§£æ

---

## 4.4.2 ChatModel æ ¸å¿ƒä»‹é¢

### åŸºæœ¬ä»‹é¢å®šç¾©

```java
public interface ChatModel extends Model<Prompt, ChatResponse>, StreamingChatModel {
    
    /**
     * ç°¡å–®å­—ä¸²å‘¼å«
     * @param message ä½¿ç”¨è€…è¨Šæ¯
     * @return AI å›æ‡‰å…§å®¹
     */
    default String call(String message) {
        Prompt prompt = new Prompt(new UserMessage(message));
        return call(prompt).getResult().getOutput().getContent();
    }
    
    /**
     * å®Œæ•´ Prompt å‘¼å«
     * @param prompt å®Œæ•´çš„æç¤ºè©ç‰©ä»¶
     * @return å®Œæ•´çš„èŠå¤©å›æ‡‰
     */
    @Override
    ChatResponse call(Prompt prompt);
}

public interface StreamingChatModel extends StreamingModel<Prompt, ChatResponse> {
    
    /**
     * æµå¼å‘¼å«
     * @param prompt æç¤ºè©ç‰©ä»¶
     * @return æµå¼èŠå¤©å›æ‡‰
     */
    @Override
    Flux<ChatResponse> stream(Prompt prompt);
    
    /**
     * ç°¡å–®æµå¼å‘¼å«
     * @param message ä½¿ç”¨è€…è¨Šæ¯
     * @return æµå¼å›æ‡‰å…§å®¹
     */
    default Flux<String> stream(String message) {
        return stream(new Prompt(new UserMessage(message)))
                .map(response -> response.getResult().getOutput().getContent());
    }
}
```

### å¯¦éš›ä½¿ç”¨ç¯„ä¾‹

```java
package com.example.service;

import lombok.RequiredArgsConstructor;
import lombok.extern.slf4j.Slf4j;
import org.springframework.ai.chat.model.ChatModel;
import org.springframework.ai.chat.model.StreamingChatModel;
import org.springframework.ai.chat.prompt.*;
import org.springframework.stereotype.Service;
import reactor.core.publisher.Flux;

import java.util.List;
import java.util.Map;

@Service
@RequiredArgsConstructor
@Slf4j
public class ChatModelService {
    
    private final ChatModel chatModel;
    private final StreamingChatModel streamingChatModel;
    
    /**
     * ç°¡å–®å­—ä¸²å‘¼å«
     */
    public String simpleCall(String message) {
        return chatModel.call(message);
    }
    
    /**
     * ä½¿ç”¨ Prompt ç‰©ä»¶çš„å®Œæ•´å‘¼å«
     */
    public ChatResponse fullCall(String systemMessage, String userMessage) {
        Prompt prompt = new Prompt(List.of(
            new SystemMessage(systemMessage),
            new UserMessage(userMessage)
        ));
        
        return chatModel.call(prompt);
    }
    
    /**
     * ä½¿ç”¨ PromptTemplate çš„å‹•æ…‹å‘¼å«
     */
    public String templateCall(String template, Map<String, Object> variables) {
        PromptTemplate promptTemplate = new PromptTemplate(template);
        Prompt prompt = promptTemplate.create(variables);
        
        ChatResponse response = chatModel.call(prompt);
        return response.getResult().getOutput().getContent();
    }
    
    /**
     * æµå¼å‘¼å«
     */
    public Flux<String> streamCall(String message) {
        return streamingChatModel.stream(message);
    }
    
    /**
     * å¸¶é¸é …çš„æµå¼å‘¼å«
     */
    public Flux<String> streamCallWithOptions(String message, ChatOptions options) {
        Prompt prompt = new Prompt(new UserMessage(message), options);
        return streamingChatModel.stream(prompt)
                .map(response -> response.getResult().getOutput().getContent());
    }
}
```

---

## 4.4.3 AI æ¨¡å‹åƒæ•¸é…ç½®

### æ ¸å¿ƒåƒæ•¸èªªæ˜

```java
package com.example.config;

import org.springframework.ai.openai.OpenAiChatOptions;
import org.springframework.ai.openai.api.OpenAiApi;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

@Configuration
public class ChatModelConfig {
    
    /**
     * é è¨­èŠå¤©é¸é …é…ç½®
     */
    @Bean
    public OpenAiChatOptions defaultChatOptions() {
        return OpenAiChatOptions.builder()
                .model("gpt-4o-mini")        // æ¨¡å‹é¸æ“‡
                .temperature(0.7F)           // å‰µæ„åº¦ï¼š0.0-2.0
                .maxTokens(1000)             // æœ€å¤§è¼¸å‡º token æ•¸
                .topP(1.0F)                  // æ ¸å¿ƒæ¡æ¨£ï¼š0.0-1.0
                .frequencyPenalty(0.0F)      // é »ç‡æ‡²ç½°ï¼š-2.0-2.0
                .presencePenalty(0.0F)       // å­˜åœ¨æ‡²ç½°ï¼š-2.0-2.0
                .build();
    }
    
    /**
     * å‰µæ„å¯«ä½œå°ˆç”¨é…ç½®
     */
    @Bean("creativeChatOptions")
    public OpenAiChatOptions creativeChatOptions() {
        return OpenAiChatOptions.builder()
                .model("gpt-4o")
                .temperature(1.2F)           // é«˜å‰µæ„åº¦
                .maxTokens(2000)             // è¼ƒé•·è¼¸å‡º
                .topP(0.9F)                  // ç¨å¾®é™åˆ¶é¸æ“‡ç¯„åœ
                .frequencyPenalty(0.5F)      // é¿å…é‡è¤‡
                .presencePenalty(0.3F)       // é¼“å‹µæ–°è©±é¡Œ
                .build();
    }
    
    /**
     * ç¨‹å¼ç¢¼ç”Ÿæˆå°ˆç”¨é…ç½®
     */
    @Bean("codeChatOptions")
    public OpenAiChatOptions codeChatOptions() {
        return OpenAiChatOptions.builder()
                .model("gpt-4o")
                .temperature(0.2F)           // ä½å‰µæ„åº¦ï¼Œæ›´ç²¾ç¢º
                .maxTokens(1500)             // é©ä¸­è¼¸å‡ºé•·åº¦
                .topP(0.95F)                 // è¼ƒä¿å®ˆçš„é¸æ“‡
                .frequencyPenalty(0.0F)      // ä¸æ‡²ç½°é‡è¤‡ï¼ˆç¨‹å¼ç¢¼å¯èƒ½éœ€è¦é‡è¤‡çµæ§‹ï¼‰
                .presencePenalty(0.0F)
                .build();
    }
}
```

### åƒæ•¸è©³ç´°èªªæ˜

| åƒæ•¸ | ç¯„åœ | èªªæ˜ | ä½¿ç”¨å»ºè­° |
|------|------|------|----------|
| **Temperature** | 0.0-2.0 | æ§åˆ¶å›æ‡‰çš„éš¨æ©Ÿæ€§å’Œå‰µæ„åº¦ | 0.2ï¼ˆç²¾ç¢ºï¼‰ã€0.7ï¼ˆå¹³è¡¡ï¼‰ã€1.2ï¼ˆå‰µæ„ï¼‰ |
| **Max Tokens** | 1-4096+ | é™åˆ¶å›æ‡‰çš„æœ€å¤§é•·åº¦ | æ ¹æ“šéœ€æ±‚è¨­å®šï¼Œæ³¨æ„æˆæœ¬æ§åˆ¶ |
| **Top P** | 0.0-1.0 | æ ¸å¿ƒæ¡æ¨£ï¼Œæ§åˆ¶è©å½™é¸æ“‡ç¯„åœ | 0.9-1.0 è¼ƒå¸¸ç”¨ |
| **Frequency Penalty** | -2.0-2.0 | æ‡²ç½°é‡è¤‡å‡ºç¾çš„è©å½™ | 0.0-0.5 é¿å…éåº¦é‡è¤‡ |
| **Presence Penalty** | -2.0-2.0 | é¼“å‹µè«‡è«–æ–°è©±é¡Œ | 0.0-0.3 å¢åŠ è©±é¡Œå¤šæ¨£æ€§ |

### å‹•æ…‹åƒæ•¸èª¿æ•´

```java
@Service
public class AdaptiveChatService {
    
    private final ChatModel chatModel;
    
    /**
     * æ ¹æ“šå…§å®¹é¡å‹å‹•æ…‹èª¿æ•´åƒæ•¸
     */
    public String adaptiveChat(String message, ContentType contentType) {
        OpenAiChatOptions options = switch (contentType) {
            case CREATIVE_WRITING -> OpenAiChatOptions.builder()
                .temperature(1.2F)
                .maxTokens(2000)
                .build();
                
            case CODE_GENERATION -> OpenAiChatOptions.builder()
                .temperature(0.2F)
                .maxTokens(1500)
                .build();
                
            case TECHNICAL_EXPLANATION -> OpenAiChatOptions.builder()
                .temperature(0.5F)
                .maxTokens(1200)
                .build();
                
            case CASUAL_CHAT -> OpenAiChatOptions.builder()
                .temperature(0.8F)
                .maxTokens(800)
                .build();
        };
        
        Prompt prompt = new Prompt(new UserMessage(message), options);
        return chatModel.call(prompt).getResult().getOutput().getContent();
    }
    
    public enum ContentType {
        CREATIVE_WRITING, CODE_GENERATION, TECHNICAL_EXPLANATION, CASUAL_CHAT
    }
}
```

---

## 4.4.4 å¤šæ¨¡å‹æ”¯æ´æ¶æ§‹

### æ¨¡å‹é¸æ“‡ç­–ç•¥

```java
package com.example.config;

import org.springframework.ai.chat.model.ChatModel;
import org.springframework.ai.openai.OpenAiChatModel;
import org.springframework.ai.openai.api.OpenAiApi;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;
import org.springframework.context.annotation.Primary;

@Configuration
public class MultiModelConfig {
    
    @Value("${spring.ai.openai.api-key}")
    private String openaiApiKey;
    
    @Value("${spring.ai.groq.api-key:}")
    private String groqApiKey;
    
    /**
     * é«˜æ€§èƒ½æ¨¡å‹ - GPT-4o
     */
    @Bean("highPerformanceModel")
    public ChatModel highPerformanceModel() {
        var openAiApi = new OpenAiApi(openaiApiKey);
        var options = OpenAiChatOptions.builder()
            .model("gpt-4o")
            .temperature(0.7F)
            .maxTokens(2000)
            .build();
        return new OpenAiChatModel(openAiApi, options);
    }
    
    /**
     * ç¶“æ¿Ÿå‹æ¨¡å‹ - GPT-4o mini
     */
    @Bean("economicModel")
    @Primary
    public ChatModel economicModel() {
        var openAiApi = new OpenAiApi(openaiApiKey);
        var options = OpenAiChatOptions.builder()
            .model("gpt-4o-mini")
            .temperature(0.7F)
            .maxTokens(1000)
            .build();
        return new OpenAiChatModel(openAiApi, options);
    }
    
    /**
     * é«˜é€Ÿæ¨¡å‹ - Groq
     */
    @Bean("speedModel")
    public ChatModel speedModel() {
        if (groqApiKey == null || groqApiKey.isEmpty()) {
            return economicModel(); // é™ç´šåˆ°ç¶“æ¿Ÿå‹æ¨¡å‹
        }
        
        var groqApi = new OpenAiApi("https://api.groq.com/openai/v1", groqApiKey);
        var options = OpenAiChatOptions.builder()
            .model("llama-3.1-70b-versatile")
            .temperature(0.7F)
            .maxTokens(1000)
            .build();
        return new OpenAiChatModel(groqApi, options);
    }
}
```

### æ™ºèƒ½æ¨¡å‹è·¯ç”±

```java
@Service
public class ModelRouterService {
    
    private final ChatModel highPerformanceModel;
    private final ChatModel economicModel;
    private final ChatModel speedModel;
    
    public ModelRouterService(
            @Qualifier("highPerformanceModel") ChatModel highPerformanceModel,
            @Qualifier("economicModel") ChatModel economicModel,
            @Qualifier("speedModel") ChatModel speedModel) {
        this.highPerformanceModel = highPerformanceModel;
        this.economicModel = economicModel;
        this.speedModel = speedModel;
    }
    
    /**
     * æ ¹æ“šä»»å‹™è¤‡é›œåº¦é¸æ“‡æ¨¡å‹
     */
    public String routeByComplexity(String message, TaskComplexity complexity) {
        ChatModel selectedModel = switch (complexity) {
            case HIGH -> {
                log.info("ä½¿ç”¨é«˜æ€§èƒ½æ¨¡å‹è™•ç†è¤‡é›œä»»å‹™");
                yield highPerformanceModel;
            }
            case MEDIUM -> {
                log.info("ä½¿ç”¨ç¶“æ¿Ÿå‹æ¨¡å‹è™•ç†ä¸­ç­‰ä»»å‹™");
                yield economicModel;
            }
            case LOW -> {
                log.info("ä½¿ç”¨é«˜é€Ÿæ¨¡å‹è™•ç†ç°¡å–®ä»»å‹™");
                yield speedModel;
            }
        };
        
        return selectedModel.call(message);
    }
    
    /**
     * æ ¹æ“šä½¿ç”¨è€…ç­‰ç´šé¸æ“‡æ¨¡å‹
     */
    public String routeByUserTier(String message, UserTier userTier) {
        ChatModel selectedModel = switch (userTier) {
            case PREMIUM -> highPerformanceModel;
            case STANDARD -> economicModel;
            case FREE -> speedModel;
        };
        
        return selectedModel.call(message);
    }
    
    /**
     * å®¹éŒ¯è·¯ç”± - è‡ªå‹•é™ç´š
     */
    public String routeWithFallback(String message) {
        List<ChatModel> models = List.of(
            highPerformanceModel,
            economicModel,
            speedModel
        );
        
        for (ChatModel model : models) {
            try {
                return model.call(message);
            } catch (Exception e) {
                log.warn("æ¨¡å‹å‘¼å«å¤±æ•—ï¼Œå˜—è©¦ä¸‹ä¸€å€‹æ¨¡å‹ï¼š{}", e.getMessage());
            }
        }
        
        throw new RuntimeException("æ‰€æœ‰ AI æ¨¡å‹éƒ½ä¸å¯ç”¨");
    }
    
    public enum TaskComplexity {
        HIGH, MEDIUM, LOW
    }
    
    public enum UserTier {
        PREMIUM, STANDARD, FREE
    }
}
```

---

## 4.4.5 æ•ˆèƒ½å„ªåŒ–èˆ‡å¿«å–

### å›æ‡‰å¿«å–æ©Ÿåˆ¶

```java
package com.example.service;

import org.springframework.cache.annotation.Cacheable;
import org.springframework.stereotype.Service;
import java.security.MessageDigest;
import java.nio.charset.StandardCharsets;

@Service
public class CachedChatService {
    
    private final ChatModel chatModel;
    
    /**
     * å¿«å–å¸¸è¦‹å•é¡Œçš„å›æ‡‰
     */
    @Cacheable(value = "chatResponses", key = "#root.methodName + '_' + T(java.util.Objects).hash(#message)")
    public String getCachedResponse(String message) {
        log.info("å¿«å–æœªå‘½ä¸­ï¼Œå‘¼å« AI æ¨¡å‹ï¼š{}", message);
        return chatModel.call(message);
    }
    
    /**
     * æ ¹æ“šå…§å®¹é›œæ¹Šå¿«å–
     */
    @Cacheable(value = "chatResponses", key = "#root.target.generateCacheKey(#message, #systemPrompt)")
    public String getCachedResponseWithSystem(String message, String systemPrompt) {
        Prompt prompt = new Prompt(List.of(
            new SystemMessage(systemPrompt),
            new UserMessage(message)
        ));
        
        return chatModel.call(prompt).getResult().getOutput().getContent();
    }
    
    /**
     * ç”Ÿæˆå¿«å–éµ
     */
    public String generateCacheKey(String message, String systemPrompt) {
        try {
            String combined = (systemPrompt != null ? systemPrompt : "") + "|" + message;
            MessageDigest digest = MessageDigest.getInstance("SHA-256");
            byte[] hash = digest.digest(combined.getBytes(StandardCharsets.UTF_8));
            return bytesToHex(hash).substring(0, 16); // å–å‰16å­—å…ƒ
        } catch (Exception e) {
            return String.valueOf(Objects.hash(message, systemPrompt));
        }
    }
    
    private String bytesToHex(byte[] bytes) {
        StringBuilder result = new StringBuilder();
        for (byte b : bytes) {
            result.append(String.format("%02x", b));
        }
        return result.toString();
    }
}
```

### å¿«å–é…ç½®

```java
@Configuration
@EnableCaching
public class CacheConfig {
    
    @Bean
    public CacheManager cacheManager() {
        CaffeineCacheManager cacheManager = new CaffeineCacheManager();
        cacheManager.setCaffeine(Caffeine.newBuilder()
            .maximumSize(1000)  // æœ€å¤§å¿«å–æ¢ç›®æ•¸
            .expireAfterWrite(Duration.ofHours(1))  // 1å°æ™‚å¾ŒéæœŸ
            .recordStats());  // å•Ÿç”¨çµ±è¨ˆ
        return cacheManager;
    }
}
```

### é€£ç·šæ± å„ªåŒ–

```yaml
# application.yml
spring:
  ai:
    openai:
      api-key: ${OPENAI_API_KEY}
      base-url: https://api.openai.com
      chat:
        options:
          model: gpt-4o-mini
          temperature: 0.7
      # é€£ç·šæ± é…ç½®
      client:
        connect-timeout: 10s
        read-timeout: 60s
        max-connections: 20
        max-connections-per-route: 10

# å¿«å–é…ç½®
cache:
  caffeine:
    spec: maximumSize=1000,expireAfterWrite=1h
```

---

## 4.4.6 ç›£æ§èˆ‡è¨ºæ–·

### æ¨¡å‹ä½¿ç”¨çµ±è¨ˆ

```java
@Component
public class ChatModelMetrics {
    
    private final MeterRegistry meterRegistry;
    private final Counter requestCounter;
    private final Timer responseTimer;
    private final Gauge activeConnections;
    
    public ChatModelMetrics(MeterRegistry meterRegistry) {
        this.meterRegistry = meterRegistry;
        this.requestCounter = Counter.builder("ai.chat.requests")
            .description("AI chat requests count")
            .register(meterRegistry);
        this.responseTimer = Timer.builder("ai.chat.response.time")
            .description("AI chat response time")
            .register(meterRegistry);
        this.activeConnections = Gauge.builder("ai.chat.connections.active")
            .description("Active AI chat connections")
            .register(meterRegistry, this, ChatModelMetrics::getActiveConnections);
    }
    
    public void recordRequest(String model, Duration responseTime, boolean success) {
        requestCounter.increment(
            Tags.of(
                "model", model,
                "status", success ? "success" : "error"
            )
        );
        responseTimer.record(responseTime, Tags.of("model", model));
    }
    
    private double getActiveConnections() {
        // å¯¦éš›å¯¦ç¾éœ€è¦æ ¹æ“šé€£ç·šæ± ç‹€æ…‹
        return 0.0;
    }
}
```

### å¥åº·æª¢æŸ¥

```java
@Component
public class ChatModelHealthIndicator implements HealthIndicator {
    
    private final ChatModel chatModel;
    
    @Override
    public Health health() {
        try {
            // ç°¡å–®çš„å¥åº·æª¢æŸ¥
            String response = chatModel.call("Hello");
            
            if (response != null && !response.isEmpty()) {
                return Health.up()
                    .withDetail("model", "available")
                    .withDetail("response_length", response.length())
                    .build();
            } else {
                return Health.down()
                    .withDetail("model", "no_response")
                    .build();
            }
        } catch (Exception e) {
            return Health.down()
                .withDetail("model", "error")
                .withDetail("error", e.getMessage())
                .build();
        }
    }
}
```

---

## 4.4.7 å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹

### ä¼æ¥­ç´šèŠå¤©æœå‹™

```java
@Service
@Transactional
public class EnterpriseChatService {
    
    private final ModelRouterService modelRouter;
    private final CachedChatService cachedChat;
    private final ChatModelMetrics metrics;
    
    /**
     * ä¼æ¥­ç´šèŠå¤©è™•ç†
     */
    public ChatResult processChat(ChatRequest request) {
        Instant startTime = Instant.now();
        String model = "unknown";
        boolean success = false;
        
        try {
            // 1. å…§å®¹å®‰å…¨æª¢æŸ¥
            if (!isContentSafe(request.getMessage())) {
                throw new ContentSafetyException("å…§å®¹åŒ…å«ä¸ç•¶è³‡è¨Š");
            }
            
            // 2. ä½¿ç”¨è€…æ¬Šé™æª¢æŸ¥
            UserTier userTier = getUserTier(request.getUserId());
            
            // 3. é¸æ“‡åˆé©çš„æ¨¡å‹
            TaskComplexity complexity = analyzeComplexity(request.getMessage());
            
            // 4. å˜—è©¦å¿«å–
            String cacheKey = generateCacheKey(request);
            String cachedResponse = getCachedResponse(cacheKey);
            if (cachedResponse != null) {
                return ChatResult.fromCache(cachedResponse);
            }
            
            // 5. å‘¼å« AI æ¨¡å‹
            String response = modelRouter.routeByComplexity(
                request.getMessage(), complexity
            );
            
            // 6. å„²å­˜å¿«å–
            saveCachedResponse(cacheKey, response);
            
            // 7. è¨˜éŒ„ä½¿ç”¨çµ±è¨ˆ
            recordUsage(request.getUserId(), model, response.length());
            
            success = true;
            return ChatResult.success(response, model);
            
        } catch (Exception e) {
            log.error("èŠå¤©è™•ç†å¤±æ•—", e);
            return ChatResult.error(e.getMessage());
        } finally {
            Duration responseTime = Duration.between(startTime, Instant.now());
            metrics.recordRequest(model, responseTime, success);
        }
    }
    
    private boolean isContentSafe(String message) {
        // å¯¦ç¾å…§å®¹å®‰å…¨æª¢æŸ¥é‚è¼¯
        return !message.toLowerCase().contains("ä¸ç•¶å…§å®¹");
    }
    
    private TaskComplexity analyzeComplexity(String message) {
        // ç°¡å–®çš„è¤‡é›œåº¦åˆ†æ
        if (message.length() > 500 || message.contains("è¤‡é›œ") || message.contains("è©³ç´°")) {
            return TaskComplexity.HIGH;
        } else if (message.length() > 100) {
            return TaskComplexity.MEDIUM;
        } else {
            return TaskComplexity.LOW;
        }
    }
}

@Data
public class ChatResult {
    private String response;
    private String model;
    private boolean fromCache;
    private boolean success;
    private String error;
    
    public static ChatResult success(String response, String model) {
        ChatResult result = new ChatResult();
        result.setResponse(response);
        result.setModel(model);
        result.setSuccess(true);
        result.setFromCache(false);
        return result;
    }
    
    public static ChatResult fromCache(String response) {
        ChatResult result = new ChatResult();
        result.setResponse(response);
        result.setSuccess(true);
        result.setFromCache(true);
        return result;
    }
    
    public static ChatResult error(String error) {
        ChatResult result = new ChatResult();
        result.setError(error);
        result.setSuccess(false);
        return result;
    }
}
```

---

## ğŸ“ æœ¬ç« é‡é»å›é¡§

1. **Spring AI æ¶æ§‹**ï¼šæ·±å…¥ç†è§£äº† ChatClient å’Œ ChatModel çš„åˆ†å±¤æ¶æ§‹
2. **æ¨¡å‹åƒæ•¸é…ç½®**ï¼šæŒæ¡äº†æº«åº¦ã€token é™åˆ¶ç­‰é—œéµåƒæ•¸çš„èª¿æ•´
3. **å¤šæ¨¡å‹æ”¯æ´**ï¼šå­¸æœƒäº†å»ºç«‹å½ˆæ€§çš„æ¨¡å‹é¸æ“‡å’Œè·¯ç”±æ©Ÿåˆ¶
4. **æ•ˆèƒ½å„ªåŒ–**ï¼šäº†è§£äº†å¿«å–ã€é€£ç·šæ± ç­‰æ•ˆèƒ½å„ªåŒ–æŠ€è¡“
5. **ä¼æ¥­ç´šæ‡‰ç”¨**ï¼šå»ºç«‹äº†å®Œæ•´çš„ä¼æ¥­ç´šèŠå¤©æœå‹™æ¶æ§‹

### ChatClient vs ChatModel é¸æ“‡æŒ‡å—

| å ´æ™¯ | æ¨è–¦é¸æ“‡ | ç†ç”± |
|------|----------|------|
| **ä¸€èˆ¬æ‡‰ç”¨é–‹ç™¼** | ChatClient | Fluent APIï¼Œæ˜“ç”¨æ€§é«˜ |
| **è¤‡é›œæç¤ºè©çµ„åˆ** | ChatClient | å…§å»ºç³»çµ±æç¤ºè©æ”¯æ´ |
| **æµå¼è¼¸å‡º** | ChatClient | æ›´ç°¡æ½”çš„æµå¼ API |
| **åº•å±¤æ§åˆ¶** | ChatModel | ç›´æ¥å­˜å– Prompt ç‰©ä»¶ |
| **è‡ªå®šç¾©æ¨¡æ¿** | ChatModel | å®Œæ•´çš„ PromptTemplate æ”¯æ´ |
| **æ•ˆèƒ½é—œéµå ´æ™¯** | ChatModel | æ›´å°‘çš„æŠ½è±¡å±¤ç´š |

### ä¸‹ä¸€æ­¥å­¸ç¿’æ–¹å‘

åœ¨ä¸‹ä¸€ç« ä¸­ï¼Œæˆ‘å€‘å°‡å­¸ç¿’å‰ç«¯å¦‚ä½•è™•ç†æµå¼è¼¸å‡ºï¼Œå»ºç«‹å®Œæ•´çš„å‰å¾Œç«¯æ•´åˆæ–¹æ¡ˆï¼Œç‚ºä½¿ç”¨è€…æä¾›æœ€ä½³çš„ AI äº’å‹•é«”é©—ã€‚

---

**åƒè€ƒè³‡æ–™ï¼š**
- [Spring AI ChatModel Documentation](https://docs.spring.io/spring-ai/reference/api/chatmodel.html)
- [OpenAI API Parameters](https://platform.openai.com/docs/api-reference/chat/create)
- [Spring Boot Caching](https://docs.spring.io/spring-boot/docs/current/reference/html/io.html#io.caching)
- [Micrometer Metrics](https://micrometer.io/docs)